{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUmSLIwM4ei9",
        "outputId": "d21ea17a-476c-4358-ec75-3cb4453368d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.10.3)\n",
            "Requirement already satisfied: pdfminer.six==20221105 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20221105)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.25.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (41.0.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.10/dist-packages (0.51.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-self-attention) (1.23.5)\n",
            "Requirement already satisfied: afinn in /usr/local/lib/python3.10/dist-packages (0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2\n",
        "!pip install pdfplumber\n",
        "!pip install spacy\n",
        "!pip install scikit-learn\n",
        "!pip install transformers\n",
        "!pip install keras-self-attention\n",
        "!pip install afinn\n",
        "!pip install transformers torch scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jUs0Eaml53fW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMY1e96zieKU",
        "outputId": "93d06de6-0618-4fa1-edfe-70e00900d064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBNhrXKg5oXq",
        "outputId": "354fc21e-0314-4eba-c455-2a5fabf1d77b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SURAJ GOPINATH\n",
            "♂phone+91 8197246247 /envel⌢pesurajgopinath14@gmail.com /linkedinLinkedIn /githubGitHub\n",
            "SUMMARY\n",
            "EDUCATION\n",
            "Amrita School of Engineering Oct. 2020 – May 2024\n",
            "Bachelor of Technology in Computer Science Engineering; CGPA: 9.19/10.0 Bengaluru, India\n",
            "Deeksha Center For Learning 2018 – 2020\n",
            "Percentage: 96% ; Secured 100 in mathematics Bengaluru, India\n",
            "D.A.V Boys Senior Secondary School 2007 – 2018\n",
            "Percentage: 93% ; Chennai, India\n",
            "TECHNICAL SKILLS\n",
            "Languages : JavaScript, HTML/CSS, Python, Java, C, C++, Scala\n",
            "Technologies/Frameworks : React, AWS, Git, NumPy, Pandas, Matplotlib\n",
            "Database : MySQL, OracleSQL, MongoDB, HanaDB\n",
            "EXPERIENCE\n",
            "SAP Labs Bangalore June 2023 – August 2023\n",
            "Software Developer Flask, UI5, HanaDB\n",
            "•Worked on Smart Labs India Assistant Project, a generative AI , based chat-bot that helps employees to get quick response on\n",
            "documents related to SAP\n",
            "•Built a website that follows the Model-View-Controller (MVC) model, utilizing HanaDB ,Flask server in the back-end, and UI5\n",
            "for front-end for department admins to add documents to retrieve data from them.\n",
            "•Integrated the chat-bot with OpenAI’s Large Language Model to understand the documents and generate answers from the\n",
            "documents.\n",
            "•Successfully was able to answer Percentage: 90% ; of the queries within 10 seconds and also successfully scrapped 4 lakh of blogs\n",
            "in 2 hours .\n",
            "PROJECTS\n",
            "TECHIE CORNER Node.js, Express.js, MongoDB GitHub\n",
            "•Techie Corner,is a full stack application is a student management portal for students to view their performance and also enables them to\n",
            "pay all college related fees.\n",
            "•Developed a responsive website applying the Model-View-Controller (MVC) architecture, leveraging MongoDB for database\n",
            "management, Node.js server for back-end operations, and React for seamless user experiences\n",
            "•Implemented a reliable authentication andauthorization system that utilizes JWT implementations, along with cookies and sessions\n",
            "•Led a team of 5 and practised Agile methodology with proper sprint planning, daily scrums, scrum reviews.\n",
            "TEXT ANALYSER |Python, Flask, NLTK, HTML, CSS GitHub\n",
            "•Apython project, for students to check their document for plagiarism with other students and paraphrase it if plagiarism score is greater\n",
            "than 0.5 to reduce the score. Teachers can further read the summary of the document with this application.\n",
            "•Employed Flask for processing the data, and performing plagiarism, paraphrasing and summarizing text and integrated with front end.\n",
            "•Performed plagiarism check accurately for Percentage: 60% ; of the documents\n",
            "MALICIOUS SERVER HACK |Python, NumPy, Pandas GitHub\n",
            "•Amachine learning and a data science project that is can be utilized to find the possibility of a server hack with various parameters like\n",
            "password length, special character count, time etc.\n",
            "•Integrated various machine learning algorithms like KNN, SVM, random forest etc.\n",
            "•Pre processed, normalized and cleaned the data and also analysed the data with various graphs using matplotlib library.\n",
            "•Classified about Percentage: 80% ; of data and predicted accurately.\n",
            "CO-CURRICULAR\n",
            "Geeks For Geeks Club ASEB Aug 2022 – June 2023\n",
            "Core Technical Member\n",
            "•Created a responsive and accessible website for the club.\n",
            "•Conducted various workshops on topics like DSA, Web Development.\n"
          ]
        }
      ],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    reader = PdfReader(pdf_path)\n",
        "    num_pages = len(reader.pages)\n",
        "    all_text = []\n",
        "\n",
        "    for page_num in range(num_pages):\n",
        "        page = reader.pages[page_num]\n",
        "        text = page.extract_text()\n",
        "        all_text.append(text)\n",
        "\n",
        "    return all_text\n",
        "\n",
        "pdf_path = \"/content/SURAJ_RESUME.pdf\"\n",
        "x11 = extract_text_from_pdf(pdf_path)\n",
        "x11=', '.join(x11)\n",
        "\n",
        "print(x11)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgYdUVbEDXpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb6269f-0740-40dd-d245-76c21d6f36f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "Software Engineer, Google.com - Mountain View \n",
            "This position can be based in San Franci sco, CA; Santa Monica, CA; Pittsburgh, PA; New \n",
            "York, NY or Kirkland/Seattle, WA. \n",
            "To apply vist: http://www.google.com/intl/en/jobs/usl ocations/mountain-view/swe/software-\n",
            "engineer-google-com-mountain-view/index.html   \n",
            " \n",
            "The area: Google.com Engineering \n",
            "With analytical and code-level troubleshooting abilities to spare, Google.com's engineers are \n",
            "technology whizzes who love being in the center of the action. We tackle a range of complex \n",
            "software and systems issues, including m onitoring, responding to and safeguarding the \n",
            "availability of our most popular services. \n",
            "The role: Software Engineer, Google.com \n",
            "As a Software Engineer working on Google's crit ical production applications and infrastructure, \n",
            "your mission will be to ensure Google is always fast, available, scalable and engineered to \n",
            "withstand unparalleled demand. You will be in the thick of solving the [often unexpected] \n",
            "problems of systems at scale in a way most engi neers never experience. Your scope is from the \n",
            "kernel level to the continent level. This position re quires the flexibility and aptitude to zoom in to \n",
            "fine-grained detail, and the agility to zoom right back out and up the stack. Delve into how \n",
            "software performs, packets flow, and hardware  and code interact, in support of managing \n",
            "services, steering global traffic a nd predicting and preventing failu res.... all in a day's work. You \n",
            "will design and develop systems to run Google Search, Gmail, YouTube, Wave, Maps, Voice, \n",
            "AppEngine, and more. You'll manage, automate, a nd make data-based decisions and judgment \n",
            "calls which influence globally distributed applications. You'll own the production services which comprise *.google.com, and critical infrastructure like \n",
            "GFS, BigTable , MapReduce  and large-\n",
            "scale 'cloud computing' clusters. \n",
            "You will also be driving performance and reliabilit y from software and infrastructure at massive \n",
            "scale -- where dealing in petabytes  and gigabits and shifting by or ders of magnitude is routine. \n",
            "You will tackle challenging, novel situations every day and work with just about every other engineering and operations team at Google. You will be looked upon as an expert and advocate \n",
            "to fellow engineers on making design and reliability  trade-offs in running large- scale services \n",
            "and engineering complex systems that fail gracef ully and transparently to users. The most \n",
            "successful candidates for this role will have stro ng analytical and trouble shooting skills, fluency \n",
            "in coding and systems design, solid communication skills and a desire to tackle the complex \n",
            "problems of scale which are uniqu ely Google. We are particular ly interested in software \n",
            "engineers familiar with aspects of running web services at scale -- depth in either networking \n",
            "technologies and Unix system calls are strong pluses. ,  \n",
            "Responsibilities: \n",
            "• Manage availability, latency, s calability and efficiency of Go ogle services by engineering \n",
            "reliability into software and systems \n",
            "• Respond to and resolve emergent service probl ems; write software and build automation \n",
            "to prevent problem recurrence \n",
            "• Participate in service capacity planning and demand forecasting, software performance \n",
            "analysis and system tuning \n",
            "• Review and influence ongoing design, architecture, standards and methods for operating \n",
            "services and systems \n",
            "Requirements: \n",
            "• BS/MS in Computer Science or related field/degree, and/or equivalent work experience \n",
            "• Fluency in one or more of: C, C++, Java; and familiarity with one or more of: Python, \n",
            "Perl, Shell, PHP \n",
            "• Expertise in data structures, al gorithms and complexity analysis \n",
            "• Expertise in analyzing an d troubleshooting large-s cale distributed systems \n",
            "• Knowledge of IP networking, network analysis, performance a nd application issues using \n",
            "standard tools like tcpdump \n",
            "• Ability to handle periodic oncall dut y as well as out-of-band requests \n",
            "• Experience in a high-volume or critical production service envir onment is preferred \n",
            " \n"
          ]
        }
      ],
      "source": [
        "jdpath = \"/content/JD.pdf\"\n",
        "job = extract_text_from_pdf(jdpath)\n",
        "job=', '.join(job)\n",
        "print(job)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY58_KKdAqtE",
        "outputId": "e54907ac-b61f-432d-b248-79074a3bc6b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ms sql server tools', ' university', ' business case', ' bsc', ' opensource technologies', 'payroll', ' sql stored procedures', ' aws gateway', ' 3nf principles', 'brs', ' sap abap', ' microcontroller', ' clinical sas programming', ' documentation', 'python/spark/sql', 'version control', ' aws redshift', 'tracking', 'structural engineering', 'node js', ' discoverorg', ' webservices', ' technical training', 'ms sql server', ' azure synapse pool', ' google tag manager', ' construction', ' vmware and/or kubernetes', ' gcp/azure/aws db', ' elasticstack', ' insights', ' geoinformatics', ' strategy', ' big table', ' multi - tenancy', ' siebel', 'tally', ' rake', 'data models', ' survey design', ' system scalability', 'core python', 'pyspark', ' arc', 'accounting', ' fsd', ' compensation analysis', ' microsoft applications', ' rich snippets', ' market risk analyst', 'professional', ' maintenance', 'requirement gathering', ' digital campaigns', ' scalability', ' monte carlo simulation', ' schedule efficiency', ' redhat linux', 'data structure & algorithm', ' ats', ' microsoft office applications', ' marketing support', ' leadership', 'nunit', ' star', 'new relic', 'etl / elt', 'credit analyst', ' opencv', ' mysql dba', ' patent landscaping', ' product planning', ' team coordination', ' bonds', 'react.js', ' automation design', 'front office', ' agile development', 'supervisor', ' multi - threaded', ' site monitoring', ' patch management', ' hse management system', ' c#', 'scrum master', 'sas enterprise miner', 'maven', 'iis', ' load balancers', ' revenue operations', 'azure database', ' manager internal audit', ' online research', ' couchbase', ' administration', 'microsoft dynamics', ' collection', \" 'java\", ' android studio', 'sql server analysis services', ' ci / cd pipeline', ' object oriented development', ' statistical data analysis', ' chaid', ' pep', ' tensorflow /pytorch', ' microsoft azure analytics services', ' data architect gcp & bigquery rdbms', 'ux', 'scheduling', ' audit compliance', ' python data science', ' time series forecasting', ' c# net', 'it services', 'machine learning development', ' story writing', ' inhouse sales', ' soql bi', 'sql development', ' and databricks', ' azure data bricks', ' heat exchangers', ' computational chemistry', ' engineering mathematics', ' modeling', 'tabluea', ' user management section', 'process documentation', ' data enterprise', ' stakeholders management', 'renewable energy', ' pytest', ' bi engineering', ' hbase', ' c suite', ' business strategy', 'quantity conversions', ' owasp', ' azure cloud systems', 'data lake', 'clinical data analyst', ' service level', ' pricing analytics', ' software design', ' ubuntu', ' mpp', ' idq', ' microsoft office suite', ' catering', 'hr function dynamics', ' business consultant', 'water testing', ' nodejs framework', ' dashboard tools', 'ifrs/us gaap', ' effects analysis', ' backend operations', ' registry', ' visa processing', ' calypso', ' gsm', ' sparkml', 'infopath', 'time series', ' oracle vcp', ' glue pyspark', 'webservices', ' java or python', ' contact discovery', ' product analysis', 'sas eg', ' redshift sql', ' gam', ' multi - tier', ' scd', ' it service management support', ' angular framework', ' sr. spec', ' cloud security', ' python for data science', ' map reduce', ' join', ' system engineering', ' aws sns', 'illustrator', ' cloud native', 'scipy', 'data science pytorch', ' excellent english', ' art', 'microservices architecture', ' order to cash', ' claims adjudication', ' azure storage', ' azure data', ' databricksetl', ' jar', ' sponsorship', ' react.js', 'keras', ' school', ' sox compliance', ' project support', ' profiler activity', ' regression analysis', ' pair programming', 'tcad', 'conceptual modelling', 'hr systems', ' sap is', ' superset', ' sql server cluster', ' strong interpersonal skills', 'excel vba', ' sql code', ' writing skills', 'tableau', 'service level', 'data annotation', ' core spark', ' market sizing', ' system implementation', ' test planning', ' test reporting', 'content', ' customer retention', ' bacs', 'reltio', ' electronics design', 'cmm', ' random forest', ' pytorch4', ' salesforce crm', 'tibco spotfire', ' application', ' sap extended warehouse management', ' loan services', 'ciem', ' downstream', 'azure spark', ' lstms', ' development lead', ' aws transfer family', ' hadoop development', ' application lead', ' product', ' b2b marketing', ' startup', ' big data warehousing', ' architecting', ' storm', ' event monitoring', ' countif', ' esb', ' model', 'datastage', 'storyteller', 'apache solr', ' opportunity assessment', ' azureml', 'wealth management', ' hlookup', ' elastic stack', ' maximo data model', ' cloud data', ' dimension', ' r & d', ' energy', ' ssrs', 'rest api', 'presentation skills', ' social media analyst', ' k8s', ' tax advisor', ' o2c', ' distribution systemx', ' statistical techniques', ' access management', ' nsq', ' thermal', ' sap bw abap', ' java ee', ' spatial data analysis', ' reinsurance', ' radar', ' condition monitoring', ' e commerce', ' big data engineer - etl', ' data storage and retrieval', ' html and css', 'computer science', ' maven', ' electrical design', 'er diagram', 'bid management', 'sql server integration services', ' data scientist', ' legal compliance', ' software development methodologies', ' data cloud', ' hadoop file system', ' react native development', ' physics', ' query management', 'the', ' enterprise reporting', 'presales', ' management associate', ' ds', 'msk', ' jaxb', ' project management certified professional', ' spark/scala', ' microsoft sql server 2008', ' cobol', 'leadership training', ' soa', ' golang', 'python developer', ' design development', ' big data technology stack administration', ' document review', ' software troubleshooting', ' product design', ' veeva vault platform', ' organizational development', ' data virtualization', ' automated testing', ' mobile development life cycle', ' data cleansing', ' customer complaints', 'due diligence', ' saas platform on aws', ' bss', ' processor', ' it risk', ' designing and developing extract', ' tsql', 'tqm', ' flask apis', ' aml', 'full-stack dev', ' on page', ' vlan configuration', ' forecasting', ' quality systems', 'customer experience', ' audit', 'leadership development', ' functional safety', 'natural language processing', ' transaction analysis', ' iso 27001', 'google data studio', ' sql', ' big data data modeling', ' advanced excel formulas', ' subject matter expert', 'digital operations', 'characterization', 'congos', 'veeva', 'data automation', ' data gathering', 'big data engineering', ' system development', ' online sales', ' cloud databases', ' profit growth', ' mule esb', 'mlops', 'visualization', ' bcom', ' sql analyst', ' asp net mvc', ' rnns', ' webpack', ' r python', ' structures', ' data evaluation', ' monthly reports', ' gaap', ' integration runtime services', ' change management', ' big data application development', ' amrut', ' media research', ' service now', 'performance management', ' sap bo', ' audits', 'database maintenance', ' puppet', ' blazemeter', ' associate director', 'performance analyst', ' board design', ' ui', ' xcuitest', ' data research', ' celery', ' uml', ' litigation', ' factiva', ' control mapping', ' platform manager', ' l2 support', ' talend development', ' azure pipelines', 'azure data factory pyspark databricks adls azure sql database python/scala sql', 'business administration', 'mdm', ' layout design', ' jar file', ' production', ' hydrocarbon product management', ' sdlc', ' consultant business analyst', ' people development', ' amazon s3', ' nlu', ' gcp data engineer', 'dev - analysis', 'ambassador platforms', 'unix', ' multi-omics data processing', 'data federation', ' beanshell scripting', ' php', ' graduate', 'economics', ' sow', ' master data management', 'knime', ' wps', ' collibratool', 'web services testing', ' mqtt', ' data lake analytics', ' sem', ' pivotal', ' ms sql server reporting services', ' application monitoring', ' time', ' business process automation', ' analysing data', 'analyst', ' articleship', ' it analyst', ' tableau reporting', ' rbac controls', ' a+', ' error analysis', ' ssrs report writer', 'greenplum', 'document review', ' or aws', 'flask', 'post production', ' fiddler', 'core java programming', 'r', ' dockers', 'advanced analysis', 'data integrity', ' test lead', 'gitlab', ' blockchain', 'fnd', ' cisco routers', ' allscripts', ' pdm', ' quality operations', 'mobile application development', ' data migration', ' c/c++', ' ibm data stage', ' business requirements', ' confluence', ' project development', 'ai/ml', 'restful', ' data bases', 'quantitative research', ' fdmee', 'research and development', ' soap apis', ' ipv6', ' charles river', ' ai modeling', ' er builder', ' glue catalog', 'rdbms/plsql/stored procedures oracle-10/11g sap hana data warehouse', 'consumer research', ' it asset management', ' corporate strategy', 'attentive listener', 'puppet', 'python web scraping', ' glue job', ' azure data stack', ' project schedules', ' hive', ' shell script', ' isms', 'remote access', 'billing', ' agile scrum', ' structure', ' gathering', ' datastudio', ' eviews', ' api testing', ' trillium', ' ppap', ' credit control', 'spring', ' sdwan', ' datastage', 'transaction monitoring', ' azure data lake gen2', 'system testing', ' rbdms', 'data warehousing', ' grpc', ' engineering services', ' reporting tool', 'quality assurance analyst', ' power bi desktop', ' physical design', ' application design', ' loan document', 'compensation benchmarking', ' six sigma', ' machine learning modelling', ' trading', ' object - oriented', 'python sql aws', 'github', ' email', ' cdh', 'email', ' advanced', ' tomcat', ' source system analysis', ' quantitative techniques', 'data curation', 'graphic designing', 'corporate actions', 'frontend development', ' senior quantitative analyst', ' crystal reports', ' data generation', ' management consulting', ' data reporting', ' bigdata frameworks', ' rpa', ' equity', ' vsts', 'edm', ' human resources', ' technology architecture', ' sales management', ' azure cloud platform', ' data sharing', ' options', ' azure repos', ' ms visual', ' kakfa', 'user research', ' db using nosql', ' deep learning stack', 'synthetic data generation', ' product training', ' wellness', ' architects', ' dt&el', ' data studiotableau', ' javamr', ' macro', ' red', ' inventory control', 'esi data processing', 'soap ui', ' email etiquette', ' implementation analyst', 'data dictionary', ' excel macro', ' jenkin', 'manager internal audit', ' cost trend analysis', 'accessories', 'informatica powercenter', ' alteyrix', ' document verification', ' query database', ' google', 'marketing research', ' cocoa apis', 'software installation', ' github', ' backend engineering', ' pcie', ' sap fieldglass', ' program management', ' consumer electronics', ' siem', ' dashboard reporting', ' azure machine learning', ' business technical analyst', ' bert', ' r&d scientist', ' wcf', ' decision making', ' wb/dpd form', ' aws lambda', ' hyperion essbase', 'airflow', ' process expert', ' withs3', 'data architecture principles', ' uat', ' consulting bfsi', ' accounts', 'kdb', ' pbm domain', ' security analyst', ' scikit - learn', ' metadata', ' datalab', ' pl/sql and standard rdbmss', 'six sigma', ' sql server db', ' process automation', ' splunk', ' quantitative', ' c# sharp', ' bsc it', ' representative', ' skin care', ' factory', ' post production', ' profitability & cost management', 'simulation', 'high throughput computational screening', ' inbound', ' mpm', ' uc4', ' solution design', 'qt', ' cognos reporting', ' cognito', 'performance turning', ' ansible', ' sql script', 'modeling risk', ' rollovers', 'neural networks', ' electronic trading', ' contract management', ' project life cycle', ' hazop', ' brainstorming', ' aws virtual private cloud', ' circuit designing', ' cobit', ' process analyst', ' checkpointt', ' mechanical engineering', ' ir fx', ' ml analytics', ' messaging framework', ' data architecture', 'd365', ' adobe marketing cloud', 'sap hana', 'pl / sql', ' data feed', ' software solutions', ' mi report development', ' scrum setup', ' technical management', ' access controls', ' mdm with informatica', ' database associate', ' aws cloud native', ' full time', ' web services development', 'angular', ' cloning', ' credit risk', ' process simulation', ' accounting entries', ' medical billing', ' ltmc', ' good with numbers', ' consulting - healthcare', ' product management', 'verbal communication', ' serving notice period', ' data warehousing architecture', ' ssms', ' 4g', ' sap mdm', 'data structures', ' commerce', 'assurance', ' business economics', ' vista', ' futures', ' fastapi', ' vms', ' ip', ' etls', 'google pub', ' sap sales', ' operational support', ' scrum', ' requirements gathering', ' root - cause analysis', ' power query', ' analyzing data', ' senior software engineer', ' internship', ' nlb', ' cross selling', ' relational databases', ' programming skills', ' system programming', ' strategic leadership', ' account opening', 'sap bods', ' talendsuite', ' process integration engineer', ' advanced iam', ' financial spreading', ' cspm', ' weka', ' open cv', ' defect tracking', ' otb', ' debtors', 'etls', ' firehose', 'software estimation', ' hbase database', 'know your customer', ' ipo', ' report studio', ' process improvement', ' digital transformation', ' manufacturing operations', 'full stack', ' key account management', ' machine learning engineer', ' interaction design', ' pricing strategy', ' data insight', ' big query ml', ' methods', ' it project management', ' haveaws', ' test case review', ' msp', 'technical analysis', 'r program', ' couchdb', ' vlookup', ' azure storage explorer', 'hcm', ' big -', ' synapze pipeline', ' prototype design', 'kafka', 'w2', ' android ndk', ' customer experience', ' allegro', ' sez', ' google app engine', ' azure cloud architecture', 'computer hardware', ' edc', 'operations', ' python programming', 'expense management', ' modem', 'data analytics', ' user acceptance testing', ' mulesoft anypoint api platform', 'tsql queries', ' sql dbs', ' less', ' change delivery', ' advanced statistics', ' occupational health', ' bluetooth', ' azure stream analytics', ' image analytics', 'product costing', ' cloud sql', ' audio editing', ' ui architecture', ' financial markets', ' agent based modeling', ' regulatory projects', 'it strategy planning', ' data optimization', ' dask', ' cloud functions', ' wet stock business', ' risk assessments', 'ratio analysis', ' sap oracle db', ' written', ' pu-sub', 'data pipelining', 'competitive analysis', ' loans', ' patent analyst', ' jango', ' tws', 'product data management', ' portfolio reconciliation', ' strategic thinking', ' html;javascript', ' flux', 'cloud formation aws', ' quality assurance analyst', ' bloomberg', 'amazon redshift', 'data cleaning', ' platform architecture', ' pass', ' assistant vice president operations', 'research', ' azure cloud data', 'associate operations', 'satisfaction', 'data research analyst', ' r coding', ' performance turning', ' trade support', ' sap pi', 'microsoft', 'microsoft word', ' data lake', ' reinforcement learning', ' associate business analyst', ' private equity', ' elk', 'aml analyst', ' personal care', ' hyper converge', 'teradata bi', ' ca', ' itsm', 'android sdk', 'business data analyst', ' azure blob', ' marketing research analyst', ' cash management analyst', ' head design', ' salesforce administrator', ' tableau/power bi', ' channel business', 'red hat linux', ' dms', ' cctv', ' dts', 'coin', ' rally', ' retail business', ' troubleshooting', ' sensors', ' telematics', ' contact center', ' scala hadoop', ' buying team', 'spark with aws', ' pythonprogramming', 'service management', ' plotly', ' js', 'customer service', ' logical and analytical ability', ' mapr', ' machinery', ' dealing', ' cyber security', ' cdp', ' transfer pricing', ' direct marketing', ' veeva rep survey', ' java', ' data mining', 'cicd', ' lms', 'team leading', ' orc protobuf', 'public policy', ' icims', ' induction', ' ai / ml', 'data security', ' construction equipment', ' graphic designing', ' git workflows', 'liquidity risk management', 'enterprise architect', ' field service management', 'sql orm', 'apex programming', ' deep learning', ' synthetic organic chemistry', 'process mapping', ' rac', ' decission trees', ' data business analyst', 'technical product management', ' core databases', ' linq', 'google cloud platform', ' azure cloud services', ' cartography', ' u - sql', ' coso', ' scientist 1', ' javascript frameworks', ' manager technology', ' android java', 'medical imaging', ' system analyst', ' life', 'ssms', ' typescript', ' pandas', ' snowflake cloud', ' node-js', ' database administrator', ' nsx - t', ' specifications', 'general insurance', ' cancer diseases', ' data mapping', ' google analytics 360', ' nexus', ' dbms', ' ci / cd automation', 'catastrophe modeling', 'organizational', ' customer support', ' flarenet', ' data modelling', ' grc', ' product marketing', 'data structures and algorithm design', ' static equipment', 'technical', 'informatica', ' redshift spectrum', ' confirmit', ' big data frameworks', ' amazon aws cloud', ' mantis', ' tsql development', 'praat', ' sales', ' spark sql', ' data validation', ' datafactory', ' etl implementation', ' material master', ' leadership skills', 'technical troubleshooting', ' mro', ' thunk', ' spend analysis', ' sysomos', ' bi support analyst', ' ci/cd tools', 'probability of default', 'media math', 'information architecture', ' unix linux', ' {{git', ' ant', 'test automation', 'statistical tools', ' obiee', 'alteryx', 'keyword research', ' tensor flow', ' system software', 'pentaho', ' media management', ' sisense', ' azure data catalog', ' it fresher', ' marketing manager', ' order management', ' cdm', ' data insights generation', ' music', ' azure data base', 'cloud platforms', ' fdc', 'azure sql dwh', 'manager quality assurance', ' reactive programming', ' scorecard building', ' siemens', ' sas enterprise guide', ' map reduce framework', ' emr', ' data flows', 'malware analysis', 'bi manager', ' forex', 'd3.js', ' hr analytics', ' aws security', ' product analytics', ' statistical simulation / regression modeling', 'building applications', ' hive queries', ' hive spark', ' business', ' ms office suite', ' written communications', ' indirect taxation', ' employee engagement', ' social media analytics', ' charts', ' reporting services', ' data - warehousing', ' oracle relational databases.', ' mdm tools', ' data moderation', ' anaconda', ' dnb', 'tableau lead', ' pivot table', 'loans', 'aws architecture', 'market research analyst', ' data data modeling', ' mariadb', ' threaded', 'continuous integration', ' lead business analyst', ' msbi', 'automation tools', 'cloudera', ' business analytics', ' healthcare analytics', ' performance reporting', ' derivatives', ' home appliances', ' rpa technologies', ' amazon connect', ' technical solutioning', 'pitch books', ' aerospace', ' data - structures', 'eks', ' hr head', 'zeplin', ' server - side', ' jsp technologies', ' performance optimization', ' nse', ' g python query language python', ' django rest framework', ' microsoft azure data stack', ' model development', ' technology implementation', ' statistical technique', ' e-commerce', ' postgresql administration', ' software', ' acl', ' azure security services', ' feedck', ' lighhouse', ' continuous deployment', ' cism', ' it risk assessment', ' engineering data', 'business management', ' coordination', ' ecs', ' hortonworks', ' econometrics', ' cloud cli', 'dynamodb', ' dagger', ' solution architecture', 'integration', ' online marketing', 'database concepts', ' azure keyvalut', ' oncology', ' phd', ' aggregation', ' performance measurement', 'framework manager', 'java 7', ' data masking', ' spark-sql', ' information retrieval and analysis', ' written communication', 'google cloud data services', ' sprint', 'procurement', ' data analysts', ' agile project experience. good understanding and experience of the various agile frameworks', ' ad hoc', ' azure dataengineer', ' time series analysis', ' lead analyst', ' data architecture principles', ' as400', 'cold calling', 'nifi', 'natural language', 'spark ml', ' ios sdk', ' financial systems analyst', 'lex', ' general insurance', ' quality engineering', ' gnu', 'erp', 'aws - s3', ' bigqurery', ' balance sheet analysis', ' nunit', ' process transition', ' lumira', 'query', 'scikit', ' supply chain planning', 'application engineering', ' statistical process control', 'mobx', 'visualforce', ' vat', ' purchase requisition', ' data marts', ' elt methodology', ' business consultant/ business analyst- hcm/payroll', ' aws data engineer', ' ux research', 'information system design', ' front office', ' vxworks', 'bpo', ' prices', ' and advertising.', ' cloud design', ' ppc', 'cfd', ' ideas', ' macos', ' data architectures', ' jasmine', ' lgd', ' flexbox', 'medical underwriting', 'aws python', 'data management', ' technology engineer', ' marketing analyst', ' containers', ' data warehouse testing', ' numphy', 'customer analysis', ' hibernate', ' business planning analyst', ' operational risk', ' polls', ' api architecture', ' comparative analysis', ' radtab', ' churn modeling', 'hana', ' oracle business intelligence', 'sfdc', ' it business', ' internet technologies', 'schema', ' numpy stack', ' apache arrow', ' oil', 'decision tree', 'azure sql datawarehouse', 'non-voices process', 'it sourcing', ' dell emc vxrail', ' clouddata proc', 'nuix', ' statistical software', 'p&c insurance', ' esi data hosting', ' itil processes', ' cognitive computing', ' cleo vl trader', 'data cleansing', 'database knowledge', 'learning', 'json', 'governance', ' dialogflow', ' teradata architecture', ' sentry', ' rds mysql', ' deliver wireframe', ' ml pipelines', 'monetization', ' adb', ' backend', ' svn', ' data recovery', ' infrastructure as code', ' biginsights', ' azure architect', ' collibra tool', ' flexera', ' googlecloud', ' hana', ' streams', ' defect management', ' linear regressions', ' postgres sql', 'ms excel', 'dataframe', 'pytorch', ' tanium', ' omni journey mapper', ' wordpress', ' lookml coding', ' pl-sql', 'technology service operations', ' sap hana', ' business management', 'data research', ' tableu', ' driven development', 'vpn', 'os', ' vulnerability assessment', ' aws stack', 'junior analyst', ' performance - oriented programming', ' apache stack', ' patent litigation', ' aws kinesis', 'rtr', ' nlp models', 'app development', ' kafka', ' isin', ' compliance management', ' b2b lead generation', ' business understanding', ' perfecto', 'graph dbs', ' optimization', 'python r', ' sas r', ' idoc', ' event management', ' excel', ' product life cycle', ' trainer', ' dynamics erp', ' us gaap', ' pharmacovigilance', ' statstics fresher', ' dashboarding', ' photoshop', ' like pyspark', ' predictive analysis', ' gap analysis', 'excel spreadsheet', ' application integration', ' manufacturing engineering', 'modelling', ' workforce management', ' dynamics crm', 'kubeflow', 'it analyst', ' logging framework', ' relational database management', ' project setup', 'cloud data', ' investment management domain', ' nosql', ' medical coding', 'data fusion', ' functional specifications', ' kpo', 'guidewire products', ' flash', 'data visualizations', ' gis project management', ' content management', 'enterprise architecture', ' camel', 'competitor analysis', ' node.js', ' production planning', ' microsoft excel', ' open component', 'data processing', ' jquery', ' mongo db', ' business acumen', ' it sales', ' uima', ' business writing', ' literature', ' visual design', ' data infrastructure', ' hrms', ' data center operations', ' power point report', ' operational excellence', ' mainframe', 'api testing', ' waterfall', ' managing reports', ' pcb designing', 'documentation', 'pythin', ' jvm', 'procurement support', ' fixed assets', ' design patterns', ' nbfc', ' synapse analytics', ' looker data analysis', ' rapidminer', 'manager crm', ' consumer durables', ' spark architecture', ' naive bayes', ' dba', 'aerospace', 'fund accounting', ' os troubleshooting', ' information security', ' snowflake / redshift', ' bpm business process management', ' python c', 'system development life cycle', ' spss statistics', 'distributed system', ' detail design', ' object oriented modeling', ' mapreduce', ' android design', 'core java', ' project management', ' bivariate analysis', ' pyspark coding', 'user acceptance testing', ' google cloud server', ' continuous security', 'oral communication', ' scalable systems', ' tableau server', ' er studio', 'big data devloper', ' spss modeller', ' dremio', ' research projects', ' system administrator', ' glue', 'san', ' efs', 'translation', ' cloudera hadoop', ' health', ' business executive', 'journal entries', ' loss prevention', 'machine learning libraries', ' azure apps', ' testing strategy', ' azure native services', ' sustainable development', 'mis executive', ' analytical method development', ' hr automation', ' streaming framework', ' code development', 'sr. full-stack dev', ' stakeholder engagement', ' optimization techniques', ' dashboard tool', ' devops jenkins', ' confluent', ' tms', 'sas model validation', ' database architecture', ' appdynamics', 'gcp storage', ' ci/cd pipeline', ' architect', ' database schema', ' data model definition', ' ajax', ' strategic consulting', 'convex optimization', 'powerbi', ' product lifecycle management', ' npv', 'kyc', ' algorithm development', ' qlikview', ' service industry', ' sql no sql', ' applied mathematics', ' vendor coordination', ' commodity trading', 'terraform', 'graphics', ' web operations', ' business development executive', 'o2c', ' cognitive services', ' analyst 2', ' product head', ' wfm', ' date lake', 'management', ' adls2', ' scrum methodology', ' graph db', ' procurement procedures', ' it project delivery', ' fraud management', ' website management', 'software architecture', ' scientist ii', 'system operations', ' assurance', ' svm', ' git', ' trade', ' bigquery', ' google apps', ' e - business', 'analytics data', 'aws lamda', ' incident investigation', ' aiml architect', ' svn}}', ' cost optimization', ' pyhton', ' medical records', 'pharmacy', ' elv systems', ' oracle fusion', 'onnx', ' r - shiny', ' network analysis', ' diabetes', ' datalake azure', ' ui path', ' machine - learning', ' big data analytic frameworks', ' database designing', ' mining operations', 'power bi tableau', 'cnn', ' junior data analyst', ' exploratory data analysis', ' snowsql', ' erdas imagine', ' hr analyst', ' strategy evaluation logistics', ' power automate', ' statistics optimization', ' cuad', ' multithreading', 'engineering services', ' process integration', ' digital analytics', ' xib', ' subversion', 'marketing interventionist', 'requirement analysis', ' databricks azure data catalog', ' windows', ' spark analytics', 'capital advisors', ' sre', ' data analytical', ' tps', ' sql tuning', ' load', 'healthcare sales', ' hadoop stack', ' object oriented coding', ' backend development', ' service analyst', ' gts', ' credit risk management', ' market research agency', ' python', ' software engineer 2', 'python/r', ' capital market', ' control system', 'quality improvement', 'bcom', ' sap cpq', ' azure analytics services', 'javascript', ' networking skills', ' variant configuration', ' azure kubernetes infrastructure admin', ' websphere data integration suite', ' cpg', ' engineering projects', ' k - means', ' data engineer ii', 'end-to-end', ' data integrator', ' mockplus', ' text minig', ' credit risk analytics', ' content analyst', ' python pandas', ' telecommunication', 'content and data management', 'senior software engineer - data and ml', 'soc', ' word', ' loan structuring', ' vba automation', 'finance operations', 'lake', ' 3g', ' big data processing', ' inter', ' dataproc hub', 'neo4j', ' scala development', 'talend big data', ' requirement gathering', ' ad campaign', ' ui / ux designers', ' balance sheet', ' data ops', ' frm', ' strategic initiatives', ' architectural design', ' cyberark psm', ' solr', 'green belt', ' geophysics', ' social service', ' awsazure spark', ' s3 data lake', ' aas', ' classic asp', ' prism', ' spinnaker', ' hadoop system', ' oracle', ' reports', 'azure developer', ' hpcm', ' otm', ' nutanix', ' software development', ' dhw', 'staffing', 'pmi acp', ' mortgage advisors', ' sparkpools', ' systems management', 'customer experience management', ' business improvement', ' proposal development', ' telecom engineering', ' qaf', ' data engineering consultant', ' x12', ' month end reporting', ' data management and analysis', ' mobile banking', 'bapis', ' cicd framework', ' infor', ' lamp', 'stored procedures', 'sql support', 'security compliance', 'db2', ' web crawling', ' sfdc', ' 5g', ' automatic speech recognition', 'deliver wireframe', ' sparkpyspark', ' primary research', ' relationship manager', ' product conceptualization', 'development', ' human rights', ' azure analysis', 'msbi', ' delta', ' devsecops', 'etl tool', ' product mgmt', ' firewall', 'varicent tool v9', 'ci / cd', ' compensation and benefits', ' mdp', ' international business', 'certified black belt', ' fact', ' adls sql server', 'lnb', ' profitability analysis', ' mass spectrometry', ' workload', ' mockito', ' peoplesoft accounting', ' scope', ' database maintenance', 'data factory', ' problem scoping', ' azure data - bricks', ' hp', '.net framework', ' design', ' financial reporting', ' negative news screening', ' engineering associate', ' ods', ' application programming', 'stattools', 'sql', 'adf', ' operations', ' aligne', ' equity analyst', ' workflow', ' fsi', ' ios', ' maintenance engineering', 'quality', ' seo analyst', ' snowflake architecture', ' data engimeer', 'ai/ml application', ' firebase', ' rest v2 connector', ' demand generation', 'delivery management', 'brd/srd', 'ip analyst', ' marketing automation', ' ms sql database', 'fabrication', ' mws', 'ssrs', ' secondary research', ' hvac', 'vpc', ' t-sql python', ' derivatives operations', ' pde', ' powershell scripting', 'financial accounting', 'saucelabs', ' is security', 'service now', ' azure data lake', ' microsoft sql server reporting services', ' us it staffing', ' chrome inspector', 'client development', ' controls', ' los', ' java 8', ' video analyst', ' lambada', 'team handling', ' product strategy', ' with num', ' j2ee', 'clinical coding systems', ' disciplinary action', ' jersey', 'application development', ' data entry operator', ' capacity planning', ' data streaming', ' tag', 'kong', ' synopsys', 'typing speed', ' talent acquisition', ' international taxation', ' bizible', ' marketing collaterals', ' regulatory affairs', 'sales operations', ' transformers', 'lead full-stack dev', ' prototype', ' sqls', 'quality audit', ' foreign language', 'relational sql', 'operational support', 'workflow management', 'statistical modeling', ' azure blob storage', ' database engineering', ' azure steam analytics', 'primary research', ' business advisory', ' hr reporting', ' ensighten', 'numby', ' plsql', ' e - commerce', ' good a compuing and excell shees is a must', ' lotus', 'health insurance', ' apache flink', ' informatica mdm', ' architecture', ' business research', ' transport management system', 'text mining', ' dataproc', 'distributed systems', ' springmvc', ' qualitative', ' vendor payments', ' informatica on cloud', ' hadoop scripts', 'arabic', ' strong analytical skills', ' azure data pipeline', ' diagnostics', ' linux shell scripting', 'nursing', ' windpro', ' implementation skills', ' oracle apps', ' equities', ' data warehouse applications', 'it project', ' data operations', ' nodejs', ' software developer', ' rdms database', ' credit risk modelling', 'algorithms', ' data analyist', ' beautiful soup', ' database queries', 'financial modeling', 'b2b solutions', ' lsa', 'spa frameworks', ' dispute resolution', ' project head', ' management systems', ' sat', ' crawler', ' payment processing', ' bayesian', ' hadoop map reduce', ' pub sub', ' mxnet', ' ebs', 'agile scrum', ' supplier development', ' microsoft azure', ' data capture cdc', ' release management', ' business modelling', ' tax analyst', ' mods', ' oral', ' pwf', ' hipaa', ' ci/cd concepts', ' java/python/scala', 'dts', ' msproject', ' technical reports', ' cad', ' sales coordination', ' ba', ' mcom', ' designing data ingestion', 'superset', 'financial analysis', ' datadog', 'veeva crm', ' bi development', ' supply chain', ' ms-dos', ' adf', ' aws or azure or google cloud', 'perl', ' spark developer', ' janusgraph', 'side', ' tableau software', ' technical publication', ' metrics', ' lambdas', ' sagemaker', ' linux environment', 'supply chain', ' iaas paas saas', 'sqoop', ' etl design', 'business transformation', ' cpq', 'of ms office', ' warehouse', ' glm', ' call monitoring', ' music scheduling', ' team building', 'isms', ' law', ' construction management', ' solution architect', ' market penetration', 'pivot table', 'sql database', ' alb', ' image analysis', 'analytical', ' modification', 'market data', ' wealth management', ' ites', ' etl jobs', ' cosmetics', ' oracle fusion middleware', ' engineering lead', 'performance optimization', ' business process management', ' gdpr', ' bi reporting tool', 'postgres database', 'safety training', 'data warehosue', '.net developer', ' value analysis', ' merchandising', ' account management', ' no-sql databases', ' python libraries', ' intrusion detection', ' w&b', 'etl development', ' cti', ' vlan configurations', ' microsoft azure paas', 'data factory pipelines', 'data steward', 'analysis', ' ibm websphere', ' octave', 't - sql', ' sns cloudwatch', ' uipath', ' capacity management', 'html', ' telecalling', ' saprk', ' manager quality assurance', ' system reconciliation', ' cost benefit analysis', ' ci - cd', ' ptp', 'product strategy', ' selenium webdriver', ' registered nurse', 'qlik sense', ' blueprism rpa', 'business research', 'javascript frameworks', ' informatica dq', 'data collection', 'ml engineer', ' windbg', ' customer segmentation', ' azure cloud technologies', 'collibra tool', ' diversity and inclusion', ' ms sql', 'statistical programming', 'azure data bricks', 'customer management', ' robotics', ' continuous testing', ' instructor', ' item data', ' config', ' data prep', ' prototype development', ' upselling', ' chemical engineering', 'spss', 'oracle ppm cloud', 'edd', ' pdf', 'hr data analystics', 'telecom', ' agm', ' sub', ' ecommerce', 'quality assurance', 'enterprise applications', 'modeling', ' scrapping', ' sqldw', ' anaplan', ' tam', ' financial statement analysis', ' r++', ' software delivery lifecycle', ' public speaking', 'sap erp', ' relationship management', ' mis preparation', 'dockers', 'object oriented design', 'alfresco', 'financial advisory', ' sql gcp', 'big data technologies', ' portfolio analysis', ' senior quality analyst', ' wireframe', ' business data analyst', ' load runner', ' accounting software', ' cost', ' datastores', ' android apk', ' production processes', ' distributed systems', ' large datsets', ' technical engineering', 'tcp\\\\ip', ' it', ' blob storage', ' root cause', ' design engineering', 'data lakes', 'python development', ' software application development', 'opensource tech stack', ' agile software development', ' formulation', 'development lifecycle', ' cloud pak', ' mdm solutions', ' data wrangler', ' model scoring', ' edw data models', ' java cloud', ' splus', 'nosql', ' fx', ' idt strategy analyst', ' team leading', 'vsphere 6 7', ' ccba', ' credit risk analysis', ' asset liability management', ' pys', ' web visualization', ' power bi dashboards', ' political knowledge', ' sql programming', ' python text', ' data model', 'druid', ' javascript', ' service marketing', ' administrator support', 'java/python/spark', ' pipeline creations', ' it recruiters', 'project life cycle', ' regression algorithms', ' technical advisor', ' enterprise applications', ' bdm', ' cnn', 'application integration', ' business support analyst', ' jee', 'mercurial', ' scada', ' sales support', ' data loss prevention', ' angular js', 'etl frameworks', ' enrollment analyst', ' machine learning models', ' biology', ' enrollment operations', 'good communication skills', ' hadoop spark', ' kubernetes', 'parquet', ' node . js', 'web service', ' redis', ' azure sentinel', ' data studio', ' jdbs', ' vsan configuration', 'software engineer/lead engineer', ' workday', ' ms bi', ' kusto', ' ms word', ' business analyst', ' top', ' occ', ' exception handling', ' luigi', ' salesnavigator', ' iso 20000', 'big data engineer full-stack developer company profile company name talent zone consultant', ' bfsi', ' kubernetes architecture and design', ' qa analysis', ' solaris', ' multiprocessing', ' it strategy', ' java programming', 'ms sql server dba', 'use cases', ' probability', ' distributed architecture', ' computer hardware', 'cro', ' associate analyst', 'call monitoring', ' aurora', 'buisness analyst', ' solar radiation', ' data visualization libraries', ' transition management', ' big data development', 'software packages', ' financial analysis', 'visual basic', 'load balancers', ' mobile app development', ' biodata', 'sr data engineer', ' mllib', ' production management', ' front end developer', ' databricks', ' assistant vice president', ' graph neural network', ' table partitioning', 'mako', ' project quantities', ' ing', ' kstreams', ' aws data engineering', ' management accounting', ' vulnerability management', ' hadoop services', ' informatica metadata manager ( imm', ' structured finance', ' linear programming', ' backup', ' db2', ' digital printing', ' dashboard', 'data engin', ' mba finance', 'redshift aws', ' downstream processing', ' regression testing', 'bidding', ' microsoft windows', ' stock market', ' commercial background', ' verbal written', ' webserver', 'hadoop ecosystem', ' infrastructure automation', ' fmcg', ' big data analyst', ' vice president', ' software analyst', ' memcached', ' enterprise integration', ' core python', ' c', ' competence development', ' data engineer', ' msexcel', ' new business', 'vista', ' nearest neighbors', ' adobe', 'public health', ' google cloud', ' management services', ' database design development', ' hofs', 'administration management', ' digital marketing analyst', ' production operations', ' app development', ' customer marketing', 'nig data', ' qlik', ' h20', ' retail sales', 'documents review', ' knn', ' people management', 'ms office suite', ' lucid', ' business rules', ' product quality', 'machine - learning', ' mobile app testing', ' computer proficiency', ' bash', ' mailbox management', ' java fullstack', ' gephi', ' rds postgresql', ' machine learning framework', ' oracle developer', ' alm', 'web analytic', ' wings', ' informatica data quality', ' telephony support', ' cypress', 'information system', ' business operations analyst', 'technical product configuration', ' client documentation', ' glacier', ' data visualizations', ' kyc operations', ' pyspark', ' cloud deployments', 'python frame', ' dropship', ' data analyst', ' microsoft net', ' cloud architecture', ' redshift', ' bot', ' system design', ' distributed computing', ' performance evaluation', ' control testing', ' scm', 'data engineering lead', 'private cloud', ' varicent cloud tool', ' shift incharge', ' ibm tivoli monitoring', ' soc', ' security configuration', ' sklearn', ' legal documentation', ' environmental impact assessment', ' source tree', ' data architectural', ' swagger', ' corporate planning', 'financial services', ' angular', ' propensity analysis', ' data ingestion cloud data management', ' cloud security engineer', ' health care domain', ' mechanical', 'written', 'change management', ' aera analytics and data quality', ' cloud hcm', 'azure machine learning', ' kpis', ' payroll processing', ' startup hiring', ' mlm', 'billing analyst', ' risklink', ' international travel', ' dictionary', ' salesforce administration', 'sql cloud', ' education', ' marketing programs', ' patent analysis', ' sun idm', 'golang', ' interpersonal communication', ' liquidity risk', ' version control system', ' business opportunity', 'pandas', ' credit derivatives', 'databricks', ' nmap', 'ecs', ' microsoft modern data', ' solid programming', ' event hub', ' partner management', 'helpdesk analyst', ' juniper', ' sap implementation', ' erwin', ' extraction', ' talend', 'automation testing', ' trade life cycle', 'hybrid framework', ' fullstack development', 'test case execution', ' azure databases', 'management systems', ' rest web services', ' python scripts', ' problem solving', ' configurations', ' sql server integration services', ' risk analysis testing', 'training methodologies', ' solutioning', ' graphana', ' sql querying', ' reliability engineering', ' p & l', ' informatica power center', ' marketing campaigns', ' extjs', ' gpus', ' informatica bdm', ' manual', ' azure synapse analytics', 'talent management', ' estimate', 'it skills', ' job evaluation', ' azure big data', 'mysql', ' jwt', ' technical design', ' aws data lake', 'cdn', ' redux saga', ' engineering design', ' mechine learning', ' consulting - bfsi', ' ml frameworks', 'epm', ' data egineer', ' ibm db2', ' computer architecture', ' health care benefit administration', 'digital marketing analyst', ' warehousing', ' market research', ' vision analytics', ' coo', 'arcfm', ' storyboarding', ' rice', ' deep ai', ' arcpy', ' big - data web services', 'ajax', ' hal', ' fund accounting', ' ctr', ' domo', ' inventory reconciliation', ' etl process', ' sales development', 'mendix', ' sas sql', ' project reports', ' apache', ' quantitative analysis', ' logistics', ' marketing', ' sap data services development', ' transform', ' clinical trials', ' azure stack', ' asp', 'process automation', ' ms office', ' cloud platforms', ' warehouses', ' sap retail', ' rfi', 'planning head', 'macos', ' resources', ' cisa', ' restify', ' e-commerce operations', ' ms bi stack', ' scheduling tool', ' excellent communication in english', ' pattern mining', 'delivery excellence', ' azure database data bricks', 'axiom', ' agriculture', ' functional support', ' maestro', ' etc', ' e-learning', 'fixed assets', ' closure', 'survey design', ' technical architect', 'transcription', ' big data technologies', 'item setup', ' azure services data factory', 'symantec', 'azure paas', ' azure data functions', ' supply planning', ' analysts', ' the hcp360 rep dashboard', ' oracle db', ' educational qualification', ' science', ' digital content', 'cloud security', ' icinga', 'logistic regression', 'ab initio', ' jar file creations', ' meltwater', 'it security', ' operations transformation', ' ad operations', ' neo4j', ' windows administration', ' object - oriented design', ' wi - fi network', ' customer acquisition', ' customer service orientation', ' external contractor sourcing', ' snowflake utilities', 'sql stored procedures', 'apache spark', ' call center operations', ' eventhub integration service', 'cloud technologies', ' oral communication', ' data governance', ' statistical tools', ' technical analyst', ' custom reports', ' restful services', 'testing', ' soap services', ' insight generation', ' cloud bigdata', ' test management', ' sqa', ' operations research', ' ifs', ' api design', 'docketing', 'database design', ' ios / android', ' cyber security analyst', ' api development', 'datorama', ' client onboarding', ' desktop engineering', ' with numbers', 'mongo db', ' financial planning and analysis', 'software design', ' unix administration', ' ggplot', ' strategic planning', ' server', 'rdbms', ' http', ' market research analysis', ' map reducer', ' tera data', ' accounting systems', 'financial transaction data', 'manager', ' azure sql server', ' access', ' azure aws', ' first mile', ' bootstrap', ' vrealize suite', ' solar energy', ' aws step functions', 'system architecture', 'kafka solutions snow flak data engineer big data hadoop hive hdfs data lakes', ' azure data science', ' content creation', ' enterprise data management', ' infrastructure modeling', 'big data developer', ' it recruitment', ' ddl', ' datacenter engineer', ' time series data', ' rxswift', ' lc-ms based experiments.', ' cpa', ' mis operations', ' manipulation', ' rightanswers', ' repository', 'associate analyst', ' clinical research', ' customer interfacing', ' tv', ' mlp', ' guidewire platform', ' demat', ' cloud data stacks', ' nltk', ' vmware administrator', 'edi', 'powr bi', ' mnc', ' functional requirement', ' cloud management', ' gis analyst', ' springboot', 'air touch stone', 'master data management', ' hosting analysts', ' sas di studio', ' oracle coherence', ' aws services', ' container', 'rpa technologies', ' ionic', ' unix/linux', 'hl7', ' proc import', ' expense analysis', 'plsql', ' veritas', ' client services', ' business applications', ' redshift db', ' iit', ' tenser flow', ' ms ssis', 'investment banking operations', ' international trade', 'management reporting', ' strategic partnerships', ' webfocus', ' azure sql warehouse', 'middle management', ' big data architect', ' se', ' boq', ' pub', ' open flow', ' financial modelling', ' engineering', ' petroleum', ' pl / pgsql', ' housekeeping', ' vba microsoft access', ' cash flow', ' service engineering', ' digital services analytics', ' data warehouse modeling', 'scrum', ' digital marketing', ' microsoft suite', ' microsoft power bi platform', ' pesticides', ' lateral hiring', ' reporting analytics', ' post sql', ' key management', ' projects', ' pyspark cloud / azure /aws /gcp / data scientist / data science', ' database developer', ' project billing', ' informatica etl', ' hiveql', ' tibco spotfire', ' rest framework', ' cd', ' apache server', ' data ware housing', ' bdd framework', ' technical lead', ' sales analytics', ' quality audit', ' sql& databricks', ' d3 js', ' query', ' qa', 'pattern recognition', 'bi testing', ' scala programming language', 'network administration', ' case', ' datarobot', 'data entry', ' listed', ' blended process', 'analytics consultan', ' strong communication skills', ' mobx', ' oops concept', ' clinical operations', ' performance testing', ' mdm', ' stat', ' unittest', 'quant analyst', ' mocha', ' clevertap', ' opennlp', ' statistics', ' mongodb.', ' financial statements', ' investigation', ' docker containers', ' insights formulation', ' workforce administration', ' azure core technologies', ' environment management', ' java application', ' libraries', ' marketing operations', 'big data', ' performance improvement', 'linux os', ' chromatography', ' pmo management', ' report management', ' informatica edc', ' web servers', ' master data', 'content writing', ' sms', 'acceptance testing', ' predictive modelingstatistical analysis', 'pl - sql', ' aws aws', ' operations executive', ' rshiny', ' technical architecture', 'micro - batches', ' sql apis', ' key skills', 'sperk', ' sftp', 'adls', ' aws/azure cloud', ' cloud spanner', ' copywriting', ' azure sql dw', 'powercenter informatica', 'generating reports', ' docker hub', ' ml cloud services', ' lr knn', ' cloudformation', ' good communication in english', ' data warehouse architect', ' data integrity', 'patch management', ' quality', ' data review', ' artificial intelligence', 'exploratory data analysis', ' behavior driven development', ' spring security', ' spark dataframe', ' qc', ' data center engineer', ' ci/cd pipelines', ' product life cycle management', ' mlflow', 'pivottables', ' core php', 'cloud data integration', ' iics', ' breeding', ' enterprise architecture', ' finance executive', ' cro', ' appexchange', ' addressing', ' real estate', ' emulator', ' project manager', 'inside sales', ' power bi tableau', ' software asset management', 'contact discovery', ' no-sql', ' asset accounting', ' budgeting', ' risk', ' global operations', ' strategy analyst', 'sql query writing', ' pyscala', ' postgres database', ' arden syntax', ' fcc', ' bagging', 'social media analysis', 'business strategy', ' lei', 'water treatment', ' customer service management', ' ms access', ' automation', ' cloud function', 'ux design', ' billing analyst', ' conflict resolution', ' data visualization', ' ms excel', 'coding', ' cme', ' data lake storage', ' functionality testing', ' critical thinking', ' tables', ' consulting', ' watson discovery', ' columnar database', ' aws core services', ' amazon ec2', ' software architect', ' power bi/tableau/ qlik', ' vfd', ' due diligence', ' advanced sales', ' statistical modling', ' http protocol', ' categorization', ' mmx', 'it facilities', 'api automation framework', ' management staff', ' sas programming', ' hr information system', 'design and development', ' fusion', ' flask api', ' credit analysis', 'jira', 'strategy implementation', 'database', ' azure cli', ' sonarqube', ' azure data lake storage', ' data warehouse development', 'resource assessment', ' bash scripting', 'elasticsearch', ' blue pumpkin', ' cloud computing', ' gtm', 'bank reconciliation', ' customer relationship', ' forensic', 'advance pl / sql', ' advanced java', ' microsoft power', ' online channel sales', ' aml svc', ' automotive', ' mvp', 'compliance', ' private equity fund', ' clinical development', ' serverless architecture', ' transformation', 'linux administration', ' ccar reporting', ' music production', ' unix shell scripting', 'gcp bigquery', 'senior manager', ' java web services', 'streaming', ' datorama', ' selenium web driver', 'idt strategy', ' investment banking operations', ' healthcare', 'web technologies', ' trouble shooting', ' wherescape 3d', 'product engineering', ' textblob', ' aws cicd', ' infrastructure security', ' portfolio performance', ' vendor manager', ' hpcc', ' apache beam', ' restful apis', ' spark and kafka', ' center of excellence', ' cma', 'svn', ' ids', 'product management', ' compile', ' risk compliance', 'test life cycle', ' web analytics', ' extract', ' product costing', ' soap api', ' fixed income', 'big data engineer', ' https', ' jdbc', ' page', ' bca', ' live commerce', ' pentaho', ' production engineering', 'autocad', 'clinical development', ' power sector', ' saql', ' big data ecosystem', ' gis', ' sas visual analytics', ' azure cosmos', ' linux os', 'security', 'linear regression', ' object - oriented programming', ' kedro', 'non voice process', ' panda', ' tcp/ip', ' spark databricks', ' lease lifecycle origination', ' embedded system development', 'msi', ' automation suites', ' karma', ' field operations', ' chemical analysis', 'it infrastructure', ' cryptography', 'foreign language', ' sap concur', ' presales', ' flow', ' qualtrics', ' reduxthunk', ' azure hdinsight databricks', ' yaml', ' mobile testing', ' performance', ' software engineer 1', ' product backlogs', ' content writer', ' structured data', ' mvc', ' market research and analysis', 'ui', ' dataops engineer', ' stp', ' accenture', ' svg', 'finance process', ' material-ui', 'oral', ' iim', ' nex think', ' oci', ' data security', ' etl testing', ' technical associate', 'informatica dq', ' communications', ' application security', ' front - end technologies', ' us shift', ' stlc', 'trouble shooting', ' abinito', 'jquery', ' time management', ' nmr', 'social media marketing', ' aws ml', ' erp system', ' etl automation', 'erp module', ' user research', ' apache tomcat', ' biomedical', ' content optimization', ' logstash', ' agile methodology', ' cloud foundry', 'it applications support', 'model building', ' hplc', ' finance manager', ' sharepoint', ' database implementation', ' auto finance', ' designing and developing compelling data visualizations', ' consultancy', ' content', 'business system analyst', 'django', 'synapse', 'reconciliation', ' avp', ' gpu', 'parking', 'data bricks', ' writing', ' java db technologies', ' autocad', ' factset', ' project analysis', ' project initiation', 'bpmn', ' pci dss', ' product managers', 'datalake', ' network operations', ' database integration', ' apache hadoop', ' aws codebuild', ' data base bigdata', ' qms', ' xcode ios', ' delivery lead', ' scientist', ' aws gcp', ' gradle', 'sap mm', ' aws database migration service', 'ml/dl', ' market place', ' block chain indexing', ' d3js', ' serverless com', ' algorithmic trading', ' segmentation', ' micro - services', ' certified agile scrum master', ' pa/om', ' statistical packages r', ' security management', 'financial markets', ' ml model development', ' julia', ' notebook', 'system maintenance', ' python / r', ' sql sql server', 'sap abap', 'communications', ' scss', ' presentation', ' systems analyst', 'automation framework', 'usage', 'react js pwa', ' bods', ' signal processing', ' ml modeling', ' jax - ws', 'splunk', ' hdfs', ' data parsing', ' grps', 'azure data', ' driver', ' matrix', ' trade processing', ' database', ' b2b', ' strategic insights', ' standard operating procedures', ' people management skills', ' secondary market research', ' or power bi', ' entry level', ' rtcp', 'aws serverless technologies', ' ci tooling', ' quality analysis', ' user interface', 'people analytics', 'report generation', ' data integration consultant', ' it business analysis', ' gst', ' tata', ' process mining', ' idea generation', ' graphics', ' machine learning libraries', ' prcess mapping', ' rdbms', ' data warehouse architecture', ' bigtable', 'artificial intelligence', 'ci/cd', ' work from home', ' sas base', 'omc', ' sas eminer', ' core sql', ' supply chain analyst', ' structured products', ' standardization', ' aws quicksight', 'clinical data management', ' splunk es', ' wcs', ' analytics consulting', ' story telling', ' ruby', ' finance', ' 3d', ' third party', ' t-sql', ' technical production support', 'financial sector', ' statistical analysis', ' azure event grid', ' credit officers', ' -', ' matillion', ' open studio', ' listening skills', 'servicenow hrsd', ' linkedin', ' middle level management', ' cloudsql', ' spark programming', ' cloud data security', ' etl architecture', ' informatica 9x', ' mi analyst', ' kyc associate', ' macro express', ' advanced git', ' resnet', 'cloud data environment', ' firehose data prep', ' mi', ' ml deployment', 'software development', ' retail merchandising', ' fresher', ' sas', ' rdms', ' ict spending trends', ' mathematics', ' fa', ' general insurance domain', ' information system', ' system integration', ' big data analytics', 'informatica axon', ' applied intelligence', ' engineering manager', ' keras', ' open refine', ' data classification', ' iso 9001', ' consumer insights', 'senior financial analyst', ' serverless', ' people technology analyst', ' aps', ' oozie', 'electrical engineering', 'lead architect', ' its', ' balsamiq', ' gcp and aws', ' glmgam', ' aws data', ' sap services', ' assets', ' field testing', 'reports', ' cuda', ' azure data lake/delta lake', ' debt collection', ' data pipeline architecture', 'tcp', ' building application', ' human capital', ' clustering', 'spring boot', ' product research', 'iot', 'collibra', ' sql seam framework', ' business services', 'object - oriented concepts', ' cce', 'automobile engineering', ' investment management', ' fhir', ' bug tracking systems', ' business consulting', ' qlik script', 'senior data scientist', 'oracle db', 'dax', ' pl / sql programming', ' malware dos', ' review', ' problem - solving', 'container', 'redshift', 'java tech stack', 'financial risk management', ' integration services', 'data developer', ' jpa', 'product development', ' arm templates', 'microsoft power bi', 'dwh desing', ' database security', ' azure streams', 'software engineer - data center', ' program delivery', ' database fundamentals', ' microsoft', 'blockchain', ' banners', ' docker', ' database modeling', ' hilt', ' data analytic', 'hp data protector', 'data reporting', ' model building', ' product roadmap', 'cloud formation', ' leasing', 'data etl', 'random forest', ' iss', ' project coordination', ' sap data & development', ' high level design', 'angular 9', ' service operations management', 'verbal', ' opex', ' data warehousing', 'ec2', ' data factory architecture', ' bi intelligence', 'secondary research', ' wms', ' continuous delivery', ' amazon web services', \" sms api's\", 'ms - office', 'backend', ' platforms', 'eno - avp # 203270', 'data mining', ' denodo', ' business process', ' mutual funds', ' cloud dataflow', ' ecommerce industry', 'emblem', ' sap data services', ' planning', ' deployment', ' service management', ' multivariate analysis', ' oracle dba', ' ui ux development', ' team management', ' scala and python', 't', ' big data developer', ' android', ' test analysis', ' system sql', ' mentor graphics', 'apache airflow', ' reuters', 'adobe analytics and rpython', ' software architecture', 'fraud analysis', ' market and analysis', 'information technology', ' excel skills', ' helm', ' international sales', ' macros', ' market research analyst', ' banking products', 'robotics process automation', ' payroll', 'data archtect', 'google analytics', ' process quality', ' project control', ' digital advertising', ' networking', ' elasticsearch', ' azure store', 'salesforce', ' bank loan', 'dask', ' aws api', 'business and process analysis', ' lisp', 'sql programming', ' visio', 'apptus', 'ee deployment', ' data development', ' bi reporting', ' project monitoring', ' openshift', ' assembly backend operations', ' google ai platform', ' cloud pubsub', ' quality standards', 'data services', ' display advertising', ' java developer', ' aviation analyst', ' codedeploy', ' audio visual', ' gcp dataflow', ' fpna', ' credit analyst', 'conceptual', ' gpdb', 'c', ' exploratory analysis', 'waterfall', ' rest', 'client servicing', ' hr', 'objective c', 'mapreduce', 'ci/cd jenkins', ' mobile marketing', ' gcp hadoop & hadoop', 'performance calculations', ' impala', ' rails', ' dimensional modeling', ' clearing', ' caffe', ' google data fusion', ' develop', 'mob', 'natural resource management', ' credit card firm', ' research analyst', 'ldm', ' illustration', ' fto', ' coding', ' data pre', 'azure sql server', ' gds data analysis', ' business system', ' odbc', ' corda', ' boot', 'accounts payable', ' test', ' hudson', ' microsoft powerpoint', ' relational', ' html', ' lambda aws', ' process documentation', 'agile', ' data manipulation', ' ci & cd using jenkins', ' cloud watch', ' salt', ' aws cloud services', ' big data applications', ' dl', ' individual contributor', ' capital modelling', ' python core development', 'publishing', 'oracle data integrator', ' teradata sql', ' qualitative analysis', ' fsldm', ' business studies', ' ability', 'metrics reporting', 'charts', ' api', ' azure data services', ' internal auditor', ' senior manager finance', ' integrated marketing', ' artificial inteligence', ' natural language', ' scikit-learn', ' clinical management', 'cloud data protection', 'bi', ' rest services', ' aws data ops', ' project design', ' etl framework', ' mom', ' advocate', ' cors', ' web application', ' crf', ' afc', ' cash flow statement', ' signalling', ' customer satisfaction', 'digital analytics', ' qa data engineer', ' sql db', ' mrdcl', ' mediclaim', ' monitoring and logging', ' kanban', ' load balancing', 'mis', ' visual studio', ' rest apis', ' power electronics', ' data integration', 'customer segmentation', ' investment portfolio', ' epos', ' spark streaming', ' personnel management', ' marketing executive', ' operations leadership', ' hivemall', ' retail analysis', ' transition', 'design engineering', 'spotfire', 'iso', ' administration management', ' random forests', ' hosting services analyst', ' wildfly server', ' large datasets', ' client retention', ' service assurance', 'business analyst', ' compliance monitoring', ' lead operations', ' delta lakes', ' promotion planning', ' actuarial', ' deep learning modeling', 'scrapy', ' flex', 'react js', ' .', ' store management', ' elastic mapreduce', ' kubernetes microservices', ' google sheets', ' asp net', ' web frameworks', 'nodejs', ' injection moulding', ' data administration', ' data engineering tools', ' vpc', ' testng', 'customer acquisition', ' science libraries', ' business case development', ' rewards', ' aws glue', 'prototype development', ' maximo', ' application support', ' vendor', ' data management analyst', ' sla', ' executive', ' lead software', ' data designer', ' analyst 1', ' spring mvc', ' key accounts', ' new business development', ' server management', ' pentaho data integration', ' hris', 'spring framework', ' principal investigator', ' idq developer', 'big data frameworks', 'paas', ' data platform - bengaluru', 'deep learning', ' rabbitmq', ' internal audit', 'forex', ' mule services integrations', ' loading', ' product support analyst', ' cloud environment', ' tools', ' data acquisition', ' data loader', ' testing tools', ' telecom billing', ' python microsoft office', ' sprinklr', ' entertainment', ' react frame work', ' variance analysis', 'mq', ' business communication skills', ' it risk management', ' azure streaming analytics', ' archiving', ' uft', 'code', ' zeplin', ' azure public cloud', ' atos', 'object oriented programming', ' mts', ' outsourcing', 'data visualization', 'application design', ' zookeeper', ' machine learning model', ' aws data warehousing', 'decision sciences', ' review analyst', 'oops', ' clinical data', ' data / business analysis', ' product support', ' sales head', ' redash', 'quality analysis', ' gremlin', ' open source technologies', ' data loading', 'payment processing', ' tcp / ip', 'microstrategy', 'bash', ' intern', 'rabbitmq', ' professional services', ' tez', ' go', ' mload', ' ni-fi', ' ppt', 'underwriting', ' aws database migration', ' content strategy', ' penetration testing', ' travel agency', ' blog writing', ' security monitoring', 'teradata', ' product based', 'unstructured data', 'information security analyst', ' content writing', ' data stage', 'power bl', 'bigdata technologies', ' api automation', 'bigdata', ' credit cards', ' msmq', ' apache pyspark', 'macros', ' html5', ' lifecycle', ' star schema', ' dbase', ' fresher graduate', ' emc', ' good analytical', ' etl performance optimization', ' automate data access', 'sagemaker', ' autosar', ' commercial strategy', ' stash', 'product quality', ' management reporting', ' healthcare domain', ' resource mobilization', ' restful web services', ' cloud trail', ' web hosting', 'html 5', ' excel powerpoint', ' aiml', ' quality audits', ' policies', ' google big query', ' law enforcement', ' edms', ' apigee', ' script writing', ' object - oriented /', ' network infrastructure', ' market study', ' non-voice process', ' junior staff', ' winforms', ' jda esp', ' alteryx deginer', ' network design', ' microsoft certified professional', ' deal', ' technical operations', ' tware', ' db queries', ' automation anywhere', ' msa architecture', ' bayesian networks', ' rdbmss', ' workforce planning', ' hr data analyst', ' aws data migration', ' analyze data', ' data quality management', ' android framework', ' it asset mgmt', ' cloud infrastructure data engineering', 'interfaces', ' product data management', ' operating model', ' data analysis/visualization', ' digital marketing executive', ' software development manager', 'analytics reporting', 'base sas', ' hp load runner', ' mobile application testing', ' audience segmentation', ' eba', ' technical specifications', ' zephyr', ' qs', 'ppc', ' beam', ' oracle financials cloud', 'bi tools tableau', ' excel ecc', ' dispute settlement', ' hp data protector', ' sap ecc', ' hqlexposure to bi tools', ' asp.net', ' qlik sense', 'sql database queries', ' data engineering', 'ruby rails', ' stream', ' visual basic', 'career development', ' food technology', ' it executive', ' qa lead', ' linux scripting', ' hyperion financial management', ' aws iaas', ' iot application development', 'regulatory reporting', 'graphql', ' lex', ' pig designing', 'relational databases', ' data entry operation', 'web analytics', ' sns', ' junit', ' navicat', ' lda', ' data center', ' problem', ' integration analyst', ' fortran', ' net', ' netezza', ' microsoft word', ' cosmetology', ' togaf', ' client interfacing', ' load balancar & storage', ' micro - batches', 'ci tooling', ' mobile applications', 'saas deployment', ' data bricks', ' data aggregation', ' bigdata scala developer', ' camunda', ' oracle data analyst', 'eco', ' guidewire claims', 'process design', 'relational data', 'business analysis', ' core and advance python programming', ' r', ' hadoop data management', ' . net', 'ssis packages', ' raw material', ' quality improvement', ' network data mover', ' regression', ' node js', ' ipr', ' os internals', 'django framework', ' quality reviews', ' sap r', 'industry research', ' simulink', ' sales force', ' regulatory data requirements', 'campaign management', 'ms office', ' integration php', ' pharmacology', 'data visualisation', ' model build', ' fastexport', ' sales process', ' gc', ' facility management', 'go lang', ' operations analyst', ' complex', ' sqlpools', 'gradle', ' technology leadership', ' company analysis', ' procurement', ' java script', ' data migration strategy', ' relationship executive', 'emr', ' web application development', ' stores', ' data build tools', ' hcpcs', ' content management system', ' azure data engineering', ' maintaining servers', ' microsoft dynamics', 'aws/azure', ' product testing', ' us staffing', ' server hardware', ' process audit', ' product roadmaps', ' cycle time reduction', ' spark', 'database designing', ' claim adjudication', ' hp al', ' model validation', ' decision tree', ' data cataloguing', 'star schema', 'data manipulation', ' investment research', ' datafusion', 'scala developer', ' junior analyst', 'apache nifi', ' high throughput computational screening', ' spectrum', ' basel iii', ' general statistics', ' mvc frameworks', 'sr. db dev', ' dataset', 'rest api development', ' mis executive', ' data ingestion', 'metadata extraction', ' aws s3', ' industry research', 'ios development', ' process operations', ' swift', 'data architectures', 'xml', ' kernel', ' sales support analyst', ' postman api', 'pdf', ' quality management', ' complex sql query', ' oral communications', ' ml cloud', 'aml', ' 524', ' microsoft web development', ' knime', ' hadoop ecosystem', ' cordova', 'information security management', 'word', ' outbound', ' amplitude', ' it management', ' recruitment lead', ' sas analyst', ' unix os', ' gke', ' development manager', ' my sql', 'reporting', ' sales presentations', ' internet research', ' group product manager', 'social media', ' data structure', 'business planning', ' customer service', ' java azure', ' project tracking', ' life sciences', ' object oriented analysis', ' azure devops', ' postgres', ' system integration testing', ' marketing data analysis', ' hrms operations', ' callidus cpq', ' test scenarios', 'azure analytical', ' public health', ' cloud composer', ' mathematica', ' batch programming', ' corporate trainer', ' customer management', 'order management', ' css5', ' analytics development', ' application deployment', ' level', 'solution architecture', 'advance excel', ' qualitative research', ' kerberos', ' numpy', ' messaging', ' storage', ' datastructure', ' co - cca', ' lead nurturing', ' hadoop 2', 'it risk', ' microsoft sql development', ' sql server analysis services', 'zookeeper', ' big data hadoop', 'analyzing information', ' data maining', 'outbound', ' devops methodologies', ' bigdata', ' mechanical fresher', ' mlt', 'open end coding', ' dnn', 'r skill', ' mongodb', ' blue prism', ' creative', ' regulatory requirements', ' fraud detection', ' data standards', ' anova', ' rfq', ' customer focus', ' oracle hcm cloud', ' apache kudu', ' software engineer', ' senior research analyst', ' memsql', 'go', ' user experience', ' ansible automation', ' coordinating', 's4 integration', ' user acquisition', ' cohesity', ' sentiment analysis', ' eks', ' audacity', ' information analysis', ' powertrain', ' chef', ' slq', ' client interaction', ' p&l understanding', ' concur', 'jenkins', ' identity management', ' data integration patterns', ' sas enterprise', ' social research', ' ieee', 'retail', 'c++', ' de novo prediction', 'english', ' product requirement documentation', 'informatica edc', ' malayalam', ' azure adx', ' web scraping', 'rf', 'etl/mysql', ' sql.', ' aiohttp', ' content delivery', ' fundamental research', ' performance analysis', ' primavera', ' team player', 'capital markets', ' java & lambdas', ' azure automation', 'wastewater', 'dashboards', ' senior management', 'stats modeling', ' basic statistics', ' business associate', ' reports extraction', ' industry reports', ' psychiatry', 'sap pm', 'query optimization', ' it skills', 'datawarehousing', 'manpower planning', ' r shiny', ' financial operations', ' healthcare research', ' dmco', ' predictive analytics', 'amazon connect', 'cloud architecture', ' oic', ' senior associate business analyst', ' csm/cspo', ' cloud data lake', ' mis reporting modules', ' pub - sub', ' python data', ' \"r\"', ' german', ' j soup', ' guard duty', ' arm processor', ' python script', ' patents', 'market risk', 'data presentation', ' mathematics and science background', ' athena databricks', ' azure event hub', ' database performance tuning', ' it support', ' password management', ' neural network methodologies', 'analytics', ' business excellence', ' api frameworks', ' comm', ' interpretation', 'b testing', 'data stage', ' cloud big query', ' business english', ' sap crm', 'powerpoint', ' vp', ' qualtrics ux', ' deep learning models', ' odata', ' open source', ' machine analytics', ' aso', ' purview', ' hive base', ' apache hive', ' postgres mongodb', 'cloud services', 'assembly language', 'trading settlements', ' risk reporting', ' junior executive', ' hr executive', 'data integration', ' sql dw', ' sap sd', ' mental health', ' reduce', 'kafka event bus', ' qa analyst', ' cloud data warehouses', 'work force management', ' ibm datastage', ' optimizing code', ' technology management', ' bi/dw', ' sac', ' quality assurance', ' java 6', ' it consulting', ' lakes', 'credit analysis', ' analytics', 'data pipeline', ' min', 'databases', ' base sql', ' migration', 'gcp cloud', ' software development engineer ii', 'jms', ' azure sql dw / synapse', ' resource planning data', ' quality control analyst', ' t - sqle', ' sheet metal', ' cloud data quality', ' mobile handset', 'power bi desktop', ' oracle 10g dataguard', ' cloud application development', ' vibration analysis', ' business banking', ' data process anaylst', ' rnn', ' data governance roadmap', ' night shift', ' data scientists', ' mba', ' ai', ' ca erwin', ' cloud front', 'ai', ' agribusiness', ' network management', ' analyst 3', ' equity market', ' cloud architect', ' aws dms', ' annual reports', ' cloud data architecture', ' talent management', ' operation', ' xgboost', ' data structures', ' data framework', ' quality review', ' ticketing', ' linguistics', ' etl tuning', ' schema design', 'nlp', ' database optimization', ' metrics analysis', ' backbone js', ' computer application', 'opt', ' product catergorization', ' data conversion', ' vb', 'sql queries', ' pipeline', ' deduction', ' system interaction design', ' etl scripts', ' retail', ' data transformation', ' vehicle', 'webpack', ' molecular dynamics', ' medicaid', 'bills payable', ' international voice process', 'ai/ml algorithm', 'speech mining', ' asr', ' salesforce', ' learn', ' proficient in aws redshift', 'shell script', ' cloud formations', ' cmmi', ' .net', ' c#.net', ' gis data engineer', ' lua', 'sas model development', ' azure data warehouse', ' jinja 2', ' automate etl', ' mbbs', ' ibm watson', 'netsuite', ' google cloud data', ' lambda', ' process control', ' training needs', 'python/java/nodejs', ' algebra', ' store operations', ' brokerage', 'sdfc', ' salesforce.com', ' database management system', ' ux design', ' azure data flow', 'and hadoop', ' edtech', ' msc', 'visualization technologies', ' inventory management', 'pypark', ' development management', ' sales report', ' surveys', ' pos', ' architectural diagrams.', ' sql coding', ' ar', ' product adoption', ' petrochemical', 'investment banking', ' bim', ' advance sql', ' statistic modelling', ' big data infrastructure', 'itsm', ' technical writing', ' unix scripts', ' hoovers', ' process orientation', ' r libraries', ' transaction s', ' mysql and postgresql', 'hbase', 'azure devops', ' managerial accounting', 'microsoft powerapps', ' service tax', ' er/studio', ' campus recruitment', 'advanced sql queries', ' logical and physical data modeling', ' biostatistics', 'batch processing', 'object - oriented programming', ' kyc', ' azure data storage', ' utilities', ' ms power point', ' sql queries', ' channel sales', ' phonegap', ' ui script', ' ldatopic modeling', ' process modeling', ' radiology', ' negotiation', 'nutrition', ' teradata bi', ' support', ' present analysis', 'cism', ' r / r#', ' modern architecture', ' abinitio', ' excel report preparation', ' engineer', ' spreadsheets', ' sql server reporting services', ' mq', ' mongo', ' lte', 'web application development', ' mpi', ' data42', ' export import documentation', 'structured data access control', 'architect', 'data quality developer', ' frd', ' bidding', ' java backend', ' linear regression models', ' intellectual property', ' quality check', ' google big', ' after - sales', 'multithreading', 'financial concepts', ' enterprise cloud', ' business transformation', ' sql+', ' aiops', ' problem analysis', ' python scripting', ' personal loans', ' oscilloscope', ' lsmw', ' framework', ' technical support', 'ba artifacts', ' chat', ' customer engagement', ' relational modeling', ' data management tools', ' data anlalytics', ' minitab', ' company secretary', ' paas', ' toad', ' object - oriented / object', ' it transformation', ' biotechnology', ' flexcube', ' ml ops', ' social media marketing', ' nagios', ' hive sql', ' flask', ' semantic hashing', ' clinical coding', ' data mart strategy', ' deep learning frameworks', 'google tag manager', ' estimation', ' management skills', ' orm', ' publishing', 'hadoop administration', 'computer languages', ' data queries', 'talend', 'experimental design', ' data project', ' react native', ' dataflows', 'sap data & development', ' data modeler', ' hive impala', 'mainframe', ' quality inspection', 'operations support', ' dpdk', ' adl etf', ' risk functions', ' ssis', ' brd', ' spring framework', 'elastic search', ' client projects', ' infotainment', ' dtp', ' brandwatch', ' data integration tools', ' var', ' genomics', ' analyst mi coe', 'medical researcher', 'cloud', 'team operations', ' symantec', ' compensation analyst', ' kubernates', ' ms visual studio', ' weaving', ' customer service delivery', ' quality monitoring', ' campaign audience engineer', 'image processing', ' project migration', 'flink', 'manual testing', ' dynamodb', ' python data analytics', ' sox', ' tickstack', ' js rest api', ' scope management', 'no sql', ' bip', ' test - driven development', ' hudi', ' governance', ' html / css', 'data warehouse', ' azure analysis services', 'data bricks delta lake', ' sales operations', ' statistical analyses', ' data requirement gathering', ' database analysis', ' asset allocation', ' data automation', ' trading settlements analyst', ' iam cloud operations', ' reporting and analytics', ' quantitative modelling', ' it marketing', ' data', ' pattern recognition', ' cucumber', 'sap master data', ' router', ' elastic search solr', 'monthly reports', ' ims data', ' problem-solving skills', ' kubernetes services', ' etl cloud', ' dataset wrangling', ' amazon cloud', 'problem solving ability', 'sql coding', ' bigdata developer', 'allegro', ' problem-solving', ' write complex', 'it', 'frs', 'cash management', ' ict', ' object oriented analysis & design', ' back office executive', 'crm implementation', ' feedback', ' aws emr', ' security services', ' aws-emr', ' data preparation', ' performance management', 'backup management', ' hadoop', 'time management', ' finance analyst', ' technical interviewer', ' application development', ' people analytics', ' process flow diagram', ' sic', 'internal audit', ' powerpoint', ' financial analyst', ' statistical analytics', ' rest controller', ' cms', ' threat analyst', ' english writing', ' cleint onboarding', 'product analytics', 'quality monitoring', 'microsoft azure data services', ' google kubernetes engine', ' cocoa touch', ' cmms', ' idq logs', ' economics', ' data science libraries', ' distributed data processing', ' advance excel', 'web crawling', ' object detection', ' product development', 'vsts', ' manager quality control', ' ivr', ' sales analyst', ' grafana', ' cxo', ' informatics', ' clinical coder', ' dotnet', ' seo', ' report', 'cplex', ' financial projections', ' data support', ' niche skill hiring', 'cce', ' financial instruments', ' polaris', ' rsa', ' scripting languages', ' robot framework', ' cloud', 'machine learning', 'technology recruitment', ' python and open source libraries and tools such as numpy', ' google apis', ' accounting', ' sales cloud', ' spark stack', ' electronics', 'bi tools', 'postgresql', ' apache avro', ' complex analysis', ' translator', ' revenue cycle management', ' business administration', 'diversity and inclusion', ' point cloud data', ' big data engineering', 'software development life cycle', 'economic analysis', ' room', ' emergency response', 'application support', ' protegrity', ' advertising management', ' mice', ' invoicing', ' customer centric', ' design review', ' spark nlp', ' underwriting', ' mathematical optimization', ' relativity', 'bi flows', 'client management', ' bi tool', ' cbap', ' analyst ii', 'process analysis', ' data scinetist', ' css3', ' typography', ' unit test', ' credentialing', ' security', ' software engineer ii', 'web application testing', 'predictive modelling', ' ab testing', 'aml pipeline', ' visualizations', 'ms azure data management', 'nlp and dialog systems', ' amazon redshift', ' datagovenance', 'jupyterlab', ' netcool', ' pyspark api', 'olm', ' big data analysis', ' riversand', ' excel functions', ' web api', ' teradata', ' site operation', ' primary skills', ' advanced excel macros', ' structure visualization', ' nlp', ' primary market research', 'micro services architecture', 'resource capacity forecasting', ' apptus cpq', ' succession planning', ' ios native', 'ftp', ' build automation', ' structured analysis', ' test data maker', ' sql databases', ' java framework', ' hardware', ' maintaining servers of the company', 'board design', 'forecasting', ' scripting language', ' regulatory compliance', ' singleton', ' ms - office', ' oracle edw', ' rxjava', ' organization and co-ordination skills', ' para legal', ' eda deep sql', ' relational data modeling', ' quality lead', ' associate quality analyst', ' etl processes', ' valuation', ' renewable energy', 'scikit-learn', 'mendix platform', ' b2c', 'object - oriented development', ' recruitment', ' bangalore', ' azure sql datawarehouse', 'a&pp', ' recommendation and forecasting', ' aws data pipelines', ' java software engineer', 'ap reconciliation', ' product promotion', 'vba', 'research analysis', ' servicenow', ' stack systems', 'rsa archer', ' backend developer', ' decision trees', ' srs', ' sql server management studio', 'mqtt', ' logility', ' statsmodels', 'azure big data', 'talend etl', ' mvc architecture', ' microsoft office', ' product presentation', ' case studies', ' s4 hana', ' room database', ' gcs', 'recruitment executive', ' hrd', ' account', ' instrumentation', ' data interpretation', ' azure iot', 'designing and implementing', ' surgical', ' subject matter expertise', ' functional testing', ' core data', ' customer care', 'database management', ' nosql dbs', ' saas', ' shiny', ' ticketing tool', ' cloud solutioning', ' mortgage', ' arima', ' atlassian', ' actuarial analyst', ' figma', 'business intelligence tools', ' team spirit', ' cloud erp', ' data analytics', 'business analytics', ' object c', ' vapt', ' engineering analyst', ' pysprk', ' dbt', ' pay', ' google automotive services', ' project delivery', ' cloud data visualization', ' test analyst', ' xpresso', ' aws cloud analytics', 'data quality', 'project development', ' quantitative research', ' data fusion', ' cicd pipeline', ' lambda architecture', ' vsphere 6 5', ' green belt', ' factor analysis', ' autolayout', ' project operations', 'team management', ' interviewing', ' jira', 'requirements analysis', ' fraud analyst', 'regression modeling', ' cards', ' talend big data', 'ns', ' banking general', ' enterprise content management', 'se', ' database design', ' lake', ' microstrategy', ' axiom controller', ' data pipeline', ' ado', ' business design', 'orchestration', 'seo analysis', ' crm analytics', ' mantas', ' ich-gcp guidelines', 'legal compliance', ' entity extraction', ' accounting standards', 'rest', 'seaborn api', 'nlp python/r pyspark cloud /azure aws gcp data scientist data science', ' data pre processing', ' kinesis', 'aws athena', ' boomi', ' marketo', ' big data', 'business acumen', ' mathematical modeling', ' visual communication', 'sap s/4hana', ' ddos', ' software qa', ' power pivot', ' early life support', 'communication', ' document checking', ' enterprise software', ' research and development', ' hyperion', ' j2ee stack', 'engineering', 'powershell', ' attention to detail', ' spring frameworks', ' pub / sub', 'azure data forms', ' ms - excel', ' asme pressure vessel code', ' information research', ' microsoft stack development', ' fraud modelling', ' aws pyspark', ' python development', ' spark rdd transformation', ' analyticssoftware services', 'ms access', ' cosmos', ' market risk', ' private cloud', ' microsoft sql', ' multi - platform', ' policy', ' as / 400', ' axon', ' data collection systems', 'product analyst', ' get', ' sales analysis', 'numpy', ' webservice', 'communication skills', ' cost analysis', ' adv excel', ' weblogic', 'retail analytics', ' focus', ' client reference data', 'business reporting', ' remedy', ' shell scripts', ' collateral management', ' relationship', ' etl', ' microsoft bi', ' snowflake db', ' video processing', ' relationship building', 'housekeeping', 'mobile testing', ' sql dba', ' billing', 'lab data manager', ' ai ops', 'azureml', 'field operations', ' problem management', 'ubuntu', ' image processing', ' workflow management', 'market analysis', 'oo', ' pricing analysis', 'product launch', ' laravel', ' sprak', ' design conceptualization', ' microsoft azure data lake storage', ' tlm', ' insurance claims', 'data extraction', ' blackline', 'fp & a', ' otc', ' sql development', ' back-end', ' ibm', 'bill of lading', 'data ingestion', ' merchant acquiring', ' micro services', ' ansys', ' rs', ' epm implementation', 'training', ' eclipse', ' tableau online', ' 2g', ' csv', ' lead developers', ' advance sql queries', ' cloud formation', ' capital iq', ' hc analytics', ' payment systems', ' ehr', ' data visualization techniques', ' data query languages', 'r shiny', ' business finance', ' data - intensive', ' quicksight', 'yarn', ' head business development', ' user support', 'software engineering', ' sme finance', 'sales analysis', ' business growth', ' power - bi visualizations', 'stock exchange', ' process', ' core finance', ' text mining', ' olap', ' psychology', 'server', ' etl developer', ' issue resolution', 'azure', ' skylearn', ' fixed income markets', ' application software support', ' dashboards', ' 2d', ' service level adherence', ' activemq', 'linux/ c++ - l2 support', ' freight forwarding', ' object - oriented / scripting', ' servo motors', ' senior manager', ' azure ml studio', ' sql server administration', ' tpus', ' san switch', ' adsf', ' etl frameworks', 'video editing', ' investment banking', ' sql data', ' application testing', ' servo', ' bom', ' sql data warehouse', ' toefl', ' sap cloud platform', ' alteryx tableau', 'good communication in english', ' executive leadership', ' web proxies', ' parquet', ' prometheus', ' supervisor', 'git', ' maria', ' report modification', ' tfs', ' associate risk analyst', ' c++', ' wireless protocol', ' data scalability', ' data businesss analyst', 'risk reporting', ' stanford nlp', ' documentum', 'machine dynamics', 'biotechnology', ' aws rds', ' product analyst', 'chartered accountant', ' celonis', ' quality analyst', 'unit testing', ' mathematical analysis', 'hive', ' software associate', ' ci cd pipeline', ' excel data management', ' amazon elastic map reduce', 'b2b sales', ' visualisation', ' microsoft project', ' database creation', ' management', ' predictive modeling', ' marketing analytics', ' chatbots', ' opengl', ' test engineering', ' powerdesigner', 'lead generation', 'database administration', 'ibm cognos tm1', ' oracle erp', ' ipro', ' claim processing', ' sales administrator', ' mobile automation testing', ' microservices', ' kafka architecture', 'blobs', ' articles', ' ds algo', ' spring', ' postman', 'graph db', ' user management', ' marketing initiatives', ' appliances', ' nginx', 'administrative assistance', ' sqoop', ' amazon documentdb', ' lucene', 'computer visions', 'direct marketing', 'dataa analyst', 'cloud environment', ' database management', ' databricks design', ' axon salesforce', ' clinical research associate', ' copy writing', 'cybersecurity', ' data engineering/ db developers', 'basic', 'technical architect', 'tax analyst', 'com', ' xform', ' svnci', 'edc', ' aws data services', 'content creation', ' senior technical lead', ' micros services architecture', ' business plan development', ' springboot java', ' azure dev ops', ' bant campaigns', ' conducting', ' analyse', ' jamf', ' sap business one', ' drug discovery', ' windows server', 'algorithm development', ' oracle teradata', ' ms azure', ' financial risk management', ' build management', ' kafka cloud', ' argo', ' kotlin', ' system administration', ' embedded systems', ' datamodelling', ' customer service operations', ' data analysis skills', ' credit card analytics', ' service', ' leadership development', ' catastrophe risk analysis', ' code review', ' big data pipeline', 'design', ' azure modern data platform', ' remote support', 'office', 'operations research', 'statistical model building', 'statistical analysis', ' skills', 'aws s3', 'learn more', ' sailpoint', ' distributed data system', ' java plus', 'integration testing', ' edi', ' cloud data framework', 'hyperion essbase', ' ai solutions', ' failure analysis', 'test strategy', 'revenue generation', ' udb sql', ' techno-savvy', ' demand analysis', ' express', ' dlp', ' graphql', 'odi', ' stakeholder management', ' google cloud platforms', ' data visualization tools', ' supply chain management', ' metaflow', ' rca', ' power apps', ' senior analyst', ' openair', ' ibm cdc', ' azure databricks', ' map - reduce', ' tableau public', ' microsoft sql server', ' no - sql', ' dropwizard', ' export import', ' pl / sql automation', ' lstm', 'cassandra', ' databricks stack', 'scripting', ' crm', ' iam', ' dermatology', ' cv', ' dw', ' data cleaning', ' revenue management', ' azure developer', 'kotlin', ' debt investment', ' sourcing', ' avro', ' component lifecycle', ' credit card domain', ' retail banking', 'maths', 'data validation', ' seamless ai', ' ml modelling', ' cloud service', 'pyspark.', ' algorithm', ' feature build', ' big data platforms', ' inspection', ' security operations', 'development management', ' aws big', 'seo', ' azure functions', ' aws sagemaker', ' mistake proofing', ' tat', ' project/program management', 'ticketing', ' axure', ' business / systems analysis', ' exm', ' whodrug', ' philosophy', ' database marketing', ' service quality', ' power management', ' json web token', ' stored procedures', ' thymeleaf', ' big', 'business intelligence reporting', 'statistical data analysis', 'spark programming', ' azure datalakes', ' reltio', ' bank accounting', ' microsoft azure devops', ' bigtable cloud sql', ' payment gateway', ' redhat', ' singlestore', ' ui development', ' micro - service architecture', ' kstream', ' product sales', 'distribution system', 'umap', ' polybase', ' personal lending', ' hadoop ecosystems', ' vertex peoplesoft', ' hospitality', 'leadership', 'mongodb', ' integeritty', ' wpf', ' pheonix', ' process management', 'quality standards', ' sap analyst', 'manufacturing', ' advanced analytics', ' customer handling', ' html 5', ' cash collection', 'mocha', ' creating data architectures', ' microsoft development lifecycle', ' assistant business analyst', ' sap fico', ' speech recognition', ' restful', ' ibpm', ' corporate intelligence', ' android app', ' ci & cd', 'training delivery', ' data migration analyst', ' ich-gcp', 'trade', ' valgrind', ' wmi', ' sybase', ' private label', 'cobol', ' spare parts', ' dax', 'programming', ' digital media', 'matlab', ' sql database design', ' sqs', ' swot analysis', ' talend etl', ' pl sql enterprise hana', ' praat', ' information security analyst', ' ksql', ' vas', ' akka', ' tfvc', ' database structure', ' perpetual inventory', ' process excellence', ' abap', ' risk analytics', ' glm algorithms', ' azure adf', ' reg framework', ' gcp analytics', ' ssh', ' mean stack', ' product implementation', ' enterprise business', 'help desk', ' tag deployment', ' xd', ' genism', ' cloud migration', ' corporate actions', 'microservice based architecture', 'senior big data developer', ' business process modeling enterprise to department level', ' frontend development', ' supply chain network optimization', ' spanish', 'audio editing', ' commercial', 'dashboarding', 'tax', ' kaizen', ' analytical techniques', ' mwaa s3', ' product portfolio', ' nsgs', ' master data mgmt', ' revenue planning', ' device tree', ' coal', ' business intelligence analyst', ' performance monitoring', ' dwh', ' lr', 'servicenow', 'java mapreduce', ' project portfolio management', ' hr system support', ' azure synapseazure', ' cgi', ' business continuity', ' product vision', ' product development life cycle', ' alert monitoring', ' pivottables', ' software testing life cycle', ' tableau', ' oaf', ' spark scala', ' data organization', ' devops engineer', ' lean', ' oracle db sql', ' google colab', 'data modelling', ' coredata', ' recruiting system', ' licensing', ' black belt', ' commercial operations', 'resource utilization', 'big data architecture document', 'finance erp system', ' campaign analytics', ' database server', ' mvs', 'hr analyst', ' general ba', ' zoho', ' data pipeline development', ' maya', ' uikit', ' epm', ' database programming', ' jupyter', 'azure adls', ' sqlite', 'data verification', ' user-centered design', ' equity research analyst', ' team lead', ' cics', ' user interface designing', ' gdb', 'ai & ml', ' relational database', ' san', ' nodejs / typescript', ' intellij', ' conditional formatting', 'presentation', ' msft', ' azure dw', ' protein bioinformatics', ' hd insight', 'pci dss', 'node.js', ' client management', ' plant engineering', ' nosql databases', ' software product management', ' glr', ' advanced python', ' base sas', ' dimensional modelling', 'databricks ml', ' it analysis', ' apache atlas', ' doctor', ' manager client servicing', ' data ingestion design', 'system integration', ' external audit', ' psm', ' azure full stack', 'bw 4hana', ' ui data', ' data mart', ' heavy machinery', ' sketch', ' hr dashboard', 'adobe suite', ' google adwords', 'prototype analysis', ' erm', ' proc transpose', ' visual', ' material science', 'hortonworks', 'data warehousing - sse/de/ architect', 'performance', 'system configuration', ' game', ' customer analysis', ' etrms', ' mvc framework', 'devops pipeline', ' quantitative diagnosis', ' sap bi', ' advanced excel', ' strategic sourcing', 'data science', ' client handling', 'data architect', ' data analysis expressions', 'network programming', ' alfresco', ' backbone', ' hql', ' retail credit', ' core banking solution', ' saving', ' network monitoring', 'mvt structure', 'haskell', ' dml', ' requirement analysis', ' costing', ' stock exchange', ' xml', ' expressjs', ' pytorch', ' auto domain', ' scrapy', 'architecting', ' ms azure ci', ' client presentations', 'business intelligence', ' cam', ' restful micro', ' box', ' delivery management', ' trade and customs analyst', ' nlp algorithms', 'lookup', 'disaster recovery', ' hadoop.', 'head business development', ' mulesoft', ' azure services', ' workflow analysis', ' angular 12', ' vsam', ' spec', ' - tier', ' bots', ' software frameworks', 'debt collection', ' withgcp', 'senior analyst', ' restful api', 'azure databricks', ' qa automation', ' multi - process', ' eee', ' pathway', ' workflows', ' cloud data fusion', ' motorola', 'pubsub', 'google cloud azure', ' regualatory projects', 'advanced analytics', ' money laundering', 'qa data', ' concatenate', 'playbook', 'statistics', ' reporting tools', ' agile', ' hardware networking', ' information management', ' sap bw', 'decision making', 'program delivery', 'data stewardship process', ' no - sql databases', ' firebug', 'data anlalytics', ' workload executive', ' process optimization', 'bigquery', ' revenue generation', ' contact center operations', ' dart cross', ' glue tables', ' sqlserver', ' medical', ' pcmcs', ' google cloud storage', ' outlook', ' administration of windows', ' risk engineering', 'secondary data', ' fi', 'ld. prod svcs app sup anlyst', ' human resource management', ' dell boomi', ' corporate taxation', ' functional analyst', 'big query', ' kafka broker', 'financial reporting', ' associate content analyst', ' credit risk modeling', ' microbiology', 'verbal written', ' compensation data', ' azure search', ' digital asset management', ' creative communication', ' analytical thinking', 'rss', 'mcom', 'spark streaming', ' large deals', 'rwa', ' informatica datastage', ' corporate sales', 'fatca', 'scala', ' hofs & data engineering', ' function modules', ' tqm', ' machine learning', ' azure data lake analytics', ' verbal', 'service contracts', ' mssql', ' iso 13485', ' kerala', ' distribution network', ' antivirus', ' optimazation', ' pricing', ' b . tech', ' web architecture', ' pmbok', ' civil engineering', ' agile methodologies', 'formulation development', 'cloud computing', ' ios ipa', ' cognos analytics', ' product analytics associate', ' runmyjobs', ' client solutions', ' malware analysis', ' senior', 'power electronics', 'mssql dba', 'expert in microsoft excel', ' agile environment', ' dax power bi', ' test case creation', ' mdx', 'e-learning', 'rpa', ' gcp stack', 'rtos', 'azure data warehouse', ' dash bo', ' aiml technical architect', ' hockeyapp', 'ml algorithms', ' enterprise data warehouse', ' mentoring', ' certified', ' google webmaster tools', ' cudnn', ' ise', ' infosphere datastage', ' vba', ' big data engineer', 'jtag', ' client support', ' establish facts', ' aws big data', ' network optimization', ' postgresql', ' r12', ' project handling', ' back office processing', ' software development lifecycle', ' arcgis desktop', ' snow slm', ' rpo', ' data mappings', ' dso', ' hierarchy diagrams', ' data flakes', ' data extraction', ' decision models', ' consumer goods', ' verbatim coding', ' operations management', 'markit edm', ' entrepreneur', ' interpreting data', 'microsoft office suite', ' aws web services', 'creative solutions', ' technology consulting', ' basic', ' performance appraisal', ' fraud analysis', ' transcription', ' incident management', ' dataframe', 'asset management/', ' manager information technology', 'solution architecting', ' threat', ' mca', ' azure etl', ' process flow', 'ivr', ' python sdk', ' remediation', ' snowpipe', ' oracle hcm', ' ontology', ' lambda functions', 'root cause analysis', ' chartio', ' financial inclusion', ' employee retention', ' growth analytics', 'min', ' gensim', ' data steward', ' marketing planning', ' python framework', ' aws cloudtrail', 'gap analysis', ' procurement management', ' emi / emc compliance', 'customer service representative', ' embedded linux', ' tibco data virtualization', ' oo', ' big data warehouse', ' technical recruitment', ' awsazuregcp', ' bamboo', ' flutter', ' r scripts', ' corporate governance', 'statutory audit', ' linux engineer', ' hadoop testing', 'hdfs', ' travel management', ' data stewardship', 'agile methodology', ' sql olap', ' typing', 'financial statements', ' feasibility analysis', ' strategy formulation', ' solidatus', 'hris', ' data analysis', ' linear logistic regression', ' software implementation', ' pivot', ' synapse pipeline', 'data engineer ii', ' data factory', ' market basket analysis', ' ua testing', ' engineering procurement', ' financial research', ' report preparation', ' b2b communications', ' b2c marketing strategy', ' object - relational mapping ( orm', ' web service', ' idrp', ' infrastructure', ' vendor management', ' security compliance', ' hadoop cluster', ' salesforce com configuration', 'hmi programming', ' sql azure', ' process monitoring', ' erp', 'software engineer', ' greenplum', ' hyperion planning', 'reinsurance', 'javascript/html5/css', 'process optimization', 'asp.net', ' consumer research', 'path management', ' data entry', ' spark python', ' analytical', 'mdm tools', ' c# scripting', ' quantitative analyst', ' data flow', ' business requirement analysis', 'big data analyst', ' e-sourcing', ' cassandra', ' guest house', ' mapreduce programming', 'project coordinator', ' troubleshooting skills', ' optimizations', ' sales operations analyst', ' tax returns', ' imagenow', ' customer profiling', ' disaster recovery', ' python based framework', ' plm', ' unisim', ' apache spark administration', ' handling large data', ' travel', ' matplotlib', 'web services', ' metric management', ' xslt', ' wind energy', 'c - nn', ' radar algorithm', ' business modeling', ' engineering calculations', ' openshift paas', ' blue prism knowledge', 'olap', 'neural network nlp', ' software engineering manager', ' mis managment', ' process flows', ' superset tools', 'business finance', ' azure file storage', ' chemistry', ' corporate banking', ' angularjs', ' ooad', ' mvvm', 'qa testing', 'big data architect', ' usage', ' data mining methodologies', ' help desk', ' business and technical metadata management', 'etl tools', ' root cause analysis', ' team handling', ' oop', ' survey', ' client coordination', 'chemical analysis', ' solutions', ' civil', ' big data testing', ' tpa', ' corporate', 'medra', ' pyramid', ' packaging', 'database warehouse', ' data sources', ' web designing', ' anti money laundering', ' bos', ' datalake', 'information research', ' pomdp', ' data forecasting', ' machin learning', ' object oriented design', ' computational algorithms', ' vcf', ' rfps', ' video conferencing', ' endpoint security', ' etl tools', ' web platforms', 'informatica mdm', 'data sheets', ' etl / elt', ' hydrocarbon', 'zookeeper hive', ' composer', ' sprint process', ' pmml', ' semantic data modeling', ' prosecution', ' website', 'rcm', ' azure cloud service', ' a/b testing', ' nimbusml', ' django orm', ' loan documentation', 'lambda', 'design patterns', 'kernel', 'test case preparation', 'beauty', 'data architecture', ' sql query writing', ' risk analysis', 'aws lex', ' data science', ' shell scripting', ' glmm', 'business process', ' social media', ' flume', ' business requirement document', ' vmware', 'ml architect', ' vtk', 'retail banking', ' project planning', ' veeva crm', 'microsoft office', 'apache flink', ' data engineering analyst', ' sdet', ' database designproduct engineering', ' npm', ' windows server administrator', ' cognos', ' actuary', ' scripting', ' android sdk', ' lamda', ' data ingestion patterns', ' insights generation', ' infrastructure management', ' hyper-v', ' rest api design', 'literature', ' erp implementation', ' cocoapods', ' sql/plsql', ' keyword analysis', 'cdc ingestion', ' alation', 'qlikview', ' plant maintenance', ' azure data lake store gen 2', ' green plum', ' senior executive', ' powerbi desktop', ' soc consultant', ' ui / ux design', ' python unix', ' nlg', ' financial model', ' machine learning frameworks', ' cosmos db', 'market sizing', ' gl', ' business reporting', ' oracle 9i', 'digital media', ' distributed computing tools', ' sap mdm consultant', 'drilling', ' etl development', 'capital market', 'datafactory', ' puppeta', ' sap btp', ' jd edwards', ' jest', 'ssis', ' ui path developer', ' big query', 'supply chain management', ' server programming', 'perl script', ' stats graduate', ' maria db', 'deployment', 'power bi', ' cvs', ' microsoft azure platform', 'aws', ' soft skills', ' people skills', ' natural language processing', ' bug tracking tool', 'hadoop', ' powerbi', ' presto', ' promotional campaigns', ' cloud storage', ' druid', ' sas database', ' hyperion hfm', ' adobe xd', ' ids firewall', ' cost management', ' user interface testing', ' data domain', 'construction management', ' image recognition', ' ec2', ' cnns', ' associate lead', 'scalaspark', 'teradata data science', 'energy market', ' auth0', ' email communication', ' glycoprotein', ' non voice process', ' python and r', ' engineer engineering', ' global marketing', ' data quality analysis', ' process mapping', ' openstack', ' activevos logs', 'tosca testing', 'machine learning algorithms', ' docker containerization', ' microsoft visual studio', ' google analytics', ' portuguese', ' apache qpid', ' aws glue athena', ' office equipment', ' solid design', ' ftp', ' c + +', ' sas di', ' aws cloudformation', 'e-commerce seo specialist', ' iso 27001 lead auditor', ' epidemiology', ' aviation', ' open dp', ' capital management', ' - driven', 'big data testing', ' spark pools', 'aws pyspark', 'data engineering', 'marketing head', 'data coding', ' reactjs', ' google bigquery', ' java scripts', 'zoho', 'pdf extraction', ' azure', ' azure data engineer', ' social networking', ' continuous improvement', ' orc', ' campaign management', ' un- supervised learning', ' business intelligence reporting', ' business process schemas', ' ascii spss excel', ' data privacy', 'front end', 'packaging', 'financial', ' core hr', ' zookeepers', ' shark', ' maven tool', ' data standardization', ' data dictionary', ' sas macros', ' research analysis', ' principal data scientist', ' snowflake schema', ' data capture', ' continuous integration', ' version control', ' gitlab', ' stream sets', ' enterprise master data', ' analytics lead', 'vlookup', ' product control', 'consulting - bfsi', 'candidae shall quick learner with good communication and team skills and excellent coordination wih hod and support staff', ' data warehouse design', 'pricing analysis', 'senior data engineer', ' adwords', ' power designer', 'software testing', 'etl process', ' big data tools', ' crm integration', ' h2o', ' datastore', ' ux designer', ' c++python', ' venture capital', ' data reconciliation', ' pyqt', ' crawling', ' integration - testing', ' scalar', ' cloud solutions', ' calculus', 'customer analytics', 'architecture', 'corelocation', ' hadoop eco', ' engineering management', ' adfs', ' sql spark', 'mining', ' cold calling', 'advanced excel formulas', ' quant analyst', ' income tax', ' game development', 'customer support', 'data link', ' hive analytics', ' s', 'machine learning ops', ' ingestion', ' power apps development', ' record to report', ' counselling', ' financial planning', ' itil process', ' vb script', ' stress testing', ' business operations', ' cisco', ' intelligence', ' loadrunner', ' rfx', ' zoominfo', 'aws emr', ' r programming', ' socialbakers', 's/4 hana', ' legal operations', ' consulting retail', ' product engineering', ' omniture', ' pumps', ' ms', ' student engagement', 'azure analytics', ' arcgis', ' sequence diagrams', ' it business analyst', ' rllib', ' linux & solaris & their patch management', ' sql performance tuning', ' network services', ' computer science', ' oracle agile', ' purchase', ' algorithm design', ' chrome extension', 'access management', ' c #', ' evaluation', ' patient data', 'informatica data quality', ' ngaa platform', 'socket programming', ' guidewire application development', ' retail marketing', ' analytical skill', ' risk management', ' control-m', ' financial packages', ' water', ' ventilation', 'computational biology', ' data wrangling', ' relational database design', ' internal audit consulting', ' power integrity', ' java j2ee developer', 'oic', ' sonar', ' peachtree', ' informatica development', ' azure synapse', ' information architecture', ' atscale', ' aws data base migration service', ' performance engineering', ' development testing', ' interior architect', ' accounts payable', ' personnel administration', 'tivoli', ' cloud aws lambda', ' adls', 'dynamics', ' ab initio software', 'sql dba', ' support analyst', 'open source', ' lead architect', ' ms office powerpoint', ' rest api development', ' web research', ' segmentation techniques', ' lead designer', ' data mart development', ' informatica', 'epbcs', 'bi lead', ' genetics', 'statistical techniques', 'reference data', ' teaching', ' system analysis', ' market scenerio', ' commercial vehicle', ' animation', ' customer experience management', ' developer', ' data privacy management', ' workforce analytics', ' lambda data prep', ' computer aided engineer', ' statical analytics', 'research analyst', 'visual studio 2017', 'transformers', 'capacity management', ' accounts receivable', ' wincross', ' net core', 'text analytics', 'time series analysis', 'technical data management', ' microsoft azure dev', ' sql jobs', 'lacp', 'auto industry', ' vba access', ' client satisfaction', ' data processor', ' risk monitoring', ' rdbms ms sql server', ' supplier relationship management', ' technical staff', ' push services', ' aspen', 'big data platforms', 'pig', ' sql alchemy', ' bpo', ' sap analytics cloud', 'service desk', ' non linear optimization', ' semiconductor manufacturing', ' data quality', ' managing', ' functional analysis', ' microservice based architecture', 'marketing analyst', 'equity', ' fraud analytics', ' clinical data coder', ' acquisition strategy', ' views', ' research lead', ' front office executive', ' arcgis pro', ' logical approach', ' veeva suggestions', ' intellij idea', ' vott', ' design architect', 'r dbt', ' efficacy', ' sass', 'process mining', ' periscope', 'organic synthesis', ' relational database service', ' sitecatalyst', ' databases administration', 'software suite', ' end user', 'python data analytics', ' r language', ' gaming', ' user stories', ' azure data lakes', ' health insurance', ' equity research', ' hr strategy', 'techno functional', ' data profiling', ' stored procedure', ' torch', 'html5', ' service contracts', 'aws sam', ' mechanical design', ' data strategy', 'waste management', ' ms visual basic', 'copa', ' biostatistician', 'redux', ' information technology', 'qualitative research', ' it product development', ' yarn', ' environmental science', '.net core', ' airflow', ' blogs', ' pl/sql', ' jenkins', ' entity security', ' knowledge of ms office', ' sap finance', ' business communication', ' business objectives', ' excellent', ' technology operations', ' technical analysis', ' service desk', ' analytical solutions', ' engineer product development', ' transform and load', ' data exploratory analysis', 'cloudera hadoop', ' cision', ' cochin', ' synapse', ' voice process', 'programming language', ' interpersonal skills', ' finma', ' postgres dbms', ' english', 'checkpoint fortigate', ' antlr', ' collectd', 'aws services', ' staff', ' python developer', 'snowflake', ' sql knowledge', ' credit assessment', 'rnn', ' trade settlements', 'quantitative analysis', ' digital analytics tools', ' manager', 'azure databricks admin', ' rooshal dsouza', ' transact sql', ' ai factory', ' collibra', ' client engagement', ' rewards and recognition', ' azure ecosystem', ' markit', ' cloudwatch', ' international business development', ' vendor master', 'monitoring', ' it security analyst', ' salesforce . com', 'azure data lake', ' boto3', ' nosql db', 'backend engineer', ' analyst', ' oltp', ' quick sight', 'sqa', 'etrm', ' market intelligence', ' fund administration', ' bms', ' power bi .', ' lead product designer', 'pyramid', ' data center activities', ' gcp cloud', ' aws cloud', ' ca intern', 'sap business objects', ' research engineer', ' analytics data', ' bmc', 'vertica', ' itl', ' demand planning', ' restful web api development', ' cma data', ' cloud applications', ' bdcs', ' machine learning algorithm', ' qa testing', ' web development', ' aml compliance', ' apache kafka', ' consulting analyst', ' equity derivatives', ' informatica. data science/ data management.business analysis workflow power bi/tableau or any other data visualization tools.oracle 10/11g- sql pl/sql or similar rdbms.', ' hypothesis testing. -experience working on building an ai conversation voice chatbot', ' operations manager', ' campaigns', ' anaconda enterprise', 'arimax', ' smb', ' proc sql', ' netbackup', 'patent landscaping', 'designing b2b and b2c products', 'unix scripting', ' change analyst', ' db replicas', ' boosting bagging techniques', ' dsp', ' performance metrics', ' seo executive', 'coding analyst', ' implementation support', ' computing', ' statistical', ' linkedin sales', ' tfserve', 'enterprise reporting', ' network programming', ' excel modeling', ' augmented reality', ' itil framework', ' author', 'smtp', ' cdc', ' hrsd framework', ' healthcare support operations', ' revenue recognition', ' modelling', ' software development life', ' tableau analytics', ' silicon', 'serverless', ' taxation', ' sql data analysis', ' ifs erp', ' maintenance operations', ' snowflake sql', 'alteryx tableau', ' c2c', ' aurora mysql', ' industry 4.0', ' scala', 'analysis skills', ' test design', ' traceability matrix', 'oozie', ' md', ' networking protocols', ' full stack development', ' cloud analytics', ' vpn', ' effort estimation', ' credit underwriting', 'atlassian tools', ' automation testing', ' ip routing', ' iis', 'account reconciliation', ' xpath', ' classification', ' media strategy', 'ci/cd pipeline', ' mis', ' rest api', ' l1', ' advanced sql', ' solution development', 'primary market research', ' effective communication', ' proteomics', ' market access', ' religare', ' power bi', ' ml algorithm', ' react', ' ci', ' it staffing', 'pmp', ' business process analysis', ' pcm', 'rest api design', ' power-bi', ' accounts payables', ' sql server analysis', 'matlababout', ' amazon athena', ' spark framework', ' oops concepts', ' copd', ' elt engineering', ' content filtering', ' aws spark', ' react js', 'data visualization tools', ' hotspot', ' excel sheet', ' accounts receivables', ' software product development', ' digital forensics', ' salesforce.com administration', ' sql analytics', ' pharmaceutical', ' cost reduction', 'os vulnerability management', ' cicd', ' journalism', 'gsm', ' hr mis', 'c# sharp & dot net', ' power bi development', ' heart disease', ' assistant manager r&d', ' scrum ceremonies', ' amazon macie', ' domain expert', 'cluster management', ' application support analyst', ' roads', ' ansi', ' risk mitigation', 'cloud storage', 'python/nodejs/java', ' technology solutions', ' decision sciences', ' go getter', ' knowledge management', ' oracle database', ' anatomy', ' hadoop technologies', 'qualitrix', ' transfer learning', ' advance analytics', ' html5+', 'system design', ' media', ' pci', ' cocoa framework', ' bootloader', ' copyright', ' gherkin', 'life sciences', ' baw', ' servicenow hiring', ' project management skills', ' asp net core', ' schema', ' engineering project management', ' data reports', 'hr', ' cosmosdb', ' elmo', ' presentation skills', ' data models', ' theano', 'statistics modelling preferably graduated in stats field.', ' platform development', ' cook', ' confidentiality', ' spacy', ' rest api s', ' build', 'spend analysis', ' project financial cost tracker', ' rackspace', ' etl data integration', ' design validation', 'large', ' visualization consultant', ' hyperparameter tuning', ' spark mllib', 'predictive modeling', ' hair care', ' debugging', ' database testing', ' corporate services', ' turbine', ' management audit', ' trade reporting', 'datapower', ' test cases', ' service bus', ' ml', ' compelling explainer', ' data warehouses', ' jboss', ' elt', 'dynamo db', ' azure data sql dw', ' emblem', ' hse', ' semiconductor', ' physics simulations', ' asp.net mvc', ' investor relations', 'fixed income', ' business process improvement', ' process design', ' openwrt', ' genpact', ' us healthcare', ' android coding', ' azure data lake services', ' seoluxury', 'fundamentals', ' contract abstraction', ' tier 3-4 support', ' mobile technology', 'windows administration', 'engineer ii', 'rca', ' microsoft technologies', ' veeva vault', ' database modelling', ' general ledger accounting', ' investment analytics', ' apics', ' python trainer', ' quality assurance engineering', ' telecom', ' sap mm', 'shell scripting', 'azure data factory', ' s / 4', ' oracle epm', ' data verification', ' shell.', ' mis reporting', 'chatbots', ' heroku', ' document management systems', 'c#', ' biochemistry', ' data bricks landscape', ' azure data factory', ' spring boot', 'sap ewm', ' simulation', ' looker', ' search engine marketing', 'qa', ' r program', ' creative designing', ' product operations', 'prototype', ' wholesale banking', ' hotspot data sync', ' recruiter', ' microsoft azure stack', 'unix shell scripting', ' scrum framework', ' cloud dw', 'azure data engineer', ' sales planning', ' emi', ' object relational mapper', ' tsql queries', ' lead', ' logic', ' procurement analyst', ' strategy deployment', ' ms sql dba', ' keyword research', ' salesforce com', ' development', ' corporate security', ' sumif', ' medicinal chemistry', ' rave', 'staff software engineer - full stack ( angular / node)', ' competitor analysis', 'model behaviors', 'mis updation', ' translation', ' adobe suite', ' mobile', ' linux administration', ' snowflake', ' software testing', 'fx', ' property management', ' lcl pricing', ' dwbi', ' it automation tools', ' payments', ' development lifecycle', ' information security management', 'r language', ' nosql technologies', 'written communication', ' payments compliance', ' line management', ' featured snippets', 'ssisssrs', ' big data tech stacks', ' jax - rs', 'dwbi', ' fme', 'sso', 'diagnostics', ' ci/cd', ' code refactoring', ' essbase', ' bq', ' medallia', ' trademarks', ' routing & switching', 'data analyst', 'business process modeling', ' sigma', ' .net core', ' sqlalchemy', ' keystone framework', 'visio', 'data', ' cloud technologies', 'analytical skills', ' drill', ' coding analyst', ' it hardware', ' iaas', ' ucs', 'azure synapse', ' end user support', ' elicitation', ' medical insurance', ' aws bigdata', ' invision app', ' decipher', 'software development engineer 2', ' google cloud platform', ' informatic', ' sdlc methodologies', 'listing', ' bi analyst', 'salesforce crm', ' pl - sql', ' activemq broker', 'sas sql', ' techno-commercial', ' business optimization', ' sap erp', ' market survey', ' solution analyst', ' medical devices', ' ms visio', ' espresso', ' informtica', ' prep', ' computer languages', ' japanese', ' business solutions', ' monitoring', ' amazon ai', ' aws/ azure', ' hiring', 'cloud warehouse', 'functional lead', ' support services', ' noc', ' database knowledge', ' scala programming', ' anomaly detection', ' scrum master', 'data quality process', ' supply chain analytics', ' test case', ' income tax audit', 'docker', ' strategic hr', ' front end', ' general administrator', ' commvault', ' spotfire', ' candidae shall be prepared for timel', ' tally', ' data modeling tool', ' ldap', 'microsoft excel', ' business suite', ' material ledger', ' litigation support', ' large data sets', ' business objects', ' emerging technologies', ' power point presentation', ' developing', ' ips', ' cloud aws', ' business development', ' azure logic app', ' legal advice', ' part time', 'jest', ' cassadra', ' automated tests', ' non voice', ' agrochemicals', ' ocr', ' training analysis', ' jupyter notebook', ' ecosystem', ' user story', ' database automation - ci/cd & devops', ' big data design patterns', ' bigdata engineer', ' linux script', ' apache spark', ' marketing management', ' sas model', 'master data', 'variance analysis', 'digital marketing', 'workday', ' quickbooks', ' odi', 'bigdata developer', ' ibm datapower', ' dataops', ' high availability', ' programing', ' pivot tables', ' vulnerability', ' ssjs', 'condition monitoring', ' data imputations', ' netsuite', ' treasury operations', ' mixed signal', ' ms data management', ' campaign execution', ' cybersecurity data science', ' banking operations', ' lead management', ' employee records', ' event grid', ' dynamo', ' proprietary trading', 'applied intelligence', ' data collection', ' manufacturing process', ' cluster analysis', 'distribution analysis', 'machine learning operations', ' bioanalytical', 'microservices', 'conversions', 'printing', ' design studio', ' data annotation', ' process analysis', ' rust', ' relational database management systems', ' infrastructure services', ' statistical analyst', ' software sales', ' azure sql pools', ' copywriter', ' benefit analysis', ' nist', ' gis software', ' oracle service bus', ' shell', ' bw', ' investment strategies', ' big data spark sql', ' azure active directory', 'pmo', ' air flow', 'architecture shell', 'dom', ' making', 'matillion', ' query authoring', ' ci cd', ' rfp', ' base shell', ' databases', ' helpdesk', ' easy writer', ' digital strategy', ' director', ' embedded c', ' portfolio management', 'market research', ' programmer analyst', ' scala developer', 'ui development', ' sc', 'sdlc', ' qt', ' microsoft windows programming', ' tsne', ' product innovation', ' timescale', ' mis generation', 'process management', 'excel', 'css', ' basic networking', ' value added services', ' impact analysis', ' patterns', ' sparql', ' software packages', ' mysql', 'process audit', ' pay per click', ' palantir', ' bdd', ' work', 'legal contracts', ' etl/elt', ' business analysis', ' bios', 'sap master data governance', 'adobe experience manager', ' azure cloud engineer', ' accountancy', ' mergers', 'data visulization', ' hana data warehouse', ' data integration engineer', ' open query', ' pgdca', ' investment risk', ' invoice processing', ' hcm', 'data enrichment', ' defect analysis', ' virtualization', ' data compression', ' programming knowledge', ' mis report', ' matlab', ' informatica master data management', ' unit testing framework', ' data warehousing concepts', ' online banking', ' direct sales', ' infringement', ' security testing', ' design specifications', ' vehicle dynamics', ' e-governance', ' rf', 'automation', ' dodaf', ' data testing', ' quantexa', ' hadoop dfs', ' database warehousing', ' aws snowflake', ' api gateway', ' data audit', ' application architecture', ' general accounting', ' french', ' s3', 'agile methodologies', ' software configuration management', ' test strategy', ' research associate', ' risk governance', ' layout design engineering', ' mesos', ' network administration', ' training', ' data engineer python sql', ' node', 'test reporting', ' synapse / dw', ' aem', 'crawler data engineer', ' mortgage underwriting', ' ms - sql', 'computer vision', ' tuning', 'data42 platforms', ' data - sql', 'd3 js', 'bfsi', ' data centre', ' public relations', ' atlassian tools', 'linux internals', ' content analytics', ' lightgbm.', ' reporting analyst', ' market mix modelling', ' access control', ' notion', ' oop skills', ' agile software design life cycle', ' apex', ' hr policies', 'datascience', 'debugging', ' vlan', ' client servicing', ' py', ' product mapping', ' erwin tool', ' cmbs', 'java', 'microsoft sql server 2012', 'medical devices', ' consulting - retail', ' database administration', ' interface testing', ' system architecture', ' columns', ' sql database', ' bds', ' senior data scientist', ' associate data analyst', ' sql server 2008', 'cca', ' sales engineering', 'cognos', 'swift', 'deep troubleshooting', ' computer operator', ' eia', ' pre sales', ' automation frameworks', ' bitbucket', ' client meeting', ' struts', ' maximo data migration', ' asset management analyst', 'strategy consulting', ' hadoop family', ' microfinance', ' interpret data', 'retail domain', 'azure synapse analytics', ' operational skills', 'enterprise cloud', ' skill development', 'scripting language skills', ' pig', ' azure sql db', ' ms sql server', 'wind modelling', ' category management', 'operations analyst', 'sentry', 'agile framework', ' azure cl', ' oops', ' reconciliation', ' asset management', ' service delivery', ' rta', ' resource requirements', ' it lead', ' google cloud sdk', 'hibernate', ' coding and development', ' ale', ' process development', 'ngs data analysis', ' data base administration', ' project leading', 'snowflake db', ' principal', ' oracle analytics', ' aws crawlers', ' performance analyst', ' data developer', ' vuejs', 'r&d', 'statistical modelling', ' predictive model', ' web scrapping', ' draw io', 'object oriented analysis', 'oracle', 'python frameworks', ' ssis developer', ' solution implementation', ' solution delivery', ' senior data analyst', ' solar', ' aci', 'project management', ' innovation management', ' english language', ' hadoop developer', 'sql scripting', ' everbridge', ' fi derivatives product', ' swaps', ' iterative', ' distributed training', ' pharma', 'informatica idq', ' mode analytics', ' ssp', ' data anayst', ' oracle e', ' ux', ' opentext', 'strong analytical skills', ' mis manager', 'public relations', ' market analyst', ' hybrid cloud infrastructure', ' functional design', ' dfm', 'sales', ' regulatory issues', ' apache nifi', ' ms project', ' qa data management', 'sitecore', ' system maintenance', 'information security', ' django framework', ' technical skills', 'ms windows', ' user experience design', 'manager technology', ' anypoint', ' tdm', ' sockets', ' sql query', ' sdlc process', 'quantum', 'google cloud', 'aws lambda', ' ehr database mapping', ' computer vision', 'informatica master data management', ' credit derivatives swaps', ' msft word', 'jmeter', ' data processing', ' spring batch', ' sales engineer', ' environment', ' pilot plant', ' operating systems', ' documents', ' mixpanel', ' maintain workload files', 'environmental analyst', ' managed services', 'microsoft sql server', ' apache 9', ' graph', 'ai modelling', ' object - oriented development', ' software distribution', 'digital transformations', ' investment', ' natural language generation', ' editing', ' web / application servers', 'ehs', ' business awareness', ' email marketing', ' onetrust', ' it sourcing business analyst', ' solution architecting', ' analytics models', ' kibana', ' data analysis and project management.', ' configuration management', ' order processing', ' datawarehousing', ' transaction processing', ' middleware', ' sme', ' cloud concepts', 'vmware', 'client communication', 'sr. data analyst', ' iqn', ' data flow mapper', ' linear regression', ' crc', ' financial', ' pcb design', ' elastic search sold', 'data model', ' voip', 'bloomberg', ' apache airflow', 's3 data lake', ' big data analysis tool', ' cosmos db master', ' freshers', ' web technologies', 'eloqua', 'react native', ' cognitive search', ' full stack developer', ' java spring framework', ' microsoft ssis', ' strings', 'ml development', ' drupal', ' query resolution', 'global operations', ' sql dwh', ' cloud portal', 'hr analytics', ' java/python', ' data engineering manager', ' whodd', ' agile framework', ' process re-engineering', ' ds modelling', ' cloud essentials', ' data engineer/etl developer', ' zyputer', ' electronics engineering', ' lead assistant manager', ' identifying', ' sap fiori', ' cicd deployment', ' azure data architect', 'sap webi', ' excel dashboards', ' ms-excel skills', 'marketing programs', ' medicare', ' drafting', ' testing', ' hadoop cloudera distribution', ' assortment planning', 'test data management', ' terraform', ' monitoring tools', 'database architecture', ' sap mdg', ' advertising', ' soc analyst', ' ed', ' kubeflow', 'faster payments', 'engineering project management', ' product specification', ' big data data', 'teradata sql', ' staffing', ' v5 collibra', ' cloud platform', ' sap erp implementation', ' system admin support', 'application programming', ' jmeter', ' servlets', ' oozieairflow', ' data processing analyst', ' mlops', ' azure data lake store', 'test scripts', ' customer analytics', ' automl', 'azure iot engineer (streaming data)', ' aws/azure data services', 'aws cloudformation', ' microsoft modern data platform', ' real time analysis', ' data analysts with business analysis', ' it operations', ' search engines', ' pharmacy', ' manager presales', ' - end', ' no sql', 'oracle database', ' account planning', 'sigma', ' advisory', ' corrective action', ' query handling', ' software project', ' data architect', 'hedge funds', ' active directory', 'statistical testing', 'daily accounting', ' transportation planning', 'advanced excel', ' cloud architectures', ' endur', ' matillion snowflake', ' dashboard development', ' internal control', ' review data', 'data intelligence', ' production support', ' data systems specialist', ' rest assured', ' spark code', ' supplier management', ' training and development', ' linux kernel', ' data dictionaries', ' arcgis server', ' skillsql', 'hospitality', ' financial data analyst', 'ecc', ' digital engineering', ' azure datafactory', 'material management', ' environment health safety', ' handling', ' big data language', ' direct tax', ' soap ui', ' speech analytics', 'kubernetes', ' inbound calls', ' training delivery', ' scoop', ' hadoop hive', ' thoughtspot', ' oracle financials', 'dimension', ' ecosys', ' hydraulic actuators', ' bpc', ' analysis services', ' simulation modeling', ' automation framework', ' sfmc', ' test automation', ' risk modeling', ' executive management', ' oracle soa', 'prtg', 'fccs', 'matplotlib', ' medical writing', ' grammar', ' distribution system', ' programming', ' python 3', ' data querying', ' system interface diagrams', ' kudu', ' project implementation', ' consultant', ' microsoft power bi architecture', 'process orientation', 'wireframe', ' stakeholders', ' problem solving skills', ' full stack', ' adb+adf+python', ' sales forecasting', ' voice', ' high performance computing', ' next js', ' consumer marketing', ' sap apo', 'image recognition', 'paid social media marketing', ' data platform', ' data noc', ' data modeling tools', ' pca', 'snowflake / redshift', ' broadcasting', ' head hunting', ' chemical', ' ebx5', ' technology', 'advanced statistics', ' team manager', 'quality orientation', ' quality tools', ' azure python', ' technical leadership', ' supply chain operations', 'apache', ' edm', ' adobe analytics', 'core data', ' program manager', 'defect analysis', ' data monitoring', 'industry reports', 'vba automation', 'business system', ' informatica powercenter', ' engineeringdatabase', ' process compliance', ' cruise control', ' operational risk reporting', ' infosphere', ' sql scripts', ' rls', ' kpi', 'ml', 'sql server', 'sap co', ' webhooks', ' pubsub', ' spacity', ' sap fi', 'stress testing', 'cae', 'remediation', ' otbi', ' usability testing', ' saml', ' test scripts', 'qliksense', ' liquidity management', ' fortigate', ' data architects', ' oracle support', ' hotjar', ' load testing', ' competencies', ' hardware specification analysis', ' gurobi', ' sparkql', ' install base', 'sysops', 'talend open studio', \" restful api's\", 'plm', ' mobile phones', ' idms', 'metadata', ' quality consultant', ' computational biology', 'principal director', 'mis analyst', ' plc programming', ' cfa level 2', ' application management', ' sld', ' a3', 'technology consulting', ' sap', ' power point', 'configuration', ' dw program management', 'sqlite', ' general ledger', ' business insights', ' machine -', 'amazon web services', ' data lineage', 'windows server configuration', ' salesforce.com development', ' solutions.ai', ' ui design', 'sql server database', ' commercial real estate', 'architectural design', ' rabbit mq', ' illustrator', 'iisc', 'it recruitment', 'knowledge of big data stackdata modelling', ' warehouse management', 'people management', ' machine learning lifecycle', 'active directory', 'mis generation', 'lda', ' sap data reports', 'data ingestion elt', 'trading system', ' network security', ' senior business process analyst', ' google spreadsheet', ' cmdb', ' sql pools', ' data base', 's3', ' corporate it operations', ' brand management', ' switching', ' mba marketing', ' c developer', ' ratio analysis', ' feature engineering', ' azure stack module', ' cash management', ' e-discovery', ' real time operating systems', 'sas', ' bugzilla', ' etl projects', 'sap hcm', ' programming languages', ' linux', ' data sciences', ' windows 2008', ' sip', ' hazard analysis', ' plc', ' cross architecture', 'section engineer - afc', ' maintainance', ' power - bi', 'development testing', 'service delivery', ' azure ml', ' dataflow', ' roadmap', 'figma', 'accountancy', ' demand analytics', ' java enterprise', ' international clients', ' database building', ' titan', ' pycharm', ' mbs data', ' back office', ' ibm mq', ' lab analyst', ' cio', ' frameworks', ' epc', ' design analysis', ' dl math', ' data research analyst', ' organic polymers', ' websense', ' communication', ' keyboard', ' implement', 'data transformation', ' cognos 11 version', ' peoplesoft', 'big data analytics', 'unix linux', 'campaign planning', ' beautifulsoup', 'application designing', ' social science', 'r/python', 'managed services', ' cloud data engineer', ' selenium', ' sftp protocols', ' azure sql', ' cloudera data', ' jms', ' learning', 'online research', ' medical monitor', 'financial research', ' product owner', ' analysis of data', ' building ds solutions', ' azure sql database', 'process improvement', ' technology regulation', ' fertilizer', ' process data engineer', 'angular 4+', ' proc', ' data quality analyst', ' object - oriented concepts', ' ssl', 'customer relationship management', 'ip addressing', ' life cycle', ' pmo', 'enterprise content management', ' cloud services', 't-sql', ' css', ' performance tuning', 'wireless', ' scientists', ' control management', ' execution', 'product catalog', ' flutter mobile uis', ' relational sql', ' water structures', ' customer acceptance testing', ' business presentation', ' jmp', ' etl with aws', ' cause analysis', ' data quality assessment', ' ml libraries &application', ' survey questionnaire', ' firmware', ' kubernetes service *ml', 'tdd', ' devops', ' technical', ' visualization engineer', ' data platforms', 'data migration', ' unix operating system', ' post gress', ' geopandas', ' healthcare operations', ' ingestion tier', ' image segmentation', ' aix scripting', ' ccna', 'security analysis', ' reference data management', ' project analyst', 'sme bank data', ' provident fund', ' cloud aidevopsmachine', ' reference data', ' sdk', ' financial accounting', ' azure sql data warehouse', ' data services', ' statistical modeling', ' regulatory guidelines', ' analysis coding', 'forms', ' web tools', ' data management', ' conceptualization', ' kafka and kafka', ' jcl', ' adl', ' cdqa', ' vision', ' process improvement projects', ' analysing', 'problem solving and decision-making skills', ' data warehouse', ' prolease', ' rss', ' typing speed', ' field marketing', ' as2', ' ms office package', 'data governance', ' corporate finance', ' information system design', ' b2b sales', ' ecc', ' ado net', ' web services', 'corporate strategy', ' analysis', 'java web services', ' perforce', ' hysys', ' scheduling', ' t', ' nprinting', ' ups', ' management reports', ' soql', ' power queries', ' knowledge of computers', ' supply chain solutions', 'excellent communication', 'asp net', 'finance manager', 'redux saga', ' aws data tools', ' dlp policies', ' d3j', ' visualization tools', 'tomcat', 'life cycle', ' sda', ' neural networks', ' moss', ' murex', ' sql server database', ' aws oracle rds', ' data maintenance', ' networks', 'sap', ' excel macros', ' data modeling', ' mangodb', ' processing', 'adobe analytics', ' visualization', ' clinical monitoring', ' non it recruitment', 'sap mm materials management', ' perl', ' gpt', 'impala', 'power query', ' it infrastructure', ' scala with spark', ' good communication skills', 'microsoft sql', ' good communication skill', ' headless chrome', ' end user training', ' micro services architecture', 'gunicorn', ' lotus notes', ' auditing', ' machine language', 'tasks', ' data proc', ' aws', ' manager program management', ' maths', 'stash', 'web development', 'ssas', ' e - mail', ' legal', ' visualizing', 'ibm', ' google data studio', ' h-sql', ' data apis', ' tcp', ' sap bpc', ' engineer analyst', ' appium', ' wind', ' artificial neural networks', ' athena', ' pu - sub', ' hris analyst', ' user documentation', ' statistical learning', ' elasticache', ' java/golang/kotlin', ' charles', ' rds', ' group head', ' hortonworks hadoop', ' machine learning ml', ' industry analysis', ' jsonnet', ' blackbox', ' cadence', 'usfda', ' hr processes', 'jdbc', ' taxonomy', ' rapid miner', ' risk analyst', ' windographer', ' use cases', ' oauth', ' forecasting skills', ' incharge', ' demand management', 'sap finance', 'operations management', ' static data', ' soap', ' ensemble', ' audit command language', ' notebooks development', ' power operations', 'power and utilities', ' training & development', ' full stack application development', ' pmp', ' financial services', ' roc', 'vnet', 'disaster recovery planning', ' selection process', 'cloudera data', ' building', 'data mapping', ' vnet', ' fintech', ' citrix', ' competitive intelligence', ' circleci', 'package configuration', ' open-source code', ' memcached aws', ' language skills', ' core banking', ' apis', ' site management', ' alarm management', 'inventory management', 'mongo', ' installation', 'sosl', ' cissp', 'python scripting', ' software engineering', ' bills receivables', ' lead generation', ' cataloguing', ' tableau apis', 'restful apis', ' hld', ' project management office', ' seaborn', ' object oriented programming', ' computer skills', ' insurance', ' email support', ' rpc', ' hadoop hortonworks', 'dataflow', ' elastic search', ' business analysts', 'code review', ' vba coding', ' data structurescapacity planning', ' risk consulting', ' account development', ' cloudera', ' regulatory reporting', ' kafka rabbit mq', ' hadoop architecture', ' data and analytics', 'aiml', ' cloud strategy', ' h1b', ' mentor', ' cosmo db', ' information retrieval', ' memory management', ' sql developer', ' isomorphic react', ' python skills', ' fab process', ' db querying', ' model deployment', ' trend forecasting', ' next.js', ' business system analyst', ' bigdata technologies', ' social', ' powerapps', 'sre', ' nifi', ' intranet', ' mining', ' power bi reports', 'esri certified geodata', ' statistical modelling', ' eai', ' azure adls gen2', '.net', ' bioinformatics', 'minimum 4 years experience as data business analyst', ' power pivot tables', ' data lifecycle', ' pwd', ' cpi', ' qtest', 'nlp/python/r', 'it business analyst', 'content management', 'restful api', ' aws ses', ' academic research', 'web scraping', ' regression modeling', ' executive search', 'bitbucket', ' hcp', 'mean stack', ' pl / sql', ' dimensional data modeling', ' computer vision stack', ' nutrition', 'aas', ' requirements management', ' credit card', ' netcool omnibus', ' oracle sql', ' t - sql', ' analytics studio', ' data solution', 'troubleshooting', ' routing', ' data vault', ' sap development', ' qgis pix4d', ' containerization', ' trams', ' flink', 'analytical project management', ' team development', ' research', 'cisco routers', 'sap master data management consultant', ' android development', ' data integrations patterns', ' json', ' ecmascript', 'administration', ' postgresql schema', ' qlik coder', ' azure information protection', ' esxi', ' hadoop administration', ' epigenomics', ' mdm ui', 'gcp', ' scikit learn', ' predictive modelling', 'marketing analytics', ' sparksql', ' feature selection', ' data enrichment', 'polyglot', ' opt', 'ms sql', ' unix scripting', 'cargo', ' data base management', 'linux', 'ml libraries', ' ml algorithms', 'margins', ' delivery excellence', ' time series', 'nexus switches', 'relationship management', 'tapeout engineering', ' cpm', ' inside sales', ' metadata management', ' system testing', ' it compliance', ' communications skills', 'sap c4c', ' pmi acp', 'strategy', ' pyython', ' microservice architecture', ' aws athena', ' content management communication', 'glue', ' netconf', ' mis analyst', 'performance tuning', ' new product development', ' aws data pipeline', ' low level design', 'sql python', ' query optimization teradata', ' software engineering lead', ' driven', 'tealium', ' desktop support', ' code', ' test data', ' clinical data management', ' c / c++', ' d3', ' career development', ' proof reading', ' business planning', 'business solutions', ' freight', ' content marketing', ' dwh testing', 'firebase', ' scorecard', ' filenet', ' restapi', ' benefits evaluation', ' product placement', 'cati', ' hedge funds', ' physical verification', ' banking', ' text analytics', ' no sql db', ' orchestrators airflow', ' integration', ' white box testing', ' dream weaver', ' db modelling', 'manufacturing data scientist', ' data storage', ' technical services', ' internal communication', ' tibco', ' compliance', ' sprint boot', ' azure logic apps', ' log analysis', 'brd', ' remote sensing', ' analytics reporting', ' pyspark sql', ' demand forecasting', ' data storytelling', ' careerbuilder', ' linux server', ' computervision', ' crimsons hexagon', ' application engineering', ' hadoop v2', ' junior research analyst', ' brand marketing', 'cyber security', ' slas', ' be', ' configuration', ' client relationship', 'mis reporting', ' oracle procedural', 'time series forecasting', ' client sanctions screening', ' sql pl sql', 'data engineer', ' ihs', ' ifrs', ' dimensionality reduction', ' snaplogic', ' process efficiency', 'agile development methodologies', ' snowflake data warehouse', ' big data architecture', ' varonis', ' ses', 'angularjs', ' graph analytics', ' tensorflow', ' cloud infrastructure', ' business intelligence', ' fas', ' asic', ' machine queues', ' statistical programmer', ' designing', ' python programmer', ' content development', ' google f1', ' sabre', ' wholesale', ' artifi', ' system troubleshooting', ' consumer behaviour', 'phython', ' market data', ' redux', 'spark core', ' oracle pl / sql', ' database development', 'interpersonal skills', 'apis', ' amazon aws', 'data loader', ' dev - ops', ' prototyping', ' data science modeling', ' datawarehouse', ' qa associate', 'google tag management', ' data flow diagrams', ' mobile development', ' refrigeration', ' ssas', ' budget management', 'business services', ' web2py', ' scikit learn]', ' business intelligence tools', ' oracle designer', ' lldb', ' strategy consulting', 'ediscovery processing', ' etl tool', ' calling', 'cloud data fusion', ' reactnative', 'finance', ' hdinsight', ' sql server', ' project closure', ' test scripting', ' business enhancement', ' non functional testing', 'consulting', ' project task management', ' amazon elastic search', ' ann', ' java fs', ' manual testing', 'pmo analyst', 'composer', ' maintenance management', ' machine learning eng', ' verbal communication', ' postgresql database administration', 'kaizen', ' claims', ' multi - threading', ' middle office', 'ms - excel', 'relationship', ' dot net', ' application designing', ' decision tree learning', ' scipy', ' verbal communications', ' analytical skills', ' workflow diagrams', 'cms', ' search engine', ' query optimization', 'api', 'campaign analytics', ' record keeping', ' mongodb sql development', 'us it recruiter', ' web', ' dom', ' gcp infra', ' developer trainee', ' python coding', ' pl / sql scripting', ' elasticsearch engine', ' data scraping', ' accounting configuration', ' redshift datawarehouse', ' nlp communication', ' galue', 'azure sql dw', ' stepfunction', 'azure sql', 'c / c++', 'technology research', ' ms office tools', ' bex', ' mvc patterns', ' enterprise application integration', ' design etl pipelines', ' pega', ' vc', ' tabulation program', ' k tp', 'tam', 'rest apis', ' software development life cycle', 'tensorflow', ' flat files', ' dns', 'applied science', ' sap ewm', ' orchestration', ' aws ci / cd', ' data lakes', ' inventory', ' information', ' molecular biology', ' jsp', ' resource optimization', ' senior business analyst', 'selenium', ' indian analytics', ' proposal writing', ' mercurial', 'it services & consulting', ' kafkainput', 'sports prediction', ' power trading', ' windows workflow foundation', ' ms outlook', ' google stack reporting', ' analytical reports.', ' pl sql', 'mainframe programming', ' azure app', ' hive scripting', 'react', ' internet banking', ' sql server development', 'team lead', ' scylla', ' bi', 'project analysis', ' bulk emailing', ' web framework', ' query languages such as sql', 'toxicology', ' big data lake', ' system software development', 'mysql object oriented program', ' whitebox', ' sckit-learn', ' oracle database patching', ' pfd', ' azure events hub', 'technical training', ' synthesis', ' full-stack developer', ' ai/ml', ' web testing', ' ppts', ' techno functional', 'blended process', ' lead solution architect', ' cost accounting', 'python', ' blueprints', 'process', 'gis', ' validation', ' sas power bi', ' entity framework', ' aws ecr', ' alteryx', ' retail analytics', ' back office operations', ' bigdata sql', ' rest frameworks', ' incident response', ' s3 aws', ' microsoft data', 'process engineering', ' adms/oem', ' statistical programming', 'french', 'linkedin', 'transaction processing', ' sociology', ' investment advisory', ' microservices architecture', ' tensorflow vision', 'crm', ' axon api', ' bmc remedy', ' gcp', 'staff software engineer (full stack development - typejs/node/angular)', ' dq suite', ' koras', ' oracle data integrator', ' bi tools', ' machine learning algorithms', ' core innovation services', 'marketing strategy', 'vsam', ' reporting', ' api integration', ' supervised learning', ' tdd', ' fraud risk assessment', ' - sql', ' azure architecture', ' ms team', ' kafka rabbitmq', 'network design', ' comms', ' pricing analyst', 'mvc frameworks', ' salesforce effectiveness', ' report generation', 'storage cloud', ' dynamo db', ' cbs', 'executive leadership', ' column chromatography', 'patent drafting', ' babel', ' services', ' etl pipelines', 'my', ' django', ' core net', 'configuration management', ' gitbun ci', ' electrical engineering', 'business objects', ' test case execution', ' etl aws cloud', ' grid', 'prepayment modeling', ' global sales', 'claims', ' resource management', 'aws sagemaker', ' exploratory testing', 'google bigquery', ' talkwalker', ' report writing', 'networking', 'operational excellence', 'whitebox', ' sprint planning', ' fcm', ' vb scripting', ' vcenter', ' zabbix administration', ' side', ' biztalk', ' competitive analysis', ' sap bods', ' sketch design', 'aws glue', ' warehouse design', ' housing finance', ' capacity and availability management', ' jython', ' metagenomics', 'backup and restore', ' j2me', ' data analysis tools', ' financial products', ' biqquery', ' ahv', ' windows os', 'communication protocols', ' hubspot', ' it services', 'production support', ' mis analysis', ' data pipelines', ' server administration', ' software services', ' ruby on rails', ' web application firewall', ' c / c + +', 'spark', 'training management', 'devops', 'saas', ' sales enablement', ' accessories', ' sap hr', 'bootstrap', ' test execution', 'phoenix', ' adobe creative suite', ' language teaching', ' risk assessment', ' oracle application server', 'soft skills', ' keyword discovery', ' analog', ' agile project management', ' legal counsel', ' journal entries', 'etl', 'azure dw', ' google kubernetes', ' ms office word', ' us mortgage', ' spark rdd', ' datacenter cabling', ' sas analytics', 'metadata management', ' lan', ' six sigma green belt', ' unixlinux systems', ' scikit', ' mapping', ' effective communication skills', ' vertica', ' data flow mapping', ' financial institutions', ' microsoft power bi', ' powershell', ' resourcing', ' power', 'data analysis', ' trend analysis', ' algorithms', ' intex', ' aws analytics', ' xcode', ' hr operations', 'risk', ' component design', ' marketing communication', ' excellent communication skills', ' backend architecture', ' operations support analyst', ' supervision', ' activevos', 'j2ee', ' integration testing', ' sql scripting', ' product manager', ' project execution', 'powe bi', ' unit testing', 'power bi dashboards', ' itil', ' project documentation', ' cost controlling and analysis', ' cdn', ' azure cloud', ' ab initio etl', ' redshift aws', 'connector', ' questionnaire design', ' incident prediction model', ' benchmarking', ' circle ci', 'tsql', ' data processing executive', ' manager ii', ' google scripting', ' waste management', ' expenses', ' unix', ' iso', ' gosu scripting', ' btech', ' action plan', 'typescript', ' 9', ' power shell', ' document management', ' capital goods', ' ci / cd', 'quest', ' metabase', ' html canvas', ' legal process outsourcing', ' cloudera hadoop ecosystem', ' basel', ' resource allocation', 'api testing using soap ui', ' information gathering', ' online media', ' oracle etl', 'etl methodology', ' verint', ' channel management', ' data visualisation', 'sql - designing tables', ' native', ' wan', ' functional programming', ' aws python', 'hadoop development', ' job analysis', ' ml flows', ' vba excel', ' sql and nosql databases', 'test plan preparation', 'six sigma green belt', ' amazon kinesis', ' sales associate', ' bi analytics', 'data modeling', ' emea', ' kyc verification', ' container registry', ' deep learning model', ' spss', 'salesforce bsa', ' clm', ' bi reporting tools', 'spark sql', ' tool design', ' employee wellness', ' agile teams', ' xlsx', ' iot', ' streaming', ' maximo implementation', ' ui technologies', ' treasury', ' software quality', ' 24x7', ' informatica idq', ' financial risk', ' tech lead', ' test driven development', ' informatica 10x', ' autosys', ' brand and messages coding', 'api integration', ' core java', 'product analysis', 'operation transition', ' user administration', ' imps', 'warehouse', 'pysql', ' e-r schema modeling', 'data scientist', ' git big', 'compensation analyst', ' eda', ' data loader demand', ' flow diagrams', ' front - end', ' cloud bigtable', 'data ingestion design', 'aws redshift', ' splunk admin', ' asap', ' cplex', ' data quality services', ' quality control', ' sap businessobjects data services', ' life insurance', ' application software', ' ui / ux', ' unix shell scripts', ' .net technologies', ' sds', 'kibana', ' ca workload management', 'seo analyst', ' siemens tia portal', ' c plus plus', ' test automation framework', ' sap mm module', ' data lake gen', ' hypothesis testing', 'solution design', ' logistic regression', 'azure kubernetes', 'audacity', ' fastload', ' wireless', ' stl', ' confluent kafka', ' spoken english', ' software solution', ' sso', ' communication skills', ' lso', ' aws computing', ' fed', ' platform', ' ab initio', ' formulas', ' aws|azure| sql', ' technical documentation', ' transaction management', ' visual analytics', ' qliksense', 'consultant business analyst', ' speech synthesis', ' device driver', ' trade finance', ' e2e implementation', 'customer operations', ' autodesk', ' teradata operations', ' medical imaging', ' event engine', ' product designer', 'us healthcare', ' database architect', ' market analysis'}\n"
          ]
        }
      ],
      "source": [
        "#extraction of skills\n",
        "import pandas as pd\n",
        "df=pd.read_csv(r'/content/naukri_data_science_jobs_india.csv')\n",
        "skillset=[]\n",
        "s=[]\n",
        "for i in df[\"Skills/Description\"]:\n",
        "  x=i.lower()\n",
        "  for y in x.split(\",\"):\n",
        "    # print(x)\n",
        "    y=y.lower()\n",
        "    skillset.append(y)\n",
        "\n",
        "skillset=set(skillset)\n",
        "print(skillset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2jY4CtQByBu"
      },
      "source": [
        "**MODEL BUILDING**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#knn\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle# Load resume dataset\n",
        "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
        "\n",
        "# Handling missing values in 'Resume' column\n",
        "df['Resume'] = df['Resume'].fillna('')  # Replace NaN values with an empty string\n",
        "\n",
        "# Preprocess resume text\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "def preprocess(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['Resume'] = df['Resume'].apply(preprocess)\n",
        "\n",
        "# Extract entities\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entities = []\n",
        "    for ent in doc.ents:\n",
        "        entities.append((ent.label_, ent.text))\n",
        "    return entities\n",
        "\n",
        "df['Entities'] = df['Resume'].apply(extract_entities)\n",
        "\n",
        "# Extract skills\n",
        "SKILLS = skillset\n",
        "def extract_skills(text):\n",
        "    doc = nlp(text)\n",
        "    skills = []\n",
        "    for token in doc:\n",
        "        if token.lemma_ in SKILLS:\n",
        "            skills.append(token.lemma_)\n",
        "    return skills\n",
        "\n",
        "df['Skills'] = df['Resume'].apply(extract_skills)\n",
        "\n",
        "# Vectorize text\n",
        "tfidf = TfidfVectorizer()\n",
        "X = tfidf.fit_transform(df['Resume'])\n",
        "y = df['Category']\n",
        "\n",
        "# Train model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "clf = OneVsRestClassifier(KNeighborsClassifier())\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "# Save model\n",
        "pickle.dump(tfidf, open('vectorizer.pkl', 'wb'))\n",
        "pickle.dump(clf, open('model.pkl', 'wb'))\n"
      ],
      "metadata": {
        "id": "zzWFz3zuNF8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8604be1a-bb29-46ef-bf6e-6c27d47972c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           precision    recall  f1-score   support\n",
            "\n",
            "                 Advocate       1.00      1.00      1.00         3\n",
            "                     Arts       1.00      1.00      1.00         6\n",
            "       Automation Testing       1.00      1.00      1.00         5\n",
            "               Blockchain       1.00      1.00      1.00         7\n",
            "         Business Analyst       1.00      1.00      1.00         4\n",
            "           Civil Engineer       1.00      1.00      1.00         9\n",
            "             Data Science       1.00      0.60      0.75         5\n",
            "                 Database       1.00      1.00      1.00         8\n",
            "          DevOps Engineer       1.00      0.93      0.96        14\n",
            "         DotNet Developer       1.00      1.00      1.00         5\n",
            "            ETL Developer       1.00      1.00      1.00         7\n",
            "   Electrical Engineering       1.00      1.00      1.00         6\n",
            "                       HR       1.00      1.00      1.00        12\n",
            "                   Hadoop       1.00      1.00      1.00         4\n",
            "       Health and fitness       1.00      1.00      1.00         7\n",
            "           Java Developer       1.00      1.00      1.00        15\n",
            "      Mechanical Engineer       1.00      1.00      1.00         8\n",
            "Network Security Engineer       1.00      1.00      1.00         3\n",
            "       Operations Manager       1.00      1.00      1.00        12\n",
            "                      PMO       0.88      1.00      0.93         7\n",
            "         Python Developer       1.00      1.00      1.00        10\n",
            "            SAP Developer       0.78      1.00      0.88         7\n",
            "                    Sales       1.00      1.00      1.00         8\n",
            "                  Testing       1.00      1.00      1.00        16\n",
            "            Web Designing       1.00      1.00      1.00         5\n",
            "\n",
            "                 accuracy                           0.98       193\n",
            "                macro avg       0.99      0.98      0.98       193\n",
            "             weighted avg       0.99      0.98      0.98       193\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print training accuracy\n",
        "def predict(resume):\n",
        "    resume = preprocess(resume)\n",
        "    resume_vec = tfidf.transform([resume])\n",
        "    prediction = clf.predict(resume_vec)[0]\n",
        "    return prediction\n",
        "print(predict(x))"
      ],
      "metadata": {
        "id": "f74OtYjgNI7W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f01e2a-a1ed-49ef-b680-7b64d3c09366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Science\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#random forest\n",
        "\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle\n",
        "\n",
        "# Load resume dataset\n",
        "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
        "\n",
        "# Handling missing values in 'Resume' column\n",
        "df['Resume'] = df['Resume'].fillna('')  # Replace NaN values with an empty string\n",
        "\n",
        "# Preprocess resume text\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "def preprocess(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['Resume'] = df['Resume'].apply(preprocess)\n",
        "\n",
        "# Vectorize text\n",
        "tfidf = TfidfVectorizer()\n",
        "X = tfidf.fit_transform(df['Resume'])\n",
        "y = df['Category']\n",
        "\n",
        "# Train model with RandomForestClassifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "clf = OneVsRestClassifier(RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print training accuracy\n",
        "train_accuracy = clf.score(X_train, y_train)\n",
        "print(\"Training Accuracy: {:.2f}%\".format(train_accuracy * 100))\n",
        "\n",
        "# Save model\n",
        "pickle.dump(tfidf, open('vectorizer.pkl', 'wb'))\n",
        "pickle.dump(clf, open('model.pkl', 'wb'))\n",
        "def predict(resume):\n",
        "    resume = preprocess(resume)\n",
        "    resume_vec = tfidf.transform([resume])\n",
        "    prediction = clf.predict(resume_vec)[0]\n",
        "    return prediction\n",
        "print(predict(x))"
      ],
      "metadata": {
        "id": "GDqMbrK3NN0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1ec1ee1-9bc3-4bda-8b88-ebdab6250336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 100.00%\n",
            "Data Science\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#svm\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle\n",
        "\n",
        "# Load resume dataset\n",
        "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
        "\n",
        "# Handling missing values in 'Resume' column\n",
        "df['Resume'] = df['Resume'].fillna('')  # Replace NaN values with an empty string\n",
        "\n",
        "# Preprocess resume text\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "def preprocess(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['Resume'] = df['Resume'].apply(preprocess)\n",
        "\n",
        "# Vectorize text\n",
        "tfidf = TfidfVectorizer()\n",
        "X = tfidf.fit_transform(df['Resume'])\n",
        "y = df['Category']\n",
        "\n",
        "# Train model with Support Vector Machine (SVM)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "clf = OneVsRestClassifier(SVC(kernel='linear', C=1, probability=True, random_state=42))\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "# Print training accuracy\n",
        "train_accuracy = clf.score(X_train, y_train)\n",
        "print(\"Training Accuracy: {:.2f}%\".format(train_accuracy * 100))\n",
        "\n",
        "# Save model\n",
        "pickle.dump(tfidf, open('vectorizer.pkl', 'wb'))\n",
        "pickle.dump(clf, open('model.pkl', 'wb'))\n"
      ],
      "metadata": {
        "id": "yphkil7-NSuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "616840ae-4e70-4554-ee2f-ef20b9f141ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           precision    recall  f1-score   support\n",
            "\n",
            "                 Advocate       1.00      1.00      1.00         3\n",
            "                     Arts       1.00      1.00      1.00         6\n",
            "       Automation Testing       1.00      1.00      1.00         5\n",
            "               Blockchain       1.00      1.00      1.00         7\n",
            "         Business Analyst       1.00      1.00      1.00         4\n",
            "           Civil Engineer       1.00      1.00      1.00         9\n",
            "             Data Science       1.00      1.00      1.00         5\n",
            "                 Database       1.00      1.00      1.00         8\n",
            "          DevOps Engineer       1.00      0.93      0.96        14\n",
            "         DotNet Developer       1.00      1.00      1.00         5\n",
            "            ETL Developer       1.00      1.00      1.00         7\n",
            "   Electrical Engineering       1.00      1.00      1.00         6\n",
            "                       HR       1.00      1.00      1.00        12\n",
            "                   Hadoop       1.00      1.00      1.00         4\n",
            "       Health and fitness       1.00      1.00      1.00         7\n",
            "           Java Developer       1.00      1.00      1.00        15\n",
            "      Mechanical Engineer       1.00      1.00      1.00         8\n",
            "Network Security Engineer       1.00      1.00      1.00         3\n",
            "       Operations Manager       1.00      1.00      1.00        12\n",
            "                      PMO       0.88      1.00      0.93         7\n",
            "         Python Developer       1.00      1.00      1.00        10\n",
            "            SAP Developer       1.00      1.00      1.00         7\n",
            "                    Sales       1.00      1.00      1.00         8\n",
            "                  Testing       1.00      1.00      1.00        16\n",
            "            Web Designing       1.00      1.00      1.00         5\n",
            "\n",
            "                 accuracy                           0.99       193\n",
            "                macro avg       0.99      1.00      1.00       193\n",
            "             weighted avg       1.00      0.99      0.99       193\n",
            "\n",
            "Training Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "import pickle\n",
        "\n",
        "# Load resume dataset\n",
        "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
        "\n",
        "# Handling missing values in 'Resume' column\n",
        "df['Resume'] = df['Resume'].fillna('')  # Replace NaN values with an empty string\n",
        "\n",
        "# Preprocess resume text\n",
        "max_words = 5000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True)\n",
        "tokenizer.fit_on_texts(df['Resume'])\n",
        "X = tokenizer.texts_to_sequences(df['Resume'])\n",
        "X = pad_sequences(X, maxlen=max_len)\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['Category'])\n",
        "y = to_categorical(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the CNN model\n",
        "embedding_dim = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 30\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# Evaluate\n",
        "loss, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Save model and tokenizer\n",
        "model.save('cnn_model.h5')\n",
        "with open('tokenizer.pkl', 'wb') as token_file:\n",
        "    pickle.dump(tokenizer, token_file)"
      ],
      "metadata": {
        "id": "Fqo9ANdtNXBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be8876d3-982b-44e5-b7c3-c75f06735f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "25/25 [==============================] - 4s 121ms/step - loss: 3.1264 - accuracy: 0.1508 - val_loss: 3.0182 - val_accuracy: 0.2798\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 3s 131ms/step - loss: 2.8902 - accuracy: 0.3030 - val_loss: 2.7617 - val_accuracy: 0.3990\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 4s 169ms/step - loss: 2.5719 - accuracy: 0.3732 - val_loss: 2.3745 - val_accuracy: 0.5596\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 2s 70ms/step - loss: 2.1553 - accuracy: 0.4980 - val_loss: 1.8874 - val_accuracy: 0.6943\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 2s 69ms/step - loss: 1.7358 - accuracy: 0.6463 - val_loss: 1.4001 - val_accuracy: 0.8135\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 2s 70ms/step - loss: 1.3040 - accuracy: 0.7607 - val_loss: 0.9751 - val_accuracy: 0.8964\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 2s 69ms/step - loss: 0.9156 - accuracy: 0.8453 - val_loss: 0.6383 - val_accuracy: 0.9741\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.6742 - accuracy: 0.8817 - val_loss: 0.4214 - val_accuracy: 0.9845\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 3s 118ms/step - loss: 0.5120 - accuracy: 0.9168 - val_loss: 0.2749 - val_accuracy: 0.9845\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 2s 72ms/step - loss: 0.3706 - accuracy: 0.9337 - val_loss: 0.1761 - val_accuracy: 0.9845\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 2s 70ms/step - loss: 0.2905 - accuracy: 0.9623 - val_loss: 0.1189 - val_accuracy: 0.9948\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 2s 69ms/step - loss: 0.2463 - accuracy: 0.9532 - val_loss: 0.0879 - val_accuracy: 0.9948\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 2s 67ms/step - loss: 0.1732 - accuracy: 0.9792 - val_loss: 0.0644 - val_accuracy: 0.9948\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 2s 68ms/step - loss: 0.1602 - accuracy: 0.9766 - val_loss: 0.0519 - val_accuracy: 0.9948\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 2s 69ms/step - loss: 0.1192 - accuracy: 0.9870 - val_loss: 0.0430 - val_accuracy: 0.9948\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 3s 112ms/step - loss: 0.1133 - accuracy: 0.9909 - val_loss: 0.0366 - val_accuracy: 0.9948\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 2s 89ms/step - loss: 0.1219 - accuracy: 0.9766 - val_loss: 0.0316 - val_accuracy: 0.9948\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 2s 69ms/step - loss: 0.0938 - accuracy: 0.9857 - val_loss: 0.0298 - val_accuracy: 0.9948\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 2s 70ms/step - loss: 0.0866 - accuracy: 0.9844 - val_loss: 0.0290 - val_accuracy: 0.9948\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 2s 70ms/step - loss: 0.0769 - accuracy: 0.9844 - val_loss: 0.0273 - val_accuracy: 0.9948\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 2s 69ms/step - loss: 0.0719 - accuracy: 0.9883 - val_loss: 0.0252 - val_accuracy: 0.9948\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 2s 70ms/step - loss: 0.0705 - accuracy: 0.9883 - val_loss: 0.0253 - val_accuracy: 0.9948\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.0547 - accuracy: 0.9883 - val_loss: 0.0248 - val_accuracy: 0.9948\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 3s 108ms/step - loss: 0.0481 - accuracy: 0.9948 - val_loss: 0.0242 - val_accuracy: 0.9948\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 2s 69ms/step - loss: 0.0570 - accuracy: 0.9935 - val_loss: 0.0239 - val_accuracy: 0.9948\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 2s 70ms/step - loss: 0.0481 - accuracy: 0.9909 - val_loss: 0.0212 - val_accuracy: 0.9948\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 2s 71ms/step - loss: 0.0420 - accuracy: 0.9896 - val_loss: 0.0221 - val_accuracy: 0.9948\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 2s 67ms/step - loss: 0.0431 - accuracy: 0.9909 - val_loss: 0.0224 - val_accuracy: 0.9948\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 2s 68ms/step - loss: 0.0451 - accuracy: 0.9935 - val_loss: 0.0215 - val_accuracy: 0.9948\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 2s 85ms/step - loss: 0.0493 - accuracy: 0.9896 - val_loss: 0.0211 - val_accuracy: 0.9948\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0211 - accuracy: 0.9948\n",
            "Test Loss: 0.021054822951555252\n",
            "Test Accuracy: 0.9948186278343201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "\n",
        "# Load the saved CNN model\n",
        "model = load_model('cnn_model.h5')\n",
        "\n",
        "# Load the saved tokenizer\n",
        "with open('tokenizer.pkl', 'rb') as token_file:\n",
        "    tokenizer = pickle.load(token_file)\n",
        "\n",
        "# Function to predict category for a single resume text\n",
        "def predict_category(resume_text):\n",
        "    # Preprocess the input resume\n",
        "    max_len = 200\n",
        "    X_input = tokenizer.texts_to_sequences([resume_text])\n",
        "    X_input = pad_sequences(X_input, maxlen=max_len)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(X_input)[0]\n",
        "\n",
        "    # Convert prediction to category label using the label encoder\n",
        "    predicted_label = label_encoder.inverse_transform([prediction.argmax()])[0]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Example usage\n",
        "input_resume = x11\n",
        "predicted_category = predict_category(input_resume)\n",
        "\n",
        "print(f\"Predicted Category: {predicted_category}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF8EAP2DKsfD",
        "outputId": "58d2819a-e7f4-4a85-df2e-41d2b9d2774f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 125ms/step\n",
            "Predicted Category: Data Science\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bert\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load resume dataset\n",
        "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
        "\n",
        "# Handling missing values in 'Resume' column\n",
        "df['Resume'] = df['Resume'].fillna('')  # Replace NaN values with an empty string\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Category'] = label_encoder.fit_transform(df['Category'])\n",
        "\n",
        "# Train-test split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# BERT Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Tokenize and encode the training data\n",
        "train_texts = train_df['Resume'].tolist()\n",
        "train_labels = torch.tensor(train_df['Category'].tolist())\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
        "\n",
        "# Tokenize and encode the test data\n",
        "test_texts = test_df['Resume'].tolist()\n",
        "test_labels = torch.tensor(test_df['Category'].tolist())\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
        "\n",
        "# Create PyTorch datasets\n",
        "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
        "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\n",
        "\n",
        "# DataLoader for training and testing data\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# BERT Model for Sequence Classification\n",
        "class BertClassifier(nn.Module):\n",
        "    def __init__(self, num_labels=10):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        return outputs.logits\n",
        "\n",
        "# Initialize the model\n",
        "model = BertClassifier(num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * 2)\n",
        "\n",
        "# Training loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "num_epochs = 2\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch in tqdm(train_loader, desc=\"Epoch {}\".format(epoch + 1)):\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = F.cross_entropy(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(\"Epoch {}: Average Loss: {:.4f}\".format(epoch + 1, avg_loss))\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "correct_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = F.cross_entropy(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "        correct_predictions += (predictions == labels).sum().item()\n",
        "\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "accuracy = correct_predictions / len(test_dataset)\n",
        "\n",
        "print(\"Test Loss: {:.4f}\".format(avg_test_loss))\n",
        "print(\"Test Accuracy: {:.2%}\".format(accuracy))\n",
        "\n",
        "# Save model and tokenizer\n",
        "model.save_pretrained('bert_model')\n",
        "tokenizer.save_pretrained('bert_model')\n",
        "label_encoder.classes_ = list(label_encoder.classes_)  # Convert numpy array to list\n",
        "with open('label_encoder.pkl', 'wb') as label_encoder_file:\n",
        "    pickle.dump(label_encoder, label_encoder_file)\n"
      ],
      "metadata": {
        "id": "r9qtXW2nNgjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbToljHX2ziK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d602d7-21e6-4976-bb7b-94501f91bfef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRINAGA JATHIN P\n",
            "♂phone+91 7259326923 /envel⌢peJathinp2019@gmail.com /envel⌢pe22f3002189@ds.study.iitm.ac.in /linkedinLinkedIn /githubGitHub\n",
            "EDUCATION:\n",
            "Amrita School of Engineering Oct. 2020 – May 2024\n",
            "Bachelor of Technology in Computer Science Engineering; CGPA: 8.62/10.0 Bengaluru, India\n",
            "Indian Institute of Technology Sept. 2022 – May 2025\n",
            "Bachelor of Science in Programming and Data Science; CGPA: 7.67/10.0 Madras, India\n",
            "Indian Institute of Technology Sept. 2022 – May 2024\n",
            "Artificial Intelligence and Machine Learning Kanpur, India\n",
            "TECHNICAL SKILLS:\n",
            "Languages : JavaScript, HTML/CSS, Python, Java\n",
            "Technologies/Frameworks : Express, React, Angular, MongoDB, Git, AWS, MySQL, Splunk, AWS\n",
            "Developer Tools and Methodologies : VS Code, Jupyter Notebook, GitHub, JIRA, Agile, Waterfall, Extreme Programming\n",
            "PROJECTS:\n",
            "Techie Corner |MERN stack GitHub\n",
            "•Engineered an integrated university portal enabling 10k+ students to access academics, payments and learning through a MERN and\n",
            "Flask application.\n",
            "•Reduced login failures by 30 % implementing JWT authorization, enhancing student experience and security.\n",
            "•Integrated Stripe API to enable seamless fee payments including tuition, bus and housing.\n",
            "•Created a React quiz portal with Flask backend enabling real-time sync of test scores to student dashboards\n",
            "•Built a simple text editor to download notes as .txt files and customized UI components using React libraries\n",
            "Consumer Review Analyser |Machine Learning GitHub\n",
            "•Developed an XGBoost model predicting consumer dispute risk using 400,000+ real complaint records.\n",
            "•Improved dispute prediction accuracy by 5% over baseline through rigorous EDA, algorithm selection and hyperparameter tuning.\n",
            "•Constructed an end-to-end ML pipeline enabling seamless batch and real-time predictions on new complaints.\n",
            "•Operationalized model inferences to provide actionable dispute risk forecasts for consumer finance complaints.\n",
            "Text Analyser |NLP , Python , Flask GitHub\n",
            "•Created a modular web application enabling plagiarism detection, text summarization, paraphrasing and grammar correction.\n",
            "•Combined rule-based techniques and ML models like TextRank and BERT to ensure over 90% accuracy across NLP tasks.\n",
            "•Designed an intuitive UI for users to seamlessly access multiple text analysis features through one platform.\n",
            "•Operationalized NLP microservices for plagiarism checking, summarization and paraphrasing using Python, NLTK and TensorFlow.\n",
            "Wizarts - Art Display Webpage |HTML, CSS, Github Pages GitHub Link\n",
            "•Designed an art gallery web app showcasing artwork from 50+ amateur artists using HTML, CSS and JavaScript.\n",
            "•Led development of responsive UI and core pages ensuring smooth user experience.\n",
            "•Managed CI/CD pipelines and GitHub Pages deployment for rapid iterations and collaboration.\n",
            "CO-CURRICULAR:\n",
            "Computer Society of India Feb. 2023 – Present\n",
            "President Bengaluru:\n",
            "Kala - The art club June 2022 – August 2022\n",
            "Executive Bengaluru:\n",
            "CERTIFICATIONS:\n",
            "•Hacker-rank- Analytic.\n",
            "•Hacker-rank - Java\n",
            "•MongoDB - Basics.\n",
            "•MongoDB - Diagnostic thinking.\n",
            "•AWS Academy Graduate - AWS Academy Introduction to Cloud Semester 1\n",
            "•Amazon Web Services - AWS Foundation\n",
            "•Google Cloud Platform -Associate Cloud Engineer\n",
            "•Simpli-learn : Associate AWS Cloud Developer\n",
            "•Simpli-learn : CompTIA Linux+\n",
            "•Splunk 7.x Fundamentals\n"
          ]
        }
      ],
      "source": [
        "#extraction of important details\n",
        "def add_colon_to_short_lines(resume_text):\n",
        "    lines = resume_text.split('\\n')\n",
        "    modified_lines = []\n",
        "\n",
        "    for line in lines:\n",
        "\n",
        "        words = line.split()\n",
        "        if len(words) in [1, 2]:\n",
        "\n",
        "            if (all(word.isupper() for word in words) or (len(words) == 1 and words[0].istitle()) or (len(words) == 2 and words[0].istitle())) and line[-1].isalpha():\n",
        "                # Add a colon to the end of the line\n",
        "                line += ':'\n",
        "        modified_lines.append(line)\n",
        "\n",
        "\n",
        "    modified_resume = '\\n'.join(modified_lines)\n",
        "    return modified_resume\n",
        "\n",
        "\n",
        "\n",
        "modified_resume = add_colon_to_short_lines(x11)\n",
        "print(modified_resume)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VMvp11g25v2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15029e12-706b-4ebc-b01d-974a2772dc30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Headings: ['EDUCATION', 'TECHNICAL SKILLS', 'PROJECTS', 'CO-CURRICULAR', 'President Bengaluru', 'Executive Bengaluru', 'CERTIFICATIONS']\n"
          ]
        }
      ],
      "source": [
        "def extract_headings(resume_text):\n",
        "    lines = resume_text.split('\\n')\n",
        "    headings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Check if the line contains one or two words\n",
        "        words = line.split()\n",
        "        if len(words) in [1, 2]:\n",
        "            # Check if either all words are in uppercase or the first letter of the first word is capitalized\n",
        "            if (all(word.isupper() for word in words) or (len(words) == 1 and words[0].istitle()) or (len(words) == 2 and words[0].istitle())) and line[-1].isalpha():\n",
        "                # Add the line to the headings list\n",
        "                headings.append(line)\n",
        "\n",
        "    return headings\n",
        "\n",
        "\n",
        "\n",
        "headings = extract_headings(x11)\n",
        "print(\"Headings:\",headings)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2E8GlJK23PdM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787fcddb-5fe4-4b0c-dd9d-2b47cabe4870"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Education:\n",
            "Amrita School of Engineering Oct. 2020 – May 2024 \n",
            " Bachelor of Technology in Computer Science Engineering ; CGPA : 8.62/10.0 Bengaluru , India \n",
            " Indian Institute of Technology Sept. 2022 – May 2025 \n",
            " Bachelor of Science in Programming and Data Science ; CGPA : 7.67/10.0 Madras , India \n",
            " Indian Institute of Technology Sept. 2022 – May 2024 \n",
            " Artificial Intelligence and Machine Learning Kanpur , India \n",
            " TECHNICAL\n",
            "\n",
            "Skills:\n",
            "Languages : JavaScript , HTML / CSS , Python , Java \n",
            " Technologies / Frameworks : Express , React , Angular , MongoDB , Git , AWS , MySQL , Splunk , AWS \n",
            " Developer Tools and Methodologies : VS Code , Jupyter Notebook , GitHub , JIRA , Agile , Waterfall , Extreme Programming\n",
            "\n",
            "Projects:\n",
            "Techie Corner |MERN stack GitHub \n",
            " •Engineered an integrated university portal enabling 10k+ students to access academics , payments and learning through a MERN and \n",
            " Flask application . \n",
            " •Reduced login failures by 30 % implementing JWT authorization , enhancing student experience and security . \n",
            " •Integrated Stripe API to enable seamless fee payments including tuition , bus and housing . \n",
            " •Created a React quiz portal with Flask backend enabling real - time sync of test scores to student dashboards \n",
            " •Built a simple text editor to download notes as .txt files and customized UI components using React libraries \n",
            " Consumer Review Analyser |Machine Learning GitHub \n",
            " •Developed an XGBoost model predicting consumer dispute risk using 400,000 + real complaint records . \n",
            " •Improved dispute prediction accuracy by 5 % over baseline through rigorous EDA , algorithm selection and hyperparameter tuning . \n",
            " •Constructed an end - to - end ML pipeline enabling seamless batch and real - time predictions on new complaints . \n",
            " •Operationalized model inferences to provide actionable dispute risk forecasts for consumer finance complaints . \n",
            " Text Analyser |NLP , Python , Flask GitHub \n",
            " •Created a modular web application enabling plagiarism detection , text summarization , paraphrasing and grammar correction . \n",
            " •Combined rule - based techniques and ML models like TextRank and BERT to ensure over 90 % accuracy across NLP tasks . \n",
            " •Designed an intuitive UI for users to seamlessly access multiple text analysis features through one platform . \n",
            " •Operationalized NLP microservices for plagiarism checking , summarization and paraphrasing using Python , NLTK and TensorFlow . \n",
            " Wizarts - Art Display Webpage |HTML , CSS , Github Pages GitHub Link \n",
            " •Designed an art gallery web app showcasing artwork from 50 + amateur artists using HTML , CSS and JavaScript . \n",
            " •Led development of responsive UI and core pages ensuring smooth user experience . \n",
            " •Managed CI / CD pipelines and GitHub Pages deployment for rapid iterations and collaboration . \n",
            " CO - CURRICULAR \n",
            " Computer Society of India Feb. 2023 – Present \n",
            " President Bengaluru \n",
            " Kala - The art club June 2022 – August 2022 \n",
            " Executive Bengaluru \n",
            " CERTIFICATIONS \n",
            " •Hacker - rank- Analytic . \n",
            " •Hacker - rank - Java \n",
            " •MongoDB - Basics . \n",
            " •MongoDB - Diagnostic thinking . \n",
            " •AWS Academy Graduate - AWS Academy Introduction to Cloud Semester 1 \n",
            " •Amazon Web Services - AWS Foundation \n",
            " •Google Cloud Platform -Associate Cloud Engineer \n",
            " •Simpli - learn : Associate AWS Cloud Developer \n",
            " •Simpli - learn : CompTIA Linux+ \n",
            " •Splunk 7.x Fundamentals\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Using spaCy for pattern matching\n",
        "import spacy\n",
        "def extract_headings_and_content_spacy(resume_text, headings):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(resume_text)\n",
        "\n",
        "    extracted_data = {}\n",
        "    current_heading = None\n",
        "\n",
        "    for token in doc:\n",
        "\n",
        "        matches = [heading for heading in headings if heading.lower() in token.text.lower()]\n",
        "\n",
        "        if matches:\n",
        "\n",
        "            current_heading = matches[0]\n",
        "            extracted_data[current_heading] = ''\n",
        "        elif current_heading is not None:\n",
        "\n",
        "            extracted_data[current_heading] += token.text + ' '\n",
        "\n",
        "\n",
        "            if any(phrase.lower() in token.text.lower() for phrase in headings):\n",
        "                break\n",
        "\n",
        "\n",
        "    for heading, content in extracted_data.items():\n",
        "        extracted_data[heading] = content.strip()\n",
        "\n",
        "    s = \"\\n\".join([f\"{heading}:\\n{content}\\n\" for heading, content in extracted_data.items()])\n",
        "\n",
        "    return s\n",
        "\n",
        "\n",
        "headings_to_extract = ['Skills', 'Education', 'Work Experience', 'Projects']\n",
        "\n",
        "result_string = extract_headings_and_content_spacy(x11, headings_to_extract)\n",
        "print(result_string)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIWbJT7dlzX7"
      },
      "source": [
        "New Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7sUnlqXkyU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0440f172-fe58-4ee2-a939-669ad878a5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity using Word2Vec: 19.343599677085876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Example texts\n",
        "# job = \"Machine learning is a subfield of artificial intelligence.\"\n",
        "# x11 = \"Artificial intelligence involves machines that can perform tasks that typically require human intelligence.\"\n",
        "\n",
        "# Tokenize and remove stop words\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word.lower() for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
        "    return filtered_tokens\n",
        "\n",
        "job_tokens = preprocess_text(job)\n",
        "x11_tokens = preprocess_text(x11)\n",
        "\n",
        "# Train Word2Vec model\n",
        "all_tokens = [job_tokens, x11_tokens]\n",
        "model = Word2Vec(all_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Function to vectorize a text using Word2Vec\n",
        "def vectorize_text(text, model):\n",
        "    vectorized_text = []\n",
        "    for word in text:\n",
        "        if word in model.wv:\n",
        "            vectorized_text.append(model.wv[word])\n",
        "    return np.mean(vectorized_text, axis=0)\n",
        "\n",
        "# Vectorize texts using Word2Vec\n",
        "vectorized_job = vectorize_text(job_tokens, model)\n",
        "vectorized_x11 = vectorize_text(x11_tokens, model)\n",
        "\n",
        "# Calculate cosine similarity\n",
        "cosine_similarity_value = cosine_similarity([vectorized_job], [vectorized_x11])[0][0]\n",
        "match_percentage = cosine_similarity_value * 100\n",
        "matchpercentage=match_percentage\n",
        "print(\"Cosine Similarity using Word2Vec:\", match_percentage)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#resume scoring\n",
        "#resume scoring\n",
        "import math\n",
        "\n",
        "skill_scores = {\n",
        "    'python': 10,\n",
        "    'machine learning': 8,\n",
        "    'data analysis': 6,\n",
        "    'communication skills': 8,\n",
        "    'teamwork': 7,\n",
        "    'java': 7,\n",
        "    'cloud computing': 8,\n",
        "    'problem solving': 9,\n",
        "    'project management': 7,\n",
        "    'sql': 7,\n",
        "    'tensorflow': 9,\n",
        "    'deep learning': 9,\n",
        "    'leadership': 8,\n",
        "    'agile': 8,\n",
        "    'critical thinking': 9,\n",
        "    'research': 7,\n",
        "    'frontend development': 8,\n",
        "    'backend development': 8,\n",
        "    'web development': 8,\n",
        "    'database design': 7,\n",
        "    'networking': 7,\n",
        "    'security': 8,\n",
        "    'natural language processing': 9,\n",
        "    'computer vision': 9,\n",
        "    'data engineering': 8,\n",
        "    'data visualization': 8,\n",
        "    'statistics': 7,\n",
        "\n",
        "    'technical writing': 7,\n",
        "    'technical support': 6,\n",
        "    'time management': 8,\n",
        "    'multitasking': 7,\n",
        "\n",
        "    'adaptability': 9,\n",
        "    'strategic planning': 8,\n",
        "    'collaboration': 8,\n",
        "    'public speaking': 8,\n",
        "    'mentoring': 8,\n",
        "\n",
        "\n",
        "    'quality assurance': 7,\n",
        "    'UX/UI design': 8,\n",
        "\n",
        "    \"bachelors degree\": 5,\n",
        "    \"btech\": 5,\n",
        "    \"mtech\": 7,\n",
        "    \"masters\": 7,\n",
        "    \"phd\": 10,\n",
        "\n",
        "    \"Cisco Certified Network Associate (CCNA)\": 7,\n",
        "    \"Cisco Certified Network Professional (CCNP)\": 8,\n",
        "    \"Certified Information Systems Security Professional (CISSP)\": 9,\n",
        "    \"Certified Ethical Hacker (CEH)\": 8,\n",
        "    \"AWS Certified Solutions Architect\": 8,\n",
        "    \"AWS Certified Developer\": 7,\n",
        "    \"AWS Certified SysOps Administrator\": 8,\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "import spacy\n",
        "c= 0\n",
        "def score_resume(resume, phrases_and_scores):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    global c\n",
        "    # Process the resume text with spaCy\n",
        "    doc = nlp(resume.lower())\n",
        "\n",
        "    total_score = 0\n",
        "    for phrase, score in phrases_and_scores.items():\n",
        "        # Process the phrase with spaCy\n",
        "        phrase_doc = nlp(phrase.lower())\n",
        "\n",
        "        # Check for exact match\n",
        "        if phrase_doc.text in doc.text:\n",
        "            total_score += score\n",
        "            c+=1\n",
        "        else:\n",
        "            # Check for similarity\n",
        "            similarity = doc.similarity(phrase_doc)\n",
        "            if similarity > 0.3:  # Adjust the threshold as needed\n",
        "                total_score += score * similarity\n",
        "                c=c+1\n",
        "\n",
        "    return math.ceil(total_score/c*10)\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "\n",
        "result = score_resume(x11, skill_scores)\n",
        "print(\"Resume Score:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quQugW0fTJe2",
        "outputId": "3d09d920-b028-4a95-ca84-59363fa84a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume Score: 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdgZ5_61uwQ9"
      },
      "outputs": [],
      "source": [
        "#reading skills == naukri\n",
        "import pandas as pd\n",
        "df=pd.read_csv(r'/content/naukri_data_science_jobs_india.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzE_vE6yB0cs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15631b46-0baa-4d85-f896-e0aa712b24e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ms sql server tools', ' university', ' business case', ' bsc', ' opensource technologies', 'payroll', ' sql stored procedures', ' aws gateway', ' 3nf principles', 'brs', ' sap abap', ' microcontroller', ' clinical sas programming', ' documentation', 'python/spark/sql', 'version control', ' aws redshift', 'tracking', 'structural engineering', 'node js', ' discoverorg', ' webservices', ' technical training', 'ms sql server', ' azure synapse pool', ' google tag manager', ' construction', ' vmware and/or kubernetes', ' gcp/azure/aws db', ' elasticstack', ' insights', ' geoinformatics', ' strategy', ' big table', ' multi - tenancy', ' siebel', 'tally', ' rake', 'data models', ' survey design', ' system scalability', 'core python', 'pyspark', ' arc', 'accounting', ' fsd', ' compensation analysis', ' microsoft applications', ' rich snippets', ' market risk analyst', 'professional', ' maintenance', 'requirement gathering', ' digital campaigns', ' scalability', ' monte carlo simulation', ' schedule efficiency', ' redhat linux', 'data structure & algorithm', ' ats', ' microsoft office applications', ' marketing support', ' leadership', 'nunit', ' star', 'new relic', 'etl / elt', 'credit analyst', ' opencv', ' mysql dba', ' patent landscaping', ' product planning', ' team coordination', ' bonds', 'react.js', ' automation design', 'front office', ' agile development', 'supervisor', ' multi - threaded', ' site monitoring', ' patch management', ' hse management system', ' c#', 'scrum master', 'sas enterprise miner', 'maven', 'iis', ' load balancers', ' revenue operations', 'azure database', ' manager internal audit', ' online research', ' couchbase', ' administration', 'microsoft dynamics', ' collection', \" 'java\", ' android studio', 'sql server analysis services', ' ci / cd pipeline', ' object oriented development', ' statistical data analysis', ' chaid', ' pep', ' tensorflow /pytorch', ' microsoft azure analytics services', ' data architect gcp & bigquery rdbms', 'ux', 'scheduling', ' audit compliance', ' python data science', ' time series forecasting', ' c# net', 'it services', 'machine learning development', ' story writing', ' inhouse sales', ' soql bi', 'sql development', ' and databricks', ' azure data bricks', ' heat exchangers', ' computational chemistry', ' engineering mathematics', ' modeling', 'tabluea', ' user management section', 'process documentation', ' data enterprise', ' stakeholders management', 'renewable energy', ' pytest', ' bi engineering', ' hbase', ' c suite', ' business strategy', 'quantity conversions', ' owasp', ' azure cloud systems', 'data lake', 'clinical data analyst', ' service level', ' pricing analytics', ' software design', ' ubuntu', ' mpp', ' idq', ' microsoft office suite', ' catering', 'hr function dynamics', ' business consultant', 'water testing', ' nodejs framework', ' dashboard tools', 'ifrs/us gaap', ' effects analysis', ' backend operations', ' registry', ' visa processing', ' calypso', ' gsm', ' sparkml', 'infopath', 'time series', ' oracle vcp', ' glue pyspark', 'webservices', ' java or python', ' contact discovery', ' product analysis', 'sas eg', ' redshift sql', ' gam', ' multi - tier', ' scd', ' it service management support', ' angular framework', ' sr. spec', ' cloud security', ' python for data science', ' map reduce', ' join', ' system engineering', ' aws sns', 'illustrator', ' cloud native', 'scipy', 'data science pytorch', ' excellent english', ' art', 'microservices architecture', ' order to cash', ' claims adjudication', ' azure storage', ' azure data', ' databricksetl', ' jar', ' sponsorship', ' react.js', 'keras', ' school', ' sox compliance', ' project support', ' profiler activity', ' regression analysis', ' pair programming', 'tcad', 'conceptual modelling', 'hr systems', ' sap is', ' superset', ' sql server cluster', ' strong interpersonal skills', 'excel vba', ' sql code', ' writing skills', 'tableau', 'service level', 'data annotation', ' core spark', ' market sizing', ' system implementation', ' test planning', ' test reporting', 'content', ' customer retention', ' bacs', 'reltio', ' electronics design', 'cmm', ' random forest', ' pytorch4', ' salesforce crm', 'tibco spotfire', ' application', ' sap extended warehouse management', ' loan services', 'ciem', ' downstream', 'azure spark', ' lstms', ' development lead', ' aws transfer family', ' hadoop development', ' application lead', ' product', ' b2b marketing', ' startup', ' big data warehousing', ' architecting', ' storm', ' event monitoring', ' countif', ' esb', ' model', 'datastage', 'storyteller', 'apache solr', ' opportunity assessment', ' azureml', 'wealth management', ' hlookup', ' elastic stack', ' maximo data model', ' cloud data', ' dimension', ' r & d', ' energy', ' ssrs', 'rest api', 'presentation skills', ' social media analyst', ' k8s', ' tax advisor', ' o2c', ' distribution systemx', ' statistical techniques', ' access management', ' nsq', ' thermal', ' sap bw abap', ' java ee', ' spatial data analysis', ' reinsurance', ' radar', ' condition monitoring', ' e commerce', ' big data engineer - etl', ' data storage and retrieval', ' html and css', 'computer science', ' maven', ' electrical design', 'er diagram', 'bid management', 'sql server integration services', ' data scientist', ' legal compliance', ' software development methodologies', ' data cloud', ' hadoop file system', ' react native development', ' physics', ' query management', 'the', ' enterprise reporting', 'presales', ' management associate', ' ds', 'msk', ' jaxb', ' project management certified professional', ' spark/scala', ' microsoft sql server 2008', ' cobol', 'leadership training', ' soa', ' golang', 'python developer', ' design development', ' big data technology stack administration', ' document review', ' software troubleshooting', ' product design', ' veeva vault platform', ' organizational development', ' data virtualization', ' automated testing', ' mobile development life cycle', ' data cleansing', ' customer complaints', 'due diligence', ' saas platform on aws', ' bss', ' processor', ' it risk', ' designing and developing extract', ' tsql', 'tqm', ' flask apis', ' aml', 'full-stack dev', ' on page', ' vlan configuration', ' forecasting', ' quality systems', 'customer experience', ' audit', 'leadership development', ' functional safety', 'natural language processing', ' transaction analysis', ' iso 27001', 'google data studio', ' sql', ' big data data modeling', ' advanced excel formulas', ' subject matter expert', 'digital operations', 'characterization', 'congos', 'veeva', 'data automation', ' data gathering', 'big data engineering', ' system development', ' online sales', ' cloud databases', ' profit growth', ' mule esb', 'mlops', 'visualization', ' bcom', ' sql analyst', ' asp net mvc', ' rnns', ' webpack', ' r python', ' structures', ' data evaluation', ' monthly reports', ' gaap', ' integration runtime services', ' change management', ' big data application development', ' amrut', ' media research', ' service now', 'performance management', ' sap bo', ' audits', 'database maintenance', ' puppet', ' blazemeter', ' associate director', 'performance analyst', ' board design', ' ui', ' xcuitest', ' data research', ' celery', ' uml', ' litigation', ' factiva', ' control mapping', ' platform manager', ' l2 support', ' talend development', ' azure pipelines', 'azure data factory pyspark databricks adls azure sql database python/scala sql', 'business administration', 'mdm', ' layout design', ' jar file', ' production', ' hydrocarbon product management', ' sdlc', ' consultant business analyst', ' people development', ' amazon s3', ' nlu', ' gcp data engineer', 'dev - analysis', 'ambassador platforms', 'unix', ' multi-omics data processing', 'data federation', ' beanshell scripting', ' php', ' graduate', 'economics', ' sow', ' master data management', 'knime', ' wps', ' collibratool', 'web services testing', ' mqtt', ' data lake analytics', ' sem', ' pivotal', ' ms sql server reporting services', ' application monitoring', ' time', ' business process automation', ' analysing data', 'analyst', ' articleship', ' it analyst', ' tableau reporting', ' rbac controls', ' a+', ' error analysis', ' ssrs report writer', 'greenplum', 'document review', ' or aws', 'flask', 'post production', ' fiddler', 'core java programming', 'r', ' dockers', 'advanced analysis', 'data integrity', ' test lead', 'gitlab', ' blockchain', 'fnd', ' cisco routers', ' allscripts', ' pdm', ' quality operations', 'mobile application development', ' data migration', ' c/c++', ' ibm data stage', ' business requirements', ' confluence', ' project development', 'ai/ml', 'restful', ' data bases', 'quantitative research', ' fdmee', 'research and development', ' soap apis', ' ipv6', ' charles river', ' ai modeling', ' er builder', ' glue catalog', 'rdbms/plsql/stored procedures oracle-10/11g sap hana data warehouse', 'consumer research', ' it asset management', ' corporate strategy', 'attentive listener', 'puppet', 'python web scraping', ' glue job', ' azure data stack', ' project schedules', ' hive', ' shell script', ' isms', 'remote access', 'billing', ' agile scrum', ' structure', ' gathering', ' datastudio', ' eviews', ' api testing', ' trillium', ' ppap', ' credit control', 'spring', ' sdwan', ' datastage', 'transaction monitoring', ' azure data lake gen2', 'system testing', ' rbdms', 'data warehousing', ' grpc', ' engineering services', ' reporting tool', 'quality assurance analyst', ' power bi desktop', ' physical design', ' application design', ' loan document', 'compensation benchmarking', ' six sigma', ' machine learning modelling', ' trading', ' object - oriented', 'python sql aws', 'github', ' email', ' cdh', 'email', ' advanced', ' tomcat', ' source system analysis', ' quantitative techniques', 'data curation', 'graphic designing', 'corporate actions', 'frontend development', ' senior quantitative analyst', ' crystal reports', ' data generation', ' management consulting', ' data reporting', ' bigdata frameworks', ' rpa', ' equity', ' vsts', 'edm', ' human resources', ' technology architecture', ' sales management', ' azure cloud platform', ' data sharing', ' options', ' azure repos', ' ms visual', ' kakfa', 'user research', ' db using nosql', ' deep learning stack', 'synthetic data generation', ' product training', ' wellness', ' architects', ' dt&el', ' data studiotableau', ' javamr', ' macro', ' red', ' inventory control', 'esi data processing', 'soap ui', ' email etiquette', ' implementation analyst', 'data dictionary', ' excel macro', ' jenkin', 'manager internal audit', ' cost trend analysis', 'accessories', 'informatica powercenter', ' alteyrix', ' document verification', ' query database', ' google', 'marketing research', ' cocoa apis', 'software installation', ' github', ' backend engineering', ' pcie', ' sap fieldglass', ' program management', ' consumer electronics', ' siem', ' dashboard reporting', ' azure machine learning', ' business technical analyst', ' bert', ' r&d scientist', ' wcf', ' decision making', ' wb/dpd form', ' aws lambda', ' hyperion essbase', 'airflow', ' process expert', ' withs3', 'data architecture principles', ' uat', ' consulting bfsi', ' accounts', 'kdb', ' pbm domain', ' security analyst', ' scikit - learn', ' metadata', ' datalab', ' pl/sql and standard rdbmss', 'six sigma', ' sql server db', ' process automation', ' splunk', ' quantitative', ' c# sharp', ' bsc it', ' representative', ' skin care', ' factory', ' post production', ' profitability & cost management', 'simulation', 'high throughput computational screening', ' inbound', ' mpm', ' uc4', ' solution design', 'qt', ' cognos reporting', ' cognito', 'performance turning', ' ansible', ' sql script', 'modeling risk', ' rollovers', 'neural networks', ' electronic trading', ' contract management', ' project life cycle', ' hazop', ' brainstorming', ' aws virtual private cloud', ' circuit designing', ' cobit', ' process analyst', ' checkpointt', ' mechanical engineering', ' ir fx', ' ml analytics', ' messaging framework', ' data architecture', 'd365', ' adobe marketing cloud', 'sap hana', 'pl / sql', ' data feed', ' software solutions', ' mi report development', ' scrum setup', ' technical management', ' access controls', ' mdm with informatica', ' database associate', ' aws cloud native', ' full time', ' web services development', 'angular', ' cloning', ' credit risk', ' process simulation', ' accounting entries', ' medical billing', ' ltmc', ' good with numbers', ' consulting - healthcare', ' product management', 'verbal communication', ' serving notice period', ' data warehousing architecture', ' ssms', ' 4g', ' sap mdm', 'data structures', ' commerce', 'assurance', ' business economics', ' vista', ' futures', ' fastapi', ' vms', ' ip', ' etls', 'google pub', ' sap sales', ' operational support', ' scrum', ' requirements gathering', ' root - cause analysis', ' power query', ' analyzing data', ' senior software engineer', ' internship', ' nlb', ' cross selling', ' relational databases', ' programming skills', ' system programming', ' strategic leadership', ' account opening', 'sap bods', ' talendsuite', ' process integration engineer', ' advanced iam', ' financial spreading', ' cspm', ' weka', ' open cv', ' defect tracking', ' otb', ' debtors', 'etls', ' firehose', 'software estimation', ' hbase database', 'know your customer', ' ipo', ' report studio', ' process improvement', ' digital transformation', ' manufacturing operations', 'full stack', ' key account management', ' machine learning engineer', ' interaction design', ' pricing strategy', ' data insight', ' big query ml', ' methods', ' it project management', ' haveaws', ' test case review', ' msp', 'technical analysis', 'r program', ' couchdb', ' vlookup', ' azure storage explorer', 'hcm', ' big -', ' synapze pipeline', ' prototype design', 'kafka', 'w2', ' android ndk', ' customer experience', ' allegro', ' sez', ' google app engine', ' azure cloud architecture', 'computer hardware', ' edc', 'operations', ' python programming', 'expense management', ' modem', 'data analytics', ' user acceptance testing', ' mulesoft anypoint api platform', 'tsql queries', ' sql dbs', ' less', ' change delivery', ' advanced statistics', ' occupational health', ' bluetooth', ' azure stream analytics', ' image analytics', 'product costing', ' cloud sql', ' audio editing', ' ui architecture', ' financial markets', ' agent based modeling', ' regulatory projects', 'it strategy planning', ' data optimization', ' dask', ' cloud functions', ' wet stock business', ' risk assessments', 'ratio analysis', ' sap oracle db', ' written', ' pu-sub', 'data pipelining', 'competitive analysis', ' loans', ' patent analyst', ' jango', ' tws', 'product data management', ' portfolio reconciliation', ' strategic thinking', ' html;javascript', ' flux', 'cloud formation aws', ' quality assurance analyst', ' bloomberg', 'amazon redshift', 'data cleaning', ' platform architecture', ' pass', ' assistant vice president operations', 'research', ' azure cloud data', 'associate operations', 'satisfaction', 'data research analyst', ' r coding', ' performance turning', ' trade support', ' sap pi', 'microsoft', 'microsoft word', ' data lake', ' reinforcement learning', ' associate business analyst', ' private equity', ' elk', 'aml analyst', ' personal care', ' hyper converge', 'teradata bi', ' ca', ' itsm', 'android sdk', 'business data analyst', ' azure blob', ' marketing research analyst', ' cash management analyst', ' head design', ' salesforce administrator', ' tableau/power bi', ' channel business', 'red hat linux', ' dms', ' cctv', ' dts', 'coin', ' rally', ' retail business', ' troubleshooting', ' sensors', ' telematics', ' contact center', ' scala hadoop', ' buying team', 'spark with aws', ' pythonprogramming', 'service management', ' plotly', ' js', 'customer service', ' logical and analytical ability', ' mapr', ' machinery', ' dealing', ' cyber security', ' cdp', ' transfer pricing', ' direct marketing', ' veeva rep survey', ' java', ' data mining', 'cicd', ' lms', 'team leading', ' orc protobuf', 'public policy', ' icims', ' induction', ' ai / ml', 'data security', ' construction equipment', ' graphic designing', ' git workflows', 'liquidity risk management', 'enterprise architect', ' field service management', 'sql orm', 'apex programming', ' deep learning', ' synthetic organic chemistry', 'process mapping', ' rac', ' decission trees', ' data business analyst', 'technical product management', ' core databases', ' linq', 'google cloud platform', ' azure cloud services', ' cartography', ' u - sql', ' coso', ' scientist 1', ' javascript frameworks', ' manager technology', ' android java', 'medical imaging', ' system analyst', ' life', 'ssms', ' typescript', ' pandas', ' snowflake cloud', ' node-js', ' database administrator', ' nsx - t', ' specifications', 'general insurance', ' cancer diseases', ' data mapping', ' google analytics 360', ' nexus', ' dbms', ' ci / cd automation', 'catastrophe modeling', 'organizational', ' customer support', ' flarenet', ' data modelling', ' grc', ' product marketing', 'data structures and algorithm design', ' static equipment', 'technical', 'informatica', ' redshift spectrum', ' confirmit', ' big data frameworks', ' amazon aws cloud', ' mantis', ' tsql development', 'praat', ' sales', ' spark sql', ' data validation', ' datafactory', ' etl implementation', ' material master', ' leadership skills', 'technical troubleshooting', ' mro', ' thunk', ' spend analysis', ' sysomos', ' bi support analyst', ' ci/cd tools', 'probability of default', 'media math', 'information architecture', ' unix linux', ' {{git', ' ant', 'test automation', 'statistical tools', ' obiee', 'alteryx', 'keyword research', ' tensor flow', ' system software', 'pentaho', ' media management', ' sisense', ' azure data catalog', ' it fresher', ' marketing manager', ' order management', ' cdm', ' data insights generation', ' music', ' azure data base', 'cloud platforms', ' fdc', 'azure sql dwh', 'manager quality assurance', ' reactive programming', ' scorecard building', ' siemens', ' sas enterprise guide', ' map reduce framework', ' emr', ' data flows', 'malware analysis', 'bi manager', ' forex', 'd3.js', ' hr analytics', ' aws security', ' product analytics', ' statistical simulation / regression modeling', 'building applications', ' hive queries', ' hive spark', ' business', ' ms office suite', ' written communications', ' indirect taxation', ' employee engagement', ' social media analytics', ' charts', ' reporting services', ' data - warehousing', ' oracle relational databases.', ' mdm tools', ' data moderation', ' anaconda', ' dnb', 'tableau lead', ' pivot table', 'loans', 'aws architecture', 'market research analyst', ' data data modeling', ' mariadb', ' threaded', 'continuous integration', ' lead business analyst', ' msbi', 'automation tools', 'cloudera', ' business analytics', ' healthcare analytics', ' performance reporting', ' derivatives', ' home appliances', ' rpa technologies', ' amazon connect', ' technical solutioning', 'pitch books', ' aerospace', ' data - structures', 'eks', ' hr head', 'zeplin', ' server - side', ' jsp technologies', ' performance optimization', ' nse', ' g python query language python', ' django rest framework', ' microsoft azure data stack', ' model development', ' technology implementation', ' statistical technique', ' e-commerce', ' postgresql administration', ' software', ' acl', ' azure security services', ' feedck', ' lighhouse', ' continuous deployment', ' cism', ' it risk assessment', ' engineering data', 'business management', ' coordination', ' ecs', ' hortonworks', ' econometrics', ' cloud cli', 'dynamodb', ' dagger', ' solution architecture', 'integration', ' online marketing', 'database concepts', ' azure keyvalut', ' oncology', ' phd', ' aggregation', ' performance measurement', 'framework manager', 'java 7', ' data masking', ' spark-sql', ' information retrieval and analysis', ' written communication', 'google cloud data services', ' sprint', 'procurement', ' data analysts', ' agile project experience. good understanding and experience of the various agile frameworks', ' ad hoc', ' azure dataengineer', ' time series analysis', ' lead analyst', ' data architecture principles', ' as400', 'cold calling', 'nifi', 'natural language', 'spark ml', ' ios sdk', ' financial systems analyst', 'lex', ' general insurance', ' quality engineering', ' gnu', 'erp', 'aws - s3', ' bigqurery', ' balance sheet analysis', ' nunit', ' process transition', ' lumira', 'query', 'scikit', ' supply chain planning', 'application engineering', ' statistical process control', 'mobx', 'visualforce', ' vat', ' purchase requisition', ' data marts', ' elt methodology', ' business consultant/ business analyst- hcm/payroll', ' aws data engineer', ' ux research', 'information system design', ' front office', ' vxworks', 'bpo', ' prices', ' and advertising.', ' cloud design', ' ppc', 'cfd', ' ideas', ' macos', ' data architectures', ' jasmine', ' lgd', ' flexbox', 'medical underwriting', 'aws python', 'data management', ' technology engineer', ' marketing analyst', ' containers', ' data warehouse testing', ' numphy', 'customer analysis', ' hibernate', ' business planning analyst', ' operational risk', ' polls', ' api architecture', ' comparative analysis', ' radtab', ' churn modeling', 'hana', ' oracle business intelligence', 'sfdc', ' it business', ' internet technologies', 'schema', ' numpy stack', ' apache arrow', ' oil', 'decision tree', 'azure sql datawarehouse', 'non-voices process', 'it sourcing', ' dell emc vxrail', ' clouddata proc', 'nuix', ' statistical software', 'p&c insurance', ' esi data hosting', ' itil processes', ' cognitive computing', ' cleo vl trader', 'data cleansing', 'database knowledge', 'learning', 'json', 'governance', ' dialogflow', ' teradata architecture', ' sentry', ' rds mysql', ' deliver wireframe', ' ml pipelines', 'monetization', ' adb', ' backend', ' svn', ' data recovery', ' infrastructure as code', ' biginsights', ' azure architect', ' collibra tool', ' flexera', ' googlecloud', ' hana', ' streams', ' defect management', ' linear regressions', ' postgres sql', 'ms excel', 'dataframe', 'pytorch', ' tanium', ' omni journey mapper', ' wordpress', ' lookml coding', ' pl-sql', 'technology service operations', ' sap hana', ' business management', 'data research', ' tableu', ' driven development', 'vpn', 'os', ' vulnerability assessment', ' aws stack', 'junior analyst', ' performance - oriented programming', ' apache stack', ' patent litigation', ' aws kinesis', 'rtr', ' nlp models', 'app development', ' kafka', ' isin', ' compliance management', ' b2b lead generation', ' business understanding', ' perfecto', 'graph dbs', ' optimization', 'python r', ' sas r', ' idoc', ' event management', ' excel', ' product life cycle', ' trainer', ' dynamics erp', ' us gaap', ' pharmacovigilance', ' statstics fresher', ' dashboarding', ' photoshop', ' like pyspark', ' predictive analysis', ' gap analysis', 'excel spreadsheet', ' application integration', ' manufacturing engineering', 'modelling', ' workforce management', ' dynamics crm', 'kubeflow', 'it analyst', ' logging framework', ' relational database management', ' project setup', 'cloud data', ' investment management domain', ' nosql', ' medical coding', 'data fusion', ' functional specifications', ' kpo', 'guidewire products', ' flash', 'data visualizations', ' gis project management', ' content management', 'enterprise architecture', ' camel', 'competitor analysis', ' node.js', ' production planning', ' microsoft excel', ' open component', 'data processing', ' jquery', ' mongo db', ' business acumen', ' it sales', ' uima', ' business writing', ' literature', ' visual design', ' data infrastructure', ' hrms', ' data center operations', ' power point report', ' operational excellence', ' mainframe', 'api testing', ' waterfall', ' managing reports', ' pcb designing', 'documentation', 'pythin', ' jvm', 'procurement support', ' fixed assets', ' design patterns', ' nbfc', ' synapse analytics', ' looker data analysis', ' rapidminer', 'manager crm', ' consumer durables', ' spark architecture', ' naive bayes', ' dba', 'aerospace', 'fund accounting', ' os troubleshooting', ' information security', ' snowflake / redshift', ' bpm business process management', ' python c', 'system development life cycle', ' spss statistics', 'distributed system', ' detail design', ' object oriented modeling', ' mapreduce', ' android design', 'core java', ' project management', ' bivariate analysis', ' pyspark coding', 'user acceptance testing', ' google cloud server', ' continuous security', 'oral communication', ' scalable systems', ' tableau server', ' er studio', 'big data devloper', ' spss modeller', ' dremio', ' research projects', ' system administrator', ' glue', 'san', ' efs', 'translation', ' cloudera hadoop', ' health', ' business executive', 'journal entries', ' loss prevention', 'machine learning libraries', ' azure apps', ' testing strategy', ' azure native services', ' sustainable development', 'mis executive', ' analytical method development', ' hr automation', ' streaming framework', ' code development', 'sr. full-stack dev', ' stakeholder engagement', ' optimization techniques', ' dashboard tool', ' devops jenkins', ' confluent', ' tms', 'sas model validation', ' database architecture', ' appdynamics', 'gcp storage', ' ci/cd pipeline', ' architect', ' database schema', ' data model definition', ' ajax', ' strategic consulting', 'convex optimization', 'powerbi', ' product lifecycle management', ' npv', 'kyc', ' algorithm development', ' qlikview', ' service industry', ' sql no sql', ' applied mathematics', ' vendor coordination', ' commodity trading', 'terraform', 'graphics', ' web operations', ' business development executive', 'o2c', ' cognitive services', ' analyst 2', ' product head', ' wfm', ' date lake', 'management', ' adls2', ' scrum methodology', ' graph db', ' procurement procedures', ' it project delivery', ' fraud management', ' website management', 'software architecture', ' scientist ii', 'system operations', ' assurance', ' svm', ' git', ' trade', ' bigquery', ' google apps', ' e - business', 'analytics data', 'aws lamda', ' incident investigation', ' aiml architect', ' svn}}', ' cost optimization', ' pyhton', ' medical records', 'pharmacy', ' elv systems', ' oracle fusion', 'onnx', ' r - shiny', ' network analysis', ' diabetes', ' datalake azure', ' ui path', ' machine - learning', ' big data analytic frameworks', ' database designing', ' mining operations', 'power bi tableau', 'cnn', ' junior data analyst', ' exploratory data analysis', ' snowsql', ' erdas imagine', ' hr analyst', ' strategy evaluation logistics', ' power automate', ' statistics optimization', ' cuad', ' multithreading', 'engineering services', ' process integration', ' digital analytics', ' xib', ' subversion', 'marketing interventionist', 'requirement analysis', ' databricks azure data catalog', ' windows', ' spark analytics', 'capital advisors', ' sre', ' data analytical', ' tps', ' sql tuning', ' load', 'healthcare sales', ' hadoop stack', ' object oriented coding', ' backend development', ' service analyst', ' gts', ' credit risk management', ' market research agency', ' python', ' software engineer 2', 'python/r', ' capital market', ' control system', 'quality improvement', 'bcom', ' sap cpq', ' azure analytics services', 'javascript', ' networking skills', ' variant configuration', ' azure kubernetes infrastructure admin', ' websphere data integration suite', ' cpg', ' engineering projects', ' k - means', ' data engineer ii', 'end-to-end', ' data integrator', ' mockplus', ' text minig', ' credit risk analytics', ' content analyst', ' python pandas', ' telecommunication', 'content and data management', 'senior software engineer - data and ml', 'soc', ' word', ' loan structuring', ' vba automation', 'finance operations', 'lake', ' 3g', ' big data processing', ' inter', ' dataproc hub', 'neo4j', ' scala development', 'talend big data', ' requirement gathering', ' ad campaign', ' ui / ux designers', ' balance sheet', ' data ops', ' frm', ' strategic initiatives', ' architectural design', ' cyberark psm', ' solr', 'green belt', ' geophysics', ' social service', ' awsazure spark', ' s3 data lake', ' aas', ' classic asp', ' prism', ' spinnaker', ' hadoop system', ' oracle', ' reports', 'azure developer', ' hpcm', ' otm', ' nutanix', ' software development', ' dhw', 'staffing', 'pmi acp', ' mortgage advisors', ' sparkpools', ' systems management', 'customer experience management', ' business improvement', ' proposal development', ' telecom engineering', ' qaf', ' data engineering consultant', ' x12', ' month end reporting', ' data management and analysis', ' mobile banking', 'bapis', ' cicd framework', ' infor', ' lamp', 'stored procedures', 'sql support', 'security compliance', 'db2', ' web crawling', ' sfdc', ' 5g', ' automatic speech recognition', 'deliver wireframe', ' sparkpyspark', ' primary research', ' relationship manager', ' product conceptualization', 'development', ' human rights', ' azure analysis', 'msbi', ' delta', ' devsecops', 'etl tool', ' product mgmt', ' firewall', 'varicent tool v9', 'ci / cd', ' compensation and benefits', ' mdp', ' international business', 'certified black belt', ' fact', ' adls sql server', 'lnb', ' profitability analysis', ' mass spectrometry', ' workload', ' mockito', ' peoplesoft accounting', ' scope', ' database maintenance', 'data factory', ' problem scoping', ' azure data - bricks', ' hp', '.net framework', ' design', ' financial reporting', ' negative news screening', ' engineering associate', ' ods', ' application programming', 'stattools', 'sql', 'adf', ' operations', ' aligne', ' equity analyst', ' workflow', ' fsi', ' ios', ' maintenance engineering', 'quality', ' seo analyst', ' snowflake architecture', ' data engimeer', 'ai/ml application', ' firebase', ' rest v2 connector', ' demand generation', 'delivery management', 'brd/srd', 'ip analyst', ' marketing automation', ' ms sql database', 'fabrication', ' mws', 'ssrs', ' secondary research', ' hvac', 'vpc', ' t-sql python', ' derivatives operations', ' pde', ' powershell scripting', 'financial accounting', 'saucelabs', ' is security', 'service now', ' azure data lake', ' microsoft sql server reporting services', ' us it staffing', ' chrome inspector', 'client development', ' controls', ' los', ' java 8', ' video analyst', ' lambada', 'team handling', ' product strategy', ' with num', ' j2ee', 'clinical coding systems', ' disciplinary action', ' jersey', 'application development', ' data entry operator', ' capacity planning', ' data streaming', ' tag', 'kong', ' synopsys', 'typing speed', ' talent acquisition', ' international taxation', ' bizible', ' marketing collaterals', ' regulatory affairs', 'sales operations', ' transformers', 'lead full-stack dev', ' prototype', ' sqls', 'quality audit', ' foreign language', 'relational sql', 'operational support', 'workflow management', 'statistical modeling', ' azure blob storage', ' database engineering', ' azure steam analytics', 'primary research', ' business advisory', ' hr reporting', ' ensighten', 'numby', ' plsql', ' e - commerce', ' good a compuing and excell shees is a must', ' lotus', 'health insurance', ' apache flink', ' informatica mdm', ' architecture', ' business research', ' transport management system', 'text mining', ' dataproc', 'distributed systems', ' springmvc', ' qualitative', ' vendor payments', ' informatica on cloud', ' hadoop scripts', 'arabic', ' strong analytical skills', ' azure data pipeline', ' diagnostics', ' linux shell scripting', 'nursing', ' windpro', ' implementation skills', ' oracle apps', ' equities', ' data warehouse applications', 'it project', ' data operations', ' nodejs', ' software developer', ' rdms database', ' credit risk modelling', 'algorithms', ' data analyist', ' beautiful soup', ' database queries', 'financial modeling', 'b2b solutions', ' lsa', 'spa frameworks', ' dispute resolution', ' project head', ' management systems', ' sat', ' crawler', ' payment processing', ' bayesian', ' hadoop map reduce', ' pub sub', ' mxnet', ' ebs', 'agile scrum', ' supplier development', ' microsoft azure', ' data capture cdc', ' release management', ' business modelling', ' tax analyst', ' mods', ' oral', ' pwf', ' hipaa', ' ci/cd concepts', ' java/python/scala', 'dts', ' msproject', ' technical reports', ' cad', ' sales coordination', ' ba', ' mcom', ' designing data ingestion', 'superset', 'financial analysis', ' datadog', 'veeva crm', ' bi development', ' supply chain', ' ms-dos', ' adf', ' aws or azure or google cloud', 'perl', ' spark developer', ' janusgraph', 'side', ' tableau software', ' technical publication', ' metrics', ' lambdas', ' sagemaker', ' linux environment', 'supply chain', ' iaas paas saas', 'sqoop', ' etl design', 'business transformation', ' cpq', 'of ms office', ' warehouse', ' glm', ' call monitoring', ' music scheduling', ' team building', 'isms', ' law', ' construction management', ' solution architect', ' market penetration', 'pivot table', 'sql database', ' alb', ' image analysis', 'analytical', ' modification', 'market data', ' wealth management', ' ites', ' etl jobs', ' cosmetics', ' oracle fusion middleware', ' engineering lead', 'performance optimization', ' business process management', ' gdpr', ' bi reporting tool', 'postgres database', 'safety training', 'data warehosue', '.net developer', ' value analysis', ' merchandising', ' account management', ' no-sql databases', ' python libraries', ' intrusion detection', ' w&b', 'etl development', ' cti', ' vlan configurations', ' microsoft azure paas', 'data factory pipelines', 'data steward', 'analysis', ' ibm websphere', ' octave', 't - sql', ' sns cloudwatch', ' uipath', ' capacity management', 'html', ' telecalling', ' saprk', ' manager quality assurance', ' system reconciliation', ' cost benefit analysis', ' ci - cd', ' ptp', 'product strategy', ' selenium webdriver', ' registered nurse', 'qlik sense', ' blueprism rpa', 'business research', 'javascript frameworks', ' informatica dq', 'data collection', 'ml engineer', ' windbg', ' customer segmentation', ' azure cloud technologies', 'collibra tool', ' diversity and inclusion', ' ms sql', 'statistical programming', 'azure data bricks', 'customer management', ' robotics', ' continuous testing', ' instructor', ' item data', ' config', ' data prep', ' prototype development', ' upselling', ' chemical engineering', 'spss', 'oracle ppm cloud', 'edd', ' pdf', 'hr data analystics', 'telecom', ' agm', ' sub', ' ecommerce', 'quality assurance', 'enterprise applications', 'modeling', ' scrapping', ' sqldw', ' anaplan', ' tam', ' financial statement analysis', ' r++', ' software delivery lifecycle', ' public speaking', 'sap erp', ' relationship management', ' mis preparation', 'dockers', 'object oriented design', 'alfresco', 'financial advisory', ' sql gcp', 'big data technologies', ' portfolio analysis', ' senior quality analyst', ' wireframe', ' business data analyst', ' load runner', ' accounting software', ' cost', ' datastores', ' android apk', ' production processes', ' distributed systems', ' large datsets', ' technical engineering', 'tcp\\\\ip', ' it', ' blob storage', ' root cause', ' design engineering', 'data lakes', 'python development', ' software application development', 'opensource tech stack', ' agile software development', ' formulation', 'development lifecycle', ' cloud pak', ' mdm solutions', ' data wrangler', ' model scoring', ' edw data models', ' java cloud', ' splus', 'nosql', ' fx', ' idt strategy analyst', ' team leading', 'vsphere 6 7', ' ccba', ' credit risk analysis', ' asset liability management', ' pys', ' web visualization', ' power bi dashboards', ' political knowledge', ' sql programming', ' python text', ' data model', 'druid', ' javascript', ' service marketing', ' administrator support', 'java/python/spark', ' pipeline creations', ' it recruiters', 'project life cycle', ' regression algorithms', ' technical advisor', ' enterprise applications', ' bdm', ' cnn', 'application integration', ' business support analyst', ' jee', 'mercurial', ' scada', ' sales support', ' data loss prevention', ' angular js', 'etl frameworks', ' enrollment analyst', ' machine learning models', ' biology', ' enrollment operations', 'good communication skills', ' hadoop spark', ' kubernetes', 'parquet', ' node . js', 'web service', ' redis', ' azure sentinel', ' data studio', ' jdbs', ' vsan configuration', 'software engineer/lead engineer', ' workday', ' ms bi', ' kusto', ' ms word', ' business analyst', ' top', ' occ', ' exception handling', ' luigi', ' salesnavigator', ' iso 20000', 'big data engineer full-stack developer company profile company name talent zone consultant', ' bfsi', ' kubernetes architecture and design', ' qa analysis', ' solaris', ' multiprocessing', ' it strategy', ' java programming', 'ms sql server dba', 'use cases', ' probability', ' distributed architecture', ' computer hardware', 'cro', ' associate analyst', 'call monitoring', ' aurora', 'buisness analyst', ' solar radiation', ' data visualization libraries', ' transition management', ' big data development', 'software packages', ' financial analysis', 'visual basic', 'load balancers', ' mobile app development', ' biodata', 'sr data engineer', ' mllib', ' production management', ' front end developer', ' databricks', ' assistant vice president', ' graph neural network', ' table partitioning', 'mako', ' project quantities', ' ing', ' kstreams', ' aws data engineering', ' management accounting', ' vulnerability management', ' hadoop services', ' informatica metadata manager ( imm', ' structured finance', ' linear programming', ' backup', ' db2', ' digital printing', ' dashboard', 'data engin', ' mba finance', 'redshift aws', ' downstream processing', ' regression testing', 'bidding', ' microsoft windows', ' stock market', ' commercial background', ' verbal written', ' webserver', 'hadoop ecosystem', ' infrastructure automation', ' fmcg', ' big data analyst', ' vice president', ' software analyst', ' memcached', ' enterprise integration', ' core python', ' c', ' competence development', ' data engineer', ' msexcel', ' new business', 'vista', ' nearest neighbors', ' adobe', 'public health', ' google cloud', ' management services', ' database design development', ' hofs', 'administration management', ' digital marketing analyst', ' production operations', ' app development', ' customer marketing', 'nig data', ' qlik', ' h20', ' retail sales', 'documents review', ' knn', ' people management', 'ms office suite', ' lucid', ' business rules', ' product quality', 'machine - learning', ' mobile app testing', ' computer proficiency', ' bash', ' mailbox management', ' java fullstack', ' gephi', ' rds postgresql', ' machine learning framework', ' oracle developer', ' alm', 'web analytic', ' wings', ' informatica data quality', ' telephony support', ' cypress', 'information system', ' business operations analyst', 'technical product configuration', ' client documentation', ' glacier', ' data visualizations', ' kyc operations', ' pyspark', ' cloud deployments', 'python frame', ' dropship', ' data analyst', ' microsoft net', ' cloud architecture', ' redshift', ' bot', ' system design', ' distributed computing', ' performance evaluation', ' control testing', ' scm', 'data engineering lead', 'private cloud', ' varicent cloud tool', ' shift incharge', ' ibm tivoli monitoring', ' soc', ' security configuration', ' sklearn', ' legal documentation', ' environmental impact assessment', ' source tree', ' data architectural', ' swagger', ' corporate planning', 'financial services', ' angular', ' propensity analysis', ' data ingestion cloud data management', ' cloud security engineer', ' health care domain', ' mechanical', 'written', 'change management', ' aera analytics and data quality', ' cloud hcm', 'azure machine learning', ' kpis', ' payroll processing', ' startup hiring', ' mlm', 'billing analyst', ' risklink', ' international travel', ' dictionary', ' salesforce administration', 'sql cloud', ' education', ' marketing programs', ' patent analysis', ' sun idm', 'golang', ' interpersonal communication', ' liquidity risk', ' version control system', ' business opportunity', 'pandas', ' credit derivatives', 'databricks', ' nmap', 'ecs', ' microsoft modern data', ' solid programming', ' event hub', ' partner management', 'helpdesk analyst', ' juniper', ' sap implementation', ' erwin', ' extraction', ' talend', 'automation testing', ' trade life cycle', 'hybrid framework', ' fullstack development', 'test case execution', ' azure databases', 'management systems', ' rest web services', ' python scripts', ' problem solving', ' configurations', ' sql server integration services', ' risk analysis testing', 'training methodologies', ' solutioning', ' graphana', ' sql querying', ' reliability engineering', ' p & l', ' informatica power center', ' marketing campaigns', ' extjs', ' gpus', ' informatica bdm', ' manual', ' azure synapse analytics', 'talent management', ' estimate', 'it skills', ' job evaluation', ' azure big data', 'mysql', ' jwt', ' technical design', ' aws data lake', 'cdn', ' redux saga', ' engineering design', ' mechine learning', ' consulting - bfsi', ' ml frameworks', 'epm', ' data egineer', ' ibm db2', ' computer architecture', ' health care benefit administration', 'digital marketing analyst', ' warehousing', ' market research', ' vision analytics', ' coo', 'arcfm', ' storyboarding', ' rice', ' deep ai', ' arcpy', ' big - data web services', 'ajax', ' hal', ' fund accounting', ' ctr', ' domo', ' inventory reconciliation', ' etl process', ' sales development', 'mendix', ' sas sql', ' project reports', ' apache', ' quantitative analysis', ' logistics', ' marketing', ' sap data services development', ' transform', ' clinical trials', ' azure stack', ' asp', 'process automation', ' ms office', ' cloud platforms', ' warehouses', ' sap retail', ' rfi', 'planning head', 'macos', ' resources', ' cisa', ' restify', ' e-commerce operations', ' ms bi stack', ' scheduling tool', ' excellent communication in english', ' pattern mining', 'delivery excellence', ' azure database data bricks', 'axiom', ' agriculture', ' functional support', ' maestro', ' etc', ' e-learning', 'fixed assets', ' closure', 'survey design', ' technical architect', 'transcription', ' big data technologies', 'item setup', ' azure services data factory', 'symantec', 'azure paas', ' azure data functions', ' supply planning', ' analysts', ' the hcp360 rep dashboard', ' oracle db', ' educational qualification', ' science', ' digital content', 'cloud security', ' icinga', 'logistic regression', 'ab initio', ' jar file creations', ' meltwater', 'it security', ' operations transformation', ' ad operations', ' neo4j', ' windows administration', ' object - oriented design', ' wi - fi network', ' customer acquisition', ' customer service orientation', ' external contractor sourcing', ' snowflake utilities', 'sql stored procedures', 'apache spark', ' call center operations', ' eventhub integration service', 'cloud technologies', ' oral communication', ' data governance', ' statistical tools', ' technical analyst', ' custom reports', ' restful services', 'testing', ' soap services', ' insight generation', ' cloud bigdata', ' test management', ' sqa', ' operations research', ' ifs', ' api design', 'docketing', 'database design', ' ios / android', ' cyber security analyst', ' api development', 'datorama', ' client onboarding', ' desktop engineering', ' with numbers', 'mongo db', ' financial planning and analysis', 'software design', ' unix administration', ' ggplot', ' strategic planning', ' server', 'rdbms', ' http', ' market research analysis', ' map reducer', ' tera data', ' accounting systems', 'financial transaction data', 'manager', ' azure sql server', ' access', ' azure aws', ' first mile', ' bootstrap', ' vrealize suite', ' solar energy', ' aws step functions', 'system architecture', 'kafka solutions snow flak data engineer big data hadoop hive hdfs data lakes', ' azure data science', ' content creation', ' enterprise data management', ' infrastructure modeling', 'big data developer', ' it recruitment', ' ddl', ' datacenter engineer', ' time series data', ' rxswift', ' lc-ms based experiments.', ' cpa', ' mis operations', ' manipulation', ' rightanswers', ' repository', 'associate analyst', ' clinical research', ' customer interfacing', ' tv', ' mlp', ' guidewire platform', ' demat', ' cloud data stacks', ' nltk', ' vmware administrator', 'edi', 'powr bi', ' mnc', ' functional requirement', ' cloud management', ' gis analyst', ' springboot', 'air touch stone', 'master data management', ' hosting analysts', ' sas di studio', ' oracle coherence', ' aws services', ' container', 'rpa technologies', ' ionic', ' unix/linux', 'hl7', ' proc import', ' expense analysis', 'plsql', ' veritas', ' client services', ' business applications', ' redshift db', ' iit', ' tenser flow', ' ms ssis', 'investment banking operations', ' international trade', 'management reporting', ' strategic partnerships', ' webfocus', ' azure sql warehouse', 'middle management', ' big data architect', ' se', ' boq', ' pub', ' open flow', ' financial modelling', ' engineering', ' petroleum', ' pl / pgsql', ' housekeeping', ' vba microsoft access', ' cash flow', ' service engineering', ' digital services analytics', ' data warehouse modeling', 'scrum', ' digital marketing', ' microsoft suite', ' microsoft power bi platform', ' pesticides', ' lateral hiring', ' reporting analytics', ' post sql', ' key management', ' projects', ' pyspark cloud / azure /aws /gcp / data scientist / data science', ' database developer', ' project billing', ' informatica etl', ' hiveql', ' tibco spotfire', ' rest framework', ' cd', ' apache server', ' data ware housing', ' bdd framework', ' technical lead', ' sales analytics', ' quality audit', ' sql& databricks', ' d3 js', ' query', ' qa', 'pattern recognition', 'bi testing', ' scala programming language', 'network administration', ' case', ' datarobot', 'data entry', ' listed', ' blended process', 'analytics consultan', ' strong communication skills', ' mobx', ' oops concept', ' clinical operations', ' performance testing', ' mdm', ' stat', ' unittest', 'quant analyst', ' mocha', ' clevertap', ' opennlp', ' statistics', ' mongodb.', ' financial statements', ' investigation', ' docker containers', ' insights formulation', ' workforce administration', ' azure core technologies', ' environment management', ' java application', ' libraries', ' marketing operations', 'big data', ' performance improvement', 'linux os', ' chromatography', ' pmo management', ' report management', ' informatica edc', ' web servers', ' master data', 'content writing', ' sms', 'acceptance testing', ' predictive modelingstatistical analysis', 'pl - sql', ' aws aws', ' operations executive', ' rshiny', ' technical architecture', 'micro - batches', ' sql apis', ' key skills', 'sperk', ' sftp', 'adls', ' aws/azure cloud', ' cloud spanner', ' copywriting', ' azure sql dw', 'powercenter informatica', 'generating reports', ' docker hub', ' ml cloud services', ' lr knn', ' cloudformation', ' good communication in english', ' data warehouse architect', ' data integrity', 'patch management', ' quality', ' data review', ' artificial intelligence', 'exploratory data analysis', ' behavior driven development', ' spring security', ' spark dataframe', ' qc', ' data center engineer', ' ci/cd pipelines', ' product life cycle management', ' mlflow', 'pivottables', ' core php', 'cloud data integration', ' iics', ' breeding', ' enterprise architecture', ' finance executive', ' cro', ' appexchange', ' addressing', ' real estate', ' emulator', ' project manager', 'inside sales', ' power bi tableau', ' software asset management', 'contact discovery', ' no-sql', ' asset accounting', ' budgeting', ' risk', ' global operations', ' strategy analyst', 'sql query writing', ' pyscala', ' postgres database', ' arden syntax', ' fcc', ' bagging', 'social media analysis', 'business strategy', ' lei', 'water treatment', ' customer service management', ' ms access', ' automation', ' cloud function', 'ux design', ' billing analyst', ' conflict resolution', ' data visualization', ' ms excel', 'coding', ' cme', ' data lake storage', ' functionality testing', ' critical thinking', ' tables', ' consulting', ' watson discovery', ' columnar database', ' aws core services', ' amazon ec2', ' software architect', ' power bi/tableau/ qlik', ' vfd', ' due diligence', ' advanced sales', ' statistical modling', ' http protocol', ' categorization', ' mmx', 'it facilities', 'api automation framework', ' management staff', ' sas programming', ' hr information system', 'design and development', ' fusion', ' flask api', ' credit analysis', 'jira', 'strategy implementation', 'database', ' azure cli', ' sonarqube', ' azure data lake storage', ' data warehouse development', 'resource assessment', ' bash scripting', 'elasticsearch', ' blue pumpkin', ' cloud computing', ' gtm', 'bank reconciliation', ' customer relationship', ' forensic', 'advance pl / sql', ' advanced java', ' microsoft power', ' online channel sales', ' aml svc', ' automotive', ' mvp', 'compliance', ' private equity fund', ' clinical development', ' serverless architecture', ' transformation', 'linux administration', ' ccar reporting', ' music production', ' unix shell scripting', 'gcp bigquery', 'senior manager', ' java web services', 'streaming', ' datorama', ' selenium web driver', 'idt strategy', ' investment banking operations', ' healthcare', 'web technologies', ' trouble shooting', ' wherescape 3d', 'product engineering', ' textblob', ' aws cicd', ' infrastructure security', ' portfolio performance', ' vendor manager', ' hpcc', ' apache beam', ' restful apis', ' spark and kafka', ' center of excellence', ' cma', 'svn', ' ids', 'product management', ' compile', ' risk compliance', 'test life cycle', ' web analytics', ' extract', ' product costing', ' soap api', ' fixed income', 'big data engineer', ' https', ' jdbc', ' page', ' bca', ' live commerce', ' pentaho', ' production engineering', 'autocad', 'clinical development', ' power sector', ' saql', ' big data ecosystem', ' gis', ' sas visual analytics', ' azure cosmos', ' linux os', 'security', 'linear regression', ' object - oriented programming', ' kedro', 'non voice process', ' panda', ' tcp/ip', ' spark databricks', ' lease lifecycle origination', ' embedded system development', 'msi', ' automation suites', ' karma', ' field operations', ' chemical analysis', 'it infrastructure', ' cryptography', 'foreign language', ' sap concur', ' presales', ' flow', ' qualtrics', ' reduxthunk', ' azure hdinsight databricks', ' yaml', ' mobile testing', ' performance', ' software engineer 1', ' product backlogs', ' content writer', ' structured data', ' mvc', ' market research and analysis', 'ui', ' dataops engineer', ' stp', ' accenture', ' svg', 'finance process', ' material-ui', 'oral', ' iim', ' nex think', ' oci', ' data security', ' etl testing', ' technical associate', 'informatica dq', ' communications', ' application security', ' front - end technologies', ' us shift', ' stlc', 'trouble shooting', ' abinito', 'jquery', ' time management', ' nmr', 'social media marketing', ' aws ml', ' erp system', ' etl automation', 'erp module', ' user research', ' apache tomcat', ' biomedical', ' content optimization', ' logstash', ' agile methodology', ' cloud foundry', 'it applications support', 'model building', ' hplc', ' finance manager', ' sharepoint', ' database implementation', ' auto finance', ' designing and developing compelling data visualizations', ' consultancy', ' content', 'business system analyst', 'django', 'synapse', 'reconciliation', ' avp', ' gpu', 'parking', 'data bricks', ' writing', ' java db technologies', ' autocad', ' factset', ' project analysis', ' project initiation', 'bpmn', ' pci dss', ' product managers', 'datalake', ' network operations', ' database integration', ' apache hadoop', ' aws codebuild', ' data base bigdata', ' qms', ' xcode ios', ' delivery lead', ' scientist', ' aws gcp', ' gradle', 'sap mm', ' aws database migration service', 'ml/dl', ' market place', ' block chain indexing', ' d3js', ' serverless com', ' algorithmic trading', ' segmentation', ' micro - services', ' certified agile scrum master', ' pa/om', ' statistical packages r', ' security management', 'financial markets', ' ml model development', ' julia', ' notebook', 'system maintenance', ' python / r', ' sql sql server', 'sap abap', 'communications', ' scss', ' presentation', ' systems analyst', 'automation framework', 'usage', 'react js pwa', ' bods', ' signal processing', ' ml modeling', ' jax - ws', 'splunk', ' hdfs', ' data parsing', ' grps', 'azure data', ' driver', ' matrix', ' trade processing', ' database', ' b2b', ' strategic insights', ' standard operating procedures', ' people management skills', ' secondary market research', ' or power bi', ' entry level', ' rtcp', 'aws serverless technologies', ' ci tooling', ' quality analysis', ' user interface', 'people analytics', 'report generation', ' data integration consultant', ' it business analysis', ' gst', ' tata', ' process mining', ' idea generation', ' graphics', ' machine learning libraries', ' prcess mapping', ' rdbms', ' data warehouse architecture', ' bigtable', 'artificial intelligence', 'ci/cd', ' work from home', ' sas base', 'omc', ' sas eminer', ' core sql', ' supply chain analyst', ' structured products', ' standardization', ' aws quicksight', 'clinical data management', ' splunk es', ' wcs', ' analytics consulting', ' story telling', ' ruby', ' finance', ' 3d', ' third party', ' t-sql', ' technical production support', 'financial sector', ' statistical analysis', ' azure event grid', ' credit officers', ' -', ' matillion', ' open studio', ' listening skills', 'servicenow hrsd', ' linkedin', ' middle level management', ' cloudsql', ' spark programming', ' cloud data security', ' etl architecture', ' informatica 9x', ' mi analyst', ' kyc associate', ' macro express', ' advanced git', ' resnet', 'cloud data environment', ' firehose data prep', ' mi', ' ml deployment', 'software development', ' retail merchandising', ' fresher', ' sas', ' rdms', ' ict spending trends', ' mathematics', ' fa', ' general insurance domain', ' information system', ' system integration', ' big data analytics', 'informatica axon', ' applied intelligence', ' engineering manager', ' keras', ' open refine', ' data classification', ' iso 9001', ' consumer insights', 'senior financial analyst', ' serverless', ' people technology analyst', ' aps', ' oozie', 'electrical engineering', 'lead architect', ' its', ' balsamiq', ' gcp and aws', ' glmgam', ' aws data', ' sap services', ' assets', ' field testing', 'reports', ' cuda', ' azure data lake/delta lake', ' debt collection', ' data pipeline architecture', 'tcp', ' building application', ' human capital', ' clustering', 'spring boot', ' product research', 'iot', 'collibra', ' sql seam framework', ' business services', 'object - oriented concepts', ' cce', 'automobile engineering', ' investment management', ' fhir', ' bug tracking systems', ' business consulting', ' qlik script', 'senior data scientist', 'oracle db', 'dax', ' pl / sql programming', ' malware dos', ' review', ' problem - solving', 'container', 'redshift', 'java tech stack', 'financial risk management', ' integration services', 'data developer', ' jpa', 'product development', ' arm templates', 'microsoft power bi', 'dwh desing', ' database security', ' azure streams', 'software engineer - data center', ' program delivery', ' database fundamentals', ' microsoft', 'blockchain', ' banners', ' docker', ' database modeling', ' hilt', ' data analytic', 'hp data protector', 'data reporting', ' model building', ' product roadmap', 'cloud formation', ' leasing', 'data etl', 'random forest', ' iss', ' project coordination', ' sap data & development', ' high level design', 'angular 9', ' service operations management', 'verbal', ' opex', ' data warehousing', 'ec2', ' data factory architecture', ' bi intelligence', 'secondary research', ' wms', ' continuous delivery', ' amazon web services', \" sms api's\", 'ms - office', 'backend', ' platforms', 'eno - avp # 203270', 'data mining', ' denodo', ' business process', ' mutual funds', ' cloud dataflow', ' ecommerce industry', 'emblem', ' sap data services', ' planning', ' deployment', ' service management', ' multivariate analysis', ' oracle dba', ' ui ux development', ' team management', ' scala and python', 't', ' big data developer', ' android', ' test analysis', ' system sql', ' mentor graphics', 'apache airflow', ' reuters', 'adobe analytics and rpython', ' software architecture', 'fraud analysis', ' market and analysis', 'information technology', ' excel skills', ' helm', ' international sales', ' macros', ' market research analyst', ' banking products', 'robotics process automation', ' payroll', 'data archtect', 'google analytics', ' process quality', ' project control', ' digital advertising', ' networking', ' elasticsearch', ' azure store', 'salesforce', ' bank loan', 'dask', ' aws api', 'business and process analysis', ' lisp', 'sql programming', ' visio', 'apptus', 'ee deployment', ' data development', ' bi reporting', ' project monitoring', ' openshift', ' assembly backend operations', ' google ai platform', ' cloud pubsub', ' quality standards', 'data services', ' display advertising', ' java developer', ' aviation analyst', ' codedeploy', ' audio visual', ' gcp dataflow', ' fpna', ' credit analyst', 'conceptual', ' gpdb', 'c', ' exploratory analysis', 'waterfall', ' rest', 'client servicing', ' hr', 'objective c', 'mapreduce', 'ci/cd jenkins', ' mobile marketing', ' gcp hadoop & hadoop', 'performance calculations', ' impala', ' rails', ' dimensional modeling', ' clearing', ' caffe', ' google data fusion', ' develop', 'mob', 'natural resource management', ' credit card firm', ' research analyst', 'ldm', ' illustration', ' fto', ' coding', ' data pre', 'azure sql server', ' gds data analysis', ' business system', ' odbc', ' corda', ' boot', 'accounts payable', ' test', ' hudson', ' microsoft powerpoint', ' relational', ' html', ' lambda aws', ' process documentation', 'agile', ' data manipulation', ' ci & cd using jenkins', ' cloud watch', ' salt', ' aws cloud services', ' big data applications', ' dl', ' individual contributor', ' capital modelling', ' python core development', 'publishing', 'oracle data integrator', ' teradata sql', ' qualitative analysis', ' fsldm', ' business studies', ' ability', 'metrics reporting', 'charts', ' api', ' azure data services', ' internal auditor', ' senior manager finance', ' integrated marketing', ' artificial inteligence', ' natural language', ' scikit-learn', ' clinical management', 'cloud data protection', 'bi', ' rest services', ' aws data ops', ' project design', ' etl framework', ' mom', ' advocate', ' cors', ' web application', ' crf', ' afc', ' cash flow statement', ' signalling', ' customer satisfaction', 'digital analytics', ' qa data engineer', ' sql db', ' mrdcl', ' mediclaim', ' monitoring and logging', ' kanban', ' load balancing', 'mis', ' visual studio', ' rest apis', ' power electronics', ' data integration', 'customer segmentation', ' investment portfolio', ' epos', ' spark streaming', ' personnel management', ' marketing executive', ' operations leadership', ' hivemall', ' retail analysis', ' transition', 'design engineering', 'spotfire', 'iso', ' administration management', ' random forests', ' hosting services analyst', ' wildfly server', ' large datasets', ' client retention', ' service assurance', 'business analyst', ' compliance monitoring', ' lead operations', ' delta lakes', ' promotion planning', ' actuarial', ' deep learning modeling', 'scrapy', ' flex', 'react js', ' .', ' store management', ' elastic mapreduce', ' kubernetes microservices', ' google sheets', ' asp net', ' web frameworks', 'nodejs', ' injection moulding', ' data administration', ' data engineering tools', ' vpc', ' testng', 'customer acquisition', ' science libraries', ' business case development', ' rewards', ' aws glue', 'prototype development', ' maximo', ' application support', ' vendor', ' data management analyst', ' sla', ' executive', ' lead software', ' data designer', ' analyst 1', ' spring mvc', ' key accounts', ' new business development', ' server management', ' pentaho data integration', ' hris', 'spring framework', ' principal investigator', ' idq developer', 'big data frameworks', 'paas', ' data platform - bengaluru', 'deep learning', ' rabbitmq', ' internal audit', 'forex', ' mule services integrations', ' loading', ' product support analyst', ' cloud environment', ' tools', ' data acquisition', ' data loader', ' testing tools', ' telecom billing', ' python microsoft office', ' sprinklr', ' entertainment', ' react frame work', ' variance analysis', 'mq', ' business communication skills', ' it risk management', ' azure streaming analytics', ' archiving', ' uft', 'code', ' zeplin', ' azure public cloud', ' atos', 'object oriented programming', ' mts', ' outsourcing', 'data visualization', 'application design', ' zookeeper', ' machine learning model', ' aws data warehousing', 'decision sciences', ' review analyst', 'oops', ' clinical data', ' data / business analysis', ' product support', ' sales head', ' redash', 'quality analysis', ' gremlin', ' open source technologies', ' data loading', 'payment processing', ' tcp / ip', 'microstrategy', 'bash', ' intern', 'rabbitmq', ' professional services', ' tez', ' go', ' mload', ' ni-fi', ' ppt', 'underwriting', ' aws database migration', ' content strategy', ' penetration testing', ' travel agency', ' blog writing', ' security monitoring', 'teradata', ' product based', 'unstructured data', 'information security analyst', ' content writing', ' data stage', 'power bl', 'bigdata technologies', ' api automation', 'bigdata', ' credit cards', ' msmq', ' apache pyspark', 'macros', ' html5', ' lifecycle', ' star schema', ' dbase', ' fresher graduate', ' emc', ' good analytical', ' etl performance optimization', ' automate data access', 'sagemaker', ' autosar', ' commercial strategy', ' stash', 'product quality', ' management reporting', ' healthcare domain', ' resource mobilization', ' restful web services', ' cloud trail', ' web hosting', 'html 5', ' excel powerpoint', ' aiml', ' quality audits', ' policies', ' google big query', ' law enforcement', ' edms', ' apigee', ' script writing', ' object - oriented /', ' network infrastructure', ' market study', ' non-voice process', ' junior staff', ' winforms', ' jda esp', ' alteryx deginer', ' network design', ' microsoft certified professional', ' deal', ' technical operations', ' tware', ' db queries', ' automation anywhere', ' msa architecture', ' bayesian networks', ' rdbmss', ' workforce planning', ' hr data analyst', ' aws data migration', ' analyze data', ' data quality management', ' android framework', ' it asset mgmt', ' cloud infrastructure data engineering', 'interfaces', ' product data management', ' operating model', ' data analysis/visualization', ' digital marketing executive', ' software development manager', 'analytics reporting', 'base sas', ' hp load runner', ' mobile application testing', ' audience segmentation', ' eba', ' technical specifications', ' zephyr', ' qs', 'ppc', ' beam', ' oracle financials cloud', 'bi tools tableau', ' excel ecc', ' dispute settlement', ' hp data protector', ' sap ecc', ' hqlexposure to bi tools', ' asp.net', ' qlik sense', 'sql database queries', ' data engineering', 'ruby rails', ' stream', ' visual basic', 'career development', ' food technology', ' it executive', ' qa lead', ' linux scripting', ' hyperion financial management', ' aws iaas', ' iot application development', 'regulatory reporting', 'graphql', ' lex', ' pig designing', 'relational databases', ' data entry operation', 'web analytics', ' sns', ' junit', ' navicat', ' lda', ' data center', ' problem', ' integration analyst', ' fortran', ' net', ' netezza', ' microsoft word', ' cosmetology', ' togaf', ' client interfacing', ' load balancar & storage', ' micro - batches', 'ci tooling', ' mobile applications', 'saas deployment', ' data bricks', ' data aggregation', ' bigdata scala developer', ' camunda', ' oracle data analyst', 'eco', ' guidewire claims', 'process design', 'relational data', 'business analysis', ' core and advance python programming', ' r', ' hadoop data management', ' . net', 'ssis packages', ' raw material', ' quality improvement', ' network data mover', ' regression', ' node js', ' ipr', ' os internals', 'django framework', ' quality reviews', ' sap r', 'industry research', ' simulink', ' sales force', ' regulatory data requirements', 'campaign management', 'ms office', ' integration php', ' pharmacology', 'data visualisation', ' model build', ' fastexport', ' sales process', ' gc', ' facility management', 'go lang', ' operations analyst', ' complex', ' sqlpools', 'gradle', ' technology leadership', ' company analysis', ' procurement', ' java script', ' data migration strategy', ' relationship executive', 'emr', ' web application development', ' stores', ' data build tools', ' hcpcs', ' content management system', ' azure data engineering', ' maintaining servers', ' microsoft dynamics', 'aws/azure', ' product testing', ' us staffing', ' server hardware', ' process audit', ' product roadmaps', ' cycle time reduction', ' spark', 'database designing', ' claim adjudication', ' hp al', ' model validation', ' decision tree', ' data cataloguing', 'star schema', 'data manipulation', ' investment research', ' datafusion', 'scala developer', ' junior analyst', 'apache nifi', ' high throughput computational screening', ' spectrum', ' basel iii', ' general statistics', ' mvc frameworks', 'sr. db dev', ' dataset', 'rest api development', ' mis executive', ' data ingestion', 'metadata extraction', ' aws s3', ' industry research', 'ios development', ' process operations', ' swift', 'data architectures', 'xml', ' kernel', ' sales support analyst', ' postman api', 'pdf', ' quality management', ' complex sql query', ' oral communications', ' ml cloud', 'aml', ' 524', ' microsoft web development', ' knime', ' hadoop ecosystem', ' cordova', 'information security management', 'word', ' outbound', ' amplitude', ' it management', ' recruitment lead', ' sas analyst', ' unix os', ' gke', ' development manager', ' my sql', 'reporting', ' sales presentations', ' internet research', ' group product manager', 'social media', ' data structure', 'business planning', ' customer service', ' java azure', ' project tracking', ' life sciences', ' object oriented analysis', ' azure devops', ' postgres', ' system integration testing', ' marketing data analysis', ' hrms operations', ' callidus cpq', ' test scenarios', 'azure analytical', ' public health', ' cloud composer', ' mathematica', ' batch programming', ' corporate trainer', ' customer management', 'order management', ' css5', ' analytics development', ' application deployment', ' level', 'solution architecture', 'advance excel', ' qualitative research', ' kerberos', ' numpy', ' messaging', ' storage', ' datastructure', ' co - cca', ' lead nurturing', ' hadoop 2', 'it risk', ' microsoft sql development', ' sql server analysis services', 'zookeeper', ' big data hadoop', 'analyzing information', ' data maining', 'outbound', ' devops methodologies', ' bigdata', ' mechanical fresher', ' mlt', 'open end coding', ' dnn', 'r skill', ' mongodb', ' blue prism', ' creative', ' regulatory requirements', ' fraud detection', ' data standards', ' anova', ' rfq', ' customer focus', ' oracle hcm cloud', ' apache kudu', ' software engineer', ' senior research analyst', ' memsql', 'go', ' user experience', ' ansible automation', ' coordinating', 's4 integration', ' user acquisition', ' cohesity', ' sentiment analysis', ' eks', ' audacity', ' information analysis', ' powertrain', ' chef', ' slq', ' client interaction', ' p&l understanding', ' concur', 'jenkins', ' identity management', ' data integration patterns', ' sas enterprise', ' social research', ' ieee', 'retail', 'c++', ' de novo prediction', 'english', ' product requirement documentation', 'informatica edc', ' malayalam', ' azure adx', ' web scraping', 'rf', 'etl/mysql', ' sql.', ' aiohttp', ' content delivery', ' fundamental research', ' performance analysis', ' primavera', ' team player', 'capital markets', ' java & lambdas', ' azure automation', 'wastewater', 'dashboards', ' senior management', 'stats modeling', ' basic statistics', ' business associate', ' reports extraction', ' industry reports', ' psychiatry', 'sap pm', 'query optimization', ' it skills', 'datawarehousing', 'manpower planning', ' r shiny', ' financial operations', ' healthcare research', ' dmco', ' predictive analytics', 'amazon connect', 'cloud architecture', ' oic', ' senior associate business analyst', ' csm/cspo', ' cloud data lake', ' mis reporting modules', ' pub - sub', ' python data', ' \"r\"', ' german', ' j soup', ' guard duty', ' arm processor', ' python script', ' patents', 'market risk', 'data presentation', ' mathematics and science background', ' athena databricks', ' azure event hub', ' database performance tuning', ' it support', ' password management', ' neural network methodologies', 'analytics', ' business excellence', ' api frameworks', ' comm', ' interpretation', 'b testing', 'data stage', ' cloud big query', ' business english', ' sap crm', 'powerpoint', ' vp', ' qualtrics ux', ' deep learning models', ' odata', ' open source', ' machine analytics', ' aso', ' purview', ' hive base', ' apache hive', ' postgres mongodb', 'cloud services', 'assembly language', 'trading settlements', ' risk reporting', ' junior executive', ' hr executive', 'data integration', ' sql dw', ' sap sd', ' mental health', ' reduce', 'kafka event bus', ' qa analyst', ' cloud data warehouses', 'work force management', ' ibm datastage', ' optimizing code', ' technology management', ' bi/dw', ' sac', ' quality assurance', ' java 6', ' it consulting', ' lakes', 'credit analysis', ' analytics', 'data pipeline', ' min', 'databases', ' base sql', ' migration', 'gcp cloud', ' software development engineer ii', 'jms', ' azure sql dw / synapse', ' resource planning data', ' quality control analyst', ' t - sqle', ' sheet metal', ' cloud data quality', ' mobile handset', 'power bi desktop', ' oracle 10g dataguard', ' cloud application development', ' vibration analysis', ' business banking', ' data process anaylst', ' rnn', ' data governance roadmap', ' night shift', ' data scientists', ' mba', ' ai', ' ca erwin', ' cloud front', 'ai', ' agribusiness', ' network management', ' analyst 3', ' equity market', ' cloud architect', ' aws dms', ' annual reports', ' cloud data architecture', ' talent management', ' operation', ' xgboost', ' data structures', ' data framework', ' quality review', ' ticketing', ' linguistics', ' etl tuning', ' schema design', 'nlp', ' database optimization', ' metrics analysis', ' backbone js', ' computer application', 'opt', ' product catergorization', ' data conversion', ' vb', 'sql queries', ' pipeline', ' deduction', ' system interaction design', ' etl scripts', ' retail', ' data transformation', ' vehicle', 'webpack', ' molecular dynamics', ' medicaid', 'bills payable', ' international voice process', 'ai/ml algorithm', 'speech mining', ' asr', ' salesforce', ' learn', ' proficient in aws redshift', 'shell script', ' cloud formations', ' cmmi', ' .net', ' c#.net', ' gis data engineer', ' lua', 'sas model development', ' azure data warehouse', ' jinja 2', ' automate etl', ' mbbs', ' ibm watson', 'netsuite', ' google cloud data', ' lambda', ' process control', ' training needs', 'python/java/nodejs', ' algebra', ' store operations', ' brokerage', 'sdfc', ' salesforce.com', ' database management system', ' ux design', ' azure data flow', 'and hadoop', ' edtech', ' msc', 'visualization technologies', ' inventory management', 'pypark', ' development management', ' sales report', ' surveys', ' pos', ' architectural diagrams.', ' sql coding', ' ar', ' product adoption', ' petrochemical', 'investment banking', ' bim', ' advance sql', ' statistic modelling', ' big data infrastructure', 'itsm', ' technical writing', ' unix scripts', ' hoovers', ' process orientation', ' r libraries', ' transaction s', ' mysql and postgresql', 'hbase', 'azure devops', ' managerial accounting', 'microsoft powerapps', ' service tax', ' er/studio', ' campus recruitment', 'advanced sql queries', ' logical and physical data modeling', ' biostatistics', 'batch processing', 'object - oriented programming', ' kyc', ' azure data storage', ' utilities', ' ms power point', ' sql queries', ' channel sales', ' phonegap', ' ui script', ' ldatopic modeling', ' process modeling', ' radiology', ' negotiation', 'nutrition', ' teradata bi', ' support', ' present analysis', 'cism', ' r / r#', ' modern architecture', ' abinitio', ' excel report preparation', ' engineer', ' spreadsheets', ' sql server reporting services', ' mq', ' mongo', ' lte', 'web application development', ' mpi', ' data42', ' export import documentation', 'structured data access control', 'architect', 'data quality developer', ' frd', ' bidding', ' java backend', ' linear regression models', ' intellectual property', ' quality check', ' google big', ' after - sales', 'multithreading', 'financial concepts', ' enterprise cloud', ' business transformation', ' sql+', ' aiops', ' problem analysis', ' python scripting', ' personal loans', ' oscilloscope', ' lsmw', ' framework', ' technical support', 'ba artifacts', ' chat', ' customer engagement', ' relational modeling', ' data management tools', ' data anlalytics', ' minitab', ' company secretary', ' paas', ' toad', ' object - oriented / object', ' it transformation', ' biotechnology', ' flexcube', ' ml ops', ' social media marketing', ' nagios', ' hive sql', ' flask', ' semantic hashing', ' clinical coding', ' data mart strategy', ' deep learning frameworks', 'google tag manager', ' estimation', ' management skills', ' orm', ' publishing', 'hadoop administration', 'computer languages', ' data queries', 'talend', 'experimental design', ' data project', ' react native', ' dataflows', 'sap data & development', ' data modeler', ' hive impala', 'mainframe', ' quality inspection', 'operations support', ' dpdk', ' adl etf', ' risk functions', ' ssis', ' brd', ' spring framework', 'elastic search', ' client projects', ' infotainment', ' dtp', ' brandwatch', ' data integration tools', ' var', ' genomics', ' analyst mi coe', 'medical researcher', 'cloud', 'team operations', ' symantec', ' compensation analyst', ' kubernates', ' ms visual studio', ' weaving', ' customer service delivery', ' quality monitoring', ' campaign audience engineer', 'image processing', ' project migration', 'flink', 'manual testing', ' dynamodb', ' python data analytics', ' sox', ' tickstack', ' js rest api', ' scope management', 'no sql', ' bip', ' test - driven development', ' hudi', ' governance', ' html / css', 'data warehouse', ' azure analysis services', 'data bricks delta lake', ' sales operations', ' statistical analyses', ' data requirement gathering', ' database analysis', ' asset allocation', ' data automation', ' trading settlements analyst', ' iam cloud operations', ' reporting and analytics', ' quantitative modelling', ' it marketing', ' data', ' pattern recognition', ' cucumber', 'sap master data', ' router', ' elastic search solr', 'monthly reports', ' ims data', ' problem-solving skills', ' kubernetes services', ' etl cloud', ' dataset wrangling', ' amazon cloud', 'problem solving ability', 'sql coding', ' bigdata developer', 'allegro', ' problem-solving', ' write complex', 'it', 'frs', 'cash management', ' ict', ' object oriented analysis & design', ' back office executive', 'crm implementation', ' feedback', ' aws emr', ' security services', ' aws-emr', ' data preparation', ' performance management', 'backup management', ' hadoop', 'time management', ' finance analyst', ' technical interviewer', ' application development', ' people analytics', ' process flow diagram', ' sic', 'internal audit', ' powerpoint', ' financial analyst', ' statistical analytics', ' rest controller', ' cms', ' threat analyst', ' english writing', ' cleint onboarding', 'product analytics', 'quality monitoring', 'microsoft azure data services', ' google kubernetes engine', ' cocoa touch', ' cmms', ' idq logs', ' economics', ' data science libraries', ' distributed data processing', ' advance excel', 'web crawling', ' object detection', ' product development', 'vsts', ' manager quality control', ' ivr', ' sales analyst', ' grafana', ' cxo', ' informatics', ' clinical coder', ' dotnet', ' seo', ' report', 'cplex', ' financial projections', ' data support', ' niche skill hiring', 'cce', ' financial instruments', ' polaris', ' rsa', ' scripting languages', ' robot framework', ' cloud', 'machine learning', 'technology recruitment', ' python and open source libraries and tools such as numpy', ' google apis', ' accounting', ' sales cloud', ' spark stack', ' electronics', 'bi tools', 'postgresql', ' apache avro', ' complex analysis', ' translator', ' revenue cycle management', ' business administration', 'diversity and inclusion', ' point cloud data', ' big data engineering', 'software development life cycle', 'economic analysis', ' room', ' emergency response', 'application support', ' protegrity', ' advertising management', ' mice', ' invoicing', ' customer centric', ' design review', ' spark nlp', ' underwriting', ' mathematical optimization', ' relativity', 'bi flows', 'client management', ' bi tool', ' cbap', ' analyst ii', 'process analysis', ' data scinetist', ' css3', ' typography', ' unit test', ' credentialing', ' security', ' software engineer ii', 'web application testing', 'predictive modelling', ' ab testing', 'aml pipeline', ' visualizations', 'ms azure data management', 'nlp and dialog systems', ' amazon redshift', ' datagovenance', 'jupyterlab', ' netcool', ' pyspark api', 'olm', ' big data analysis', ' riversand', ' excel functions', ' web api', ' teradata', ' site operation', ' primary skills', ' advanced excel macros', ' structure visualization', ' nlp', ' primary market research', 'micro services architecture', 'resource capacity forecasting', ' apptus cpq', ' succession planning', ' ios native', 'ftp', ' build automation', ' structured analysis', ' test data maker', ' sql databases', ' java framework', ' hardware', ' maintaining servers of the company', 'board design', 'forecasting', ' scripting language', ' regulatory compliance', ' singleton', ' ms - office', ' oracle edw', ' rxjava', ' organization and co-ordination skills', ' para legal', ' eda deep sql', ' relational data modeling', ' quality lead', ' associate quality analyst', ' etl processes', ' valuation', ' renewable energy', 'scikit-learn', 'mendix platform', ' b2c', 'object - oriented development', ' recruitment', ' bangalore', ' azure sql datawarehouse', 'a&pp', ' recommendation and forecasting', ' aws data pipelines', ' java software engineer', 'ap reconciliation', ' product promotion', 'vba', 'research analysis', ' servicenow', ' stack systems', 'rsa archer', ' backend developer', ' decision trees', ' srs', ' sql server management studio', 'mqtt', ' logility', ' statsmodels', 'azure big data', 'talend etl', ' mvc architecture', ' microsoft office', ' product presentation', ' case studies', ' s4 hana', ' room database', ' gcs', 'recruitment executive', ' hrd', ' account', ' instrumentation', ' data interpretation', ' azure iot', 'designing and implementing', ' surgical', ' subject matter expertise', ' functional testing', ' core data', ' customer care', 'database management', ' nosql dbs', ' saas', ' shiny', ' ticketing tool', ' cloud solutioning', ' mortgage', ' arima', ' atlassian', ' actuarial analyst', ' figma', 'business intelligence tools', ' team spirit', ' cloud erp', ' data analytics', 'business analytics', ' object c', ' vapt', ' engineering analyst', ' pysprk', ' dbt', ' pay', ' google automotive services', ' project delivery', ' cloud data visualization', ' test analyst', ' xpresso', ' aws cloud analytics', 'data quality', 'project development', ' quantitative research', ' data fusion', ' cicd pipeline', ' lambda architecture', ' vsphere 6 5', ' green belt', ' factor analysis', ' autolayout', ' project operations', 'team management', ' interviewing', ' jira', 'requirements analysis', ' fraud analyst', 'regression modeling', ' cards', ' talend big data', 'ns', ' banking general', ' enterprise content management', 'se', ' database design', ' lake', ' microstrategy', ' axiom controller', ' data pipeline', ' ado', ' business design', 'orchestration', 'seo analysis', ' crm analytics', ' mantas', ' ich-gcp guidelines', 'legal compliance', ' entity extraction', ' accounting standards', 'rest', 'seaborn api', 'nlp python/r pyspark cloud /azure aws gcp data scientist data science', ' data pre processing', ' kinesis', 'aws athena', ' boomi', ' marketo', ' big data', 'business acumen', ' mathematical modeling', ' visual communication', 'sap s/4hana', ' ddos', ' software qa', ' power pivot', ' early life support', 'communication', ' document checking', ' enterprise software', ' research and development', ' hyperion', ' j2ee stack', 'engineering', 'powershell', ' attention to detail', ' spring frameworks', ' pub / sub', 'azure data forms', ' ms - excel', ' asme pressure vessel code', ' information research', ' microsoft stack development', ' fraud modelling', ' aws pyspark', ' python development', ' spark rdd transformation', ' analyticssoftware services', 'ms access', ' cosmos', ' market risk', ' private cloud', ' microsoft sql', ' multi - platform', ' policy', ' as / 400', ' axon', ' data collection systems', 'product analyst', ' get', ' sales analysis', 'numpy', ' webservice', 'communication skills', ' cost analysis', ' adv excel', ' weblogic', 'retail analytics', ' focus', ' client reference data', 'business reporting', ' remedy', ' shell scripts', ' collateral management', ' relationship', ' etl', ' microsoft bi', ' snowflake db', ' video processing', ' relationship building', 'housekeeping', 'mobile testing', ' sql dba', ' billing', 'lab data manager', ' ai ops', 'azureml', 'field operations', ' problem management', 'ubuntu', ' image processing', ' workflow management', 'market analysis', 'oo', ' pricing analysis', 'product launch', ' laravel', ' sprak', ' design conceptualization', ' microsoft azure data lake storage', ' tlm', ' insurance claims', 'data extraction', ' blackline', 'fp & a', ' otc', ' sql development', ' back-end', ' ibm', 'bill of lading', 'data ingestion', ' merchant acquiring', ' micro services', ' ansys', ' rs', ' epm implementation', 'training', ' eclipse', ' tableau online', ' 2g', ' csv', ' lead developers', ' advance sql queries', ' cloud formation', ' capital iq', ' hc analytics', ' payment systems', ' ehr', ' data visualization techniques', ' data query languages', 'r shiny', ' business finance', ' data - intensive', ' quicksight', 'yarn', ' head business development', ' user support', 'software engineering', ' sme finance', 'sales analysis', ' business growth', ' power - bi visualizations', 'stock exchange', ' process', ' core finance', ' text mining', ' olap', ' psychology', 'server', ' etl developer', ' issue resolution', 'azure', ' skylearn', ' fixed income markets', ' application software support', ' dashboards', ' 2d', ' service level adherence', ' activemq', 'linux/ c++ - l2 support', ' freight forwarding', ' object - oriented / scripting', ' servo motors', ' senior manager', ' azure ml studio', ' sql server administration', ' tpus', ' san switch', ' adsf', ' etl frameworks', 'video editing', ' investment banking', ' sql data', ' application testing', ' servo', ' bom', ' sql data warehouse', ' toefl', ' sap cloud platform', ' alteryx tableau', 'good communication in english', ' executive leadership', ' web proxies', ' parquet', ' prometheus', ' supervisor', 'git', ' maria', ' report modification', ' tfs', ' associate risk analyst', ' c++', ' wireless protocol', ' data scalability', ' data businesss analyst', 'risk reporting', ' stanford nlp', ' documentum', 'machine dynamics', 'biotechnology', ' aws rds', ' product analyst', 'chartered accountant', ' celonis', ' quality analyst', 'unit testing', ' mathematical analysis', 'hive', ' software associate', ' ci cd pipeline', ' excel data management', ' amazon elastic map reduce', 'b2b sales', ' visualisation', ' microsoft project', ' database creation', ' management', ' predictive modeling', ' marketing analytics', ' chatbots', ' opengl', ' test engineering', ' powerdesigner', 'lead generation', 'database administration', 'ibm cognos tm1', ' oracle erp', ' ipro', ' claim processing', ' sales administrator', ' mobile automation testing', ' microservices', ' kafka architecture', 'blobs', ' articles', ' ds algo', ' spring', ' postman', 'graph db', ' user management', ' marketing initiatives', ' appliances', ' nginx', 'administrative assistance', ' sqoop', ' amazon documentdb', ' lucene', 'computer visions', 'direct marketing', 'dataa analyst', 'cloud environment', ' database management', ' databricks design', ' axon salesforce', ' clinical research associate', ' copy writing', 'cybersecurity', ' data engineering/ db developers', 'basic', 'technical architect', 'tax analyst', 'com', ' xform', ' svnci', 'edc', ' aws data services', 'content creation', ' senior technical lead', ' micros services architecture', ' business plan development', ' springboot java', ' azure dev ops', ' bant campaigns', ' conducting', ' analyse', ' jamf', ' sap business one', ' drug discovery', ' windows server', 'algorithm development', ' oracle teradata', ' ms azure', ' financial risk management', ' build management', ' kafka cloud', ' argo', ' kotlin', ' system administration', ' embedded systems', ' datamodelling', ' customer service operations', ' data analysis skills', ' credit card analytics', ' service', ' leadership development', ' catastrophe risk analysis', ' code review', ' big data pipeline', 'design', ' azure modern data platform', ' remote support', 'office', 'operations research', 'statistical model building', 'statistical analysis', ' skills', 'aws s3', 'learn more', ' sailpoint', ' distributed data system', ' java plus', 'integration testing', ' edi', ' cloud data framework', 'hyperion essbase', ' ai solutions', ' failure analysis', 'test strategy', 'revenue generation', ' udb sql', ' techno-savvy', ' demand analysis', ' express', ' dlp', ' graphql', 'odi', ' stakeholder management', ' google cloud platforms', ' data visualization tools', ' supply chain management', ' metaflow', ' rca', ' power apps', ' senior analyst', ' openair', ' ibm cdc', ' azure databricks', ' map - reduce', ' tableau public', ' microsoft sql server', ' no - sql', ' dropwizard', ' export import', ' pl / sql automation', ' lstm', 'cassandra', ' databricks stack', 'scripting', ' crm', ' iam', ' dermatology', ' cv', ' dw', ' data cleaning', ' revenue management', ' azure developer', 'kotlin', ' debt investment', ' sourcing', ' avro', ' component lifecycle', ' credit card domain', ' retail banking', 'maths', 'data validation', ' seamless ai', ' ml modelling', ' cloud service', 'pyspark.', ' algorithm', ' feature build', ' big data platforms', ' inspection', ' security operations', 'development management', ' aws big', 'seo', ' azure functions', ' aws sagemaker', ' mistake proofing', ' tat', ' project/program management', 'ticketing', ' axure', ' business / systems analysis', ' exm', ' whodrug', ' philosophy', ' database marketing', ' service quality', ' power management', ' json web token', ' stored procedures', ' thymeleaf', ' big', 'business intelligence reporting', 'statistical data analysis', 'spark programming', ' azure datalakes', ' reltio', ' bank accounting', ' microsoft azure devops', ' bigtable cloud sql', ' payment gateway', ' redhat', ' singlestore', ' ui development', ' micro - service architecture', ' kstream', ' product sales', 'distribution system', 'umap', ' polybase', ' personal lending', ' hadoop ecosystems', ' vertex peoplesoft', ' hospitality', 'leadership', 'mongodb', ' integeritty', ' wpf', ' pheonix', ' process management', 'quality standards', ' sap analyst', 'manufacturing', ' advanced analytics', ' customer handling', ' html 5', ' cash collection', 'mocha', ' creating data architectures', ' microsoft development lifecycle', ' assistant business analyst', ' sap fico', ' speech recognition', ' restful', ' ibpm', ' corporate intelligence', ' android app', ' ci & cd', 'training delivery', ' data migration analyst', ' ich-gcp', 'trade', ' valgrind', ' wmi', ' sybase', ' private label', 'cobol', ' spare parts', ' dax', 'programming', ' digital media', 'matlab', ' sql database design', ' sqs', ' swot analysis', ' talend etl', ' pl sql enterprise hana', ' praat', ' information security analyst', ' ksql', ' vas', ' akka', ' tfvc', ' database structure', ' perpetual inventory', ' process excellence', ' abap', ' risk analytics', ' glm algorithms', ' azure adf', ' reg framework', ' gcp analytics', ' ssh', ' mean stack', ' product implementation', ' enterprise business', 'help desk', ' tag deployment', ' xd', ' genism', ' cloud migration', ' corporate actions', 'microservice based architecture', 'senior big data developer', ' business process modeling enterprise to department level', ' frontend development', ' supply chain network optimization', ' spanish', 'audio editing', ' commercial', 'dashboarding', 'tax', ' kaizen', ' analytical techniques', ' mwaa s3', ' product portfolio', ' nsgs', ' master data mgmt', ' revenue planning', ' device tree', ' coal', ' business intelligence analyst', ' performance monitoring', ' dwh', ' lr', 'servicenow', 'java mapreduce', ' project portfolio management', ' hr system support', ' azure synapseazure', ' cgi', ' business continuity', ' product vision', ' product development life cycle', ' alert monitoring', ' pivottables', ' software testing life cycle', ' tableau', ' oaf', ' spark scala', ' data organization', ' devops engineer', ' lean', ' oracle db sql', ' google colab', 'data modelling', ' coredata', ' recruiting system', ' licensing', ' black belt', ' commercial operations', 'resource utilization', 'big data architecture document', 'finance erp system', ' campaign analytics', ' database server', ' mvs', 'hr analyst', ' general ba', ' zoho', ' data pipeline development', ' maya', ' uikit', ' epm', ' database programming', ' jupyter', 'azure adls', ' sqlite', 'data verification', ' user-centered design', ' equity research analyst', ' team lead', ' cics', ' user interface designing', ' gdb', 'ai & ml', ' relational database', ' san', ' nodejs / typescript', ' intellij', ' conditional formatting', 'presentation', ' msft', ' azure dw', ' protein bioinformatics', ' hd insight', 'pci dss', 'node.js', ' client management', ' plant engineering', ' nosql databases', ' software product management', ' glr', ' advanced python', ' base sas', ' dimensional modelling', 'databricks ml', ' it analysis', ' apache atlas', ' doctor', ' manager client servicing', ' data ingestion design', 'system integration', ' external audit', ' psm', ' azure full stack', 'bw 4hana', ' ui data', ' data mart', ' heavy machinery', ' sketch', ' hr dashboard', 'adobe suite', ' google adwords', 'prototype analysis', ' erm', ' proc transpose', ' visual', ' material science', 'hortonworks', 'data warehousing - sse/de/ architect', 'performance', 'system configuration', ' game', ' customer analysis', ' etrms', ' mvc framework', 'devops pipeline', ' quantitative diagnosis', ' sap bi', ' advanced excel', ' strategic sourcing', 'data science', ' client handling', 'data architect', ' data analysis expressions', 'network programming', ' alfresco', ' backbone', ' hql', ' retail credit', ' core banking solution', ' saving', ' network monitoring', 'mvt structure', 'haskell', ' dml', ' requirement analysis', ' costing', ' stock exchange', ' xml', ' expressjs', ' pytorch', ' auto domain', ' scrapy', 'architecting', ' ms azure ci', ' client presentations', 'business intelligence', ' cam', ' restful micro', ' box', ' delivery management', ' trade and customs analyst', ' nlp algorithms', 'lookup', 'disaster recovery', ' hadoop.', 'head business development', ' mulesoft', ' azure services', ' workflow analysis', ' angular 12', ' vsam', ' spec', ' - tier', ' bots', ' software frameworks', 'debt collection', ' withgcp', 'senior analyst', ' restful api', 'azure databricks', ' qa automation', ' multi - process', ' eee', ' pathway', ' workflows', ' cloud data fusion', ' motorola', 'pubsub', 'google cloud azure', ' regualatory projects', 'advanced analytics', ' money laundering', 'qa data', ' concatenate', 'playbook', 'statistics', ' reporting tools', ' agile', ' hardware networking', ' information management', ' sap bw', 'decision making', 'program delivery', 'data stewardship process', ' no - sql databases', ' firebug', 'data anlalytics', ' workload executive', ' process optimization', 'bigquery', ' revenue generation', ' contact center operations', ' dart cross', ' glue tables', ' sqlserver', ' medical', ' pcmcs', ' google cloud storage', ' outlook', ' administration of windows', ' risk engineering', 'secondary data', ' fi', 'ld. prod svcs app sup anlyst', ' human resource management', ' dell boomi', ' corporate taxation', ' functional analyst', 'big query', ' kafka broker', 'financial reporting', ' associate content analyst', ' credit risk modeling', ' microbiology', 'verbal written', ' compensation data', ' azure search', ' digital asset management', ' creative communication', ' analytical thinking', 'rss', 'mcom', 'spark streaming', ' large deals', 'rwa', ' informatica datastage', ' corporate sales', 'fatca', 'scala', ' hofs & data engineering', ' function modules', ' tqm', ' machine learning', ' azure data lake analytics', ' verbal', 'service contracts', ' mssql', ' iso 13485', ' kerala', ' distribution network', ' antivirus', ' optimazation', ' pricing', ' b . tech', ' web architecture', ' pmbok', ' civil engineering', ' agile methodologies', 'formulation development', 'cloud computing', ' ios ipa', ' cognos analytics', ' product analytics associate', ' runmyjobs', ' client solutions', ' malware analysis', ' senior', 'power electronics', 'mssql dba', 'expert in microsoft excel', ' agile environment', ' dax power bi', ' test case creation', ' mdx', 'e-learning', 'rpa', ' gcp stack', 'rtos', 'azure data warehouse', ' dash bo', ' aiml technical architect', ' hockeyapp', 'ml algorithms', ' enterprise data warehouse', ' mentoring', ' certified', ' google webmaster tools', ' cudnn', ' ise', ' infosphere datastage', ' vba', ' big data engineer', 'jtag', ' client support', ' establish facts', ' aws big data', ' network optimization', ' postgresql', ' r12', ' project handling', ' back office processing', ' software development lifecycle', ' arcgis desktop', ' snow slm', ' rpo', ' data mappings', ' dso', ' hierarchy diagrams', ' data flakes', ' data extraction', ' decision models', ' consumer goods', ' verbatim coding', ' operations management', 'markit edm', ' entrepreneur', ' interpreting data', 'microsoft office suite', ' aws web services', 'creative solutions', ' technology consulting', ' basic', ' performance appraisal', ' fraud analysis', ' transcription', ' incident management', ' dataframe', 'asset management/', ' manager information technology', 'solution architecting', ' threat', ' mca', ' azure etl', ' process flow', 'ivr', ' python sdk', ' remediation', ' snowpipe', ' oracle hcm', ' ontology', ' lambda functions', 'root cause analysis', ' chartio', ' financial inclusion', ' employee retention', ' growth analytics', 'min', ' gensim', ' data steward', ' marketing planning', ' python framework', ' aws cloudtrail', 'gap analysis', ' procurement management', ' emi / emc compliance', 'customer service representative', ' embedded linux', ' tibco data virtualization', ' oo', ' big data warehouse', ' technical recruitment', ' awsazuregcp', ' bamboo', ' flutter', ' r scripts', ' corporate governance', 'statutory audit', ' linux engineer', ' hadoop testing', 'hdfs', ' travel management', ' data stewardship', 'agile methodology', ' sql olap', ' typing', 'financial statements', ' feasibility analysis', ' strategy formulation', ' solidatus', 'hris', ' data analysis', ' linear logistic regression', ' software implementation', ' pivot', ' synapse pipeline', 'data engineer ii', ' data factory', ' market basket analysis', ' ua testing', ' engineering procurement', ' financial research', ' report preparation', ' b2b communications', ' b2c marketing strategy', ' object - relational mapping ( orm', ' web service', ' idrp', ' infrastructure', ' vendor management', ' security compliance', ' hadoop cluster', ' salesforce com configuration', 'hmi programming', ' sql azure', ' process monitoring', ' erp', 'software engineer', ' greenplum', ' hyperion planning', 'reinsurance', 'javascript/html5/css', 'process optimization', 'asp.net', ' consumer research', 'path management', ' data entry', ' spark python', ' analytical', 'mdm tools', ' c# scripting', ' quantitative analyst', ' data flow', ' business requirement analysis', 'big data analyst', ' e-sourcing', ' cassandra', ' guest house', ' mapreduce programming', 'project coordinator', ' troubleshooting skills', ' optimizations', ' sales operations analyst', ' tax returns', ' imagenow', ' customer profiling', ' disaster recovery', ' python based framework', ' plm', ' unisim', ' apache spark administration', ' handling large data', ' travel', ' matplotlib', 'web services', ' metric management', ' xslt', ' wind energy', 'c - nn', ' radar algorithm', ' business modeling', ' engineering calculations', ' openshift paas', ' blue prism knowledge', 'olap', 'neural network nlp', ' software engineering manager', ' mis managment', ' process flows', ' superset tools', 'business finance', ' azure file storage', ' chemistry', ' corporate banking', ' angularjs', ' ooad', ' mvvm', 'qa testing', 'big data architect', ' usage', ' data mining methodologies', ' help desk', ' business and technical metadata management', 'etl tools', ' root cause analysis', ' team handling', ' oop', ' survey', ' client coordination', 'chemical analysis', ' solutions', ' civil', ' big data testing', ' tpa', ' corporate', 'medra', ' pyramid', ' packaging', 'database warehouse', ' data sources', ' web designing', ' anti money laundering', ' bos', ' datalake', 'information research', ' pomdp', ' data forecasting', ' machin learning', ' object oriented design', ' computational algorithms', ' vcf', ' rfps', ' video conferencing', ' endpoint security', ' etl tools', ' web platforms', 'informatica mdm', 'data sheets', ' etl / elt', ' hydrocarbon', 'zookeeper hive', ' composer', ' sprint process', ' pmml', ' semantic data modeling', ' prosecution', ' website', 'rcm', ' azure cloud service', ' a/b testing', ' nimbusml', ' django orm', ' loan documentation', 'lambda', 'design patterns', 'kernel', 'test case preparation', 'beauty', 'data architecture', ' sql query writing', ' risk analysis', 'aws lex', ' data science', ' shell scripting', ' glmm', 'business process', ' social media', ' flume', ' business requirement document', ' vmware', 'ml architect', ' vtk', 'retail banking', ' project planning', ' veeva crm', 'microsoft office', 'apache flink', ' data engineering analyst', ' sdet', ' database designproduct engineering', ' npm', ' windows server administrator', ' cognos', ' actuary', ' scripting', ' android sdk', ' lamda', ' data ingestion patterns', ' insights generation', ' infrastructure management', ' hyper-v', ' rest api design', 'literature', ' erp implementation', ' cocoapods', ' sql/plsql', ' keyword analysis', 'cdc ingestion', ' alation', 'qlikview', ' plant maintenance', ' azure data lake store gen 2', ' green plum', ' senior executive', ' powerbi desktop', ' soc consultant', ' ui / ux design', ' python unix', ' nlg', ' financial model', ' machine learning frameworks', ' cosmos db', 'market sizing', ' gl', ' business reporting', ' oracle 9i', 'digital media', ' distributed computing tools', ' sap mdm consultant', 'drilling', ' etl development', 'capital market', 'datafactory', ' puppeta', ' sap btp', ' jd edwards', ' jest', 'ssis', ' ui path developer', ' big query', 'supply chain management', ' server programming', 'perl script', ' stats graduate', ' maria db', 'deployment', 'power bi', ' cvs', ' microsoft azure platform', 'aws', ' soft skills', ' people skills', ' natural language processing', ' bug tracking tool', 'hadoop', ' powerbi', ' presto', ' promotional campaigns', ' cloud storage', ' druid', ' sas database', ' hyperion hfm', ' adobe xd', ' ids firewall', ' cost management', ' user interface testing', ' data domain', 'construction management', ' image recognition', ' ec2', ' cnns', ' associate lead', 'scalaspark', 'teradata data science', 'energy market', ' auth0', ' email communication', ' glycoprotein', ' non voice process', ' python and r', ' engineer engineering', ' global marketing', ' data quality analysis', ' process mapping', ' openstack', ' activevos logs', 'tosca testing', 'machine learning algorithms', ' docker containerization', ' microsoft visual studio', ' google analytics', ' portuguese', ' apache qpid', ' aws glue athena', ' office equipment', ' solid design', ' ftp', ' c + +', ' sas di', ' aws cloudformation', 'e-commerce seo specialist', ' iso 27001 lead auditor', ' epidemiology', ' aviation', ' open dp', ' capital management', ' - driven', 'big data testing', ' spark pools', 'aws pyspark', 'data engineering', 'marketing head', 'data coding', ' reactjs', ' google bigquery', ' java scripts', 'zoho', 'pdf extraction', ' azure', ' azure data engineer', ' social networking', ' continuous improvement', ' orc', ' campaign management', ' un- supervised learning', ' business intelligence reporting', ' business process schemas', ' ascii spss excel', ' data privacy', 'front end', 'packaging', 'financial', ' core hr', ' zookeepers', ' shark', ' maven tool', ' data standardization', ' data dictionary', ' sas macros', ' research analysis', ' principal data scientist', ' snowflake schema', ' data capture', ' continuous integration', ' version control', ' gitlab', ' stream sets', ' enterprise master data', ' analytics lead', 'vlookup', ' product control', 'consulting - bfsi', 'candidae shall quick learner with good communication and team skills and excellent coordination wih hod and support staff', ' data warehouse design', 'pricing analysis', 'senior data engineer', ' adwords', ' power designer', 'software testing', 'etl process', ' big data tools', ' crm integration', ' h2o', ' datastore', ' ux designer', ' c++python', ' venture capital', ' data reconciliation', ' pyqt', ' crawling', ' integration - testing', ' scalar', ' cloud solutions', ' calculus', 'customer analytics', 'architecture', 'corelocation', ' hadoop eco', ' engineering management', ' adfs', ' sql spark', 'mining', ' cold calling', 'advanced excel formulas', ' quant analyst', ' income tax', ' game development', 'customer support', 'data link', ' hive analytics', ' s', 'machine learning ops', ' ingestion', ' power apps development', ' record to report', ' counselling', ' financial planning', ' itil process', ' vb script', ' stress testing', ' business operations', ' cisco', ' intelligence', ' loadrunner', ' rfx', ' zoominfo', 'aws emr', ' r programming', ' socialbakers', 's/4 hana', ' legal operations', ' consulting retail', ' product engineering', ' omniture', ' pumps', ' ms', ' student engagement', 'azure analytics', ' arcgis', ' sequence diagrams', ' it business analyst', ' rllib', ' linux & solaris & their patch management', ' sql performance tuning', ' network services', ' computer science', ' oracle agile', ' purchase', ' algorithm design', ' chrome extension', 'access management', ' c #', ' evaluation', ' patient data', 'informatica data quality', ' ngaa platform', 'socket programming', ' guidewire application development', ' retail marketing', ' analytical skill', ' risk management', ' control-m', ' financial packages', ' water', ' ventilation', 'computational biology', ' data wrangling', ' relational database design', ' internal audit consulting', ' power integrity', ' java j2ee developer', 'oic', ' sonar', ' peachtree', ' informatica development', ' azure synapse', ' information architecture', ' atscale', ' aws data base migration service', ' performance engineering', ' development testing', ' interior architect', ' accounts payable', ' personnel administration', 'tivoli', ' cloud aws lambda', ' adls', 'dynamics', ' ab initio software', 'sql dba', ' support analyst', 'open source', ' lead architect', ' ms office powerpoint', ' rest api development', ' web research', ' segmentation techniques', ' lead designer', ' data mart development', ' informatica', 'epbcs', 'bi lead', ' genetics', 'statistical techniques', 'reference data', ' teaching', ' system analysis', ' market scenerio', ' commercial vehicle', ' animation', ' customer experience management', ' developer', ' data privacy management', ' workforce analytics', ' lambda data prep', ' computer aided engineer', ' statical analytics', 'research analyst', 'visual studio 2017', 'transformers', 'capacity management', ' accounts receivable', ' wincross', ' net core', 'text analytics', 'time series analysis', 'technical data management', ' microsoft azure dev', ' sql jobs', 'lacp', 'auto industry', ' vba access', ' client satisfaction', ' data processor', ' risk monitoring', ' rdbms ms sql server', ' supplier relationship management', ' technical staff', ' push services', ' aspen', 'big data platforms', 'pig', ' sql alchemy', ' bpo', ' sap analytics cloud', 'service desk', ' non linear optimization', ' semiconductor manufacturing', ' data quality', ' managing', ' functional analysis', ' microservice based architecture', 'marketing analyst', 'equity', ' fraud analytics', ' clinical data coder', ' acquisition strategy', ' views', ' research lead', ' front office executive', ' arcgis pro', ' logical approach', ' veeva suggestions', ' intellij idea', ' vott', ' design architect', 'r dbt', ' efficacy', ' sass', 'process mining', ' periscope', 'organic synthesis', ' relational database service', ' sitecatalyst', ' databases administration', 'software suite', ' end user', 'python data analytics', ' r language', ' gaming', ' user stories', ' azure data lakes', ' health insurance', ' equity research', ' hr strategy', 'techno functional', ' data profiling', ' stored procedure', ' torch', 'html5', ' service contracts', 'aws sam', ' mechanical design', ' data strategy', 'waste management', ' ms visual basic', 'copa', ' biostatistician', 'redux', ' information technology', 'qualitative research', ' it product development', ' yarn', ' environmental science', '.net core', ' airflow', ' blogs', ' pl/sql', ' jenkins', ' entity security', ' knowledge of ms office', ' sap finance', ' business communication', ' business objectives', ' excellent', ' technology operations', ' technical analysis', ' service desk', ' analytical solutions', ' engineer product development', ' transform and load', ' data exploratory analysis', 'cloudera hadoop', ' cision', ' cochin', ' synapse', ' voice process', 'programming language', ' interpersonal skills', ' finma', ' postgres dbms', ' english', 'checkpoint fortigate', ' antlr', ' collectd', 'aws services', ' staff', ' python developer', 'snowflake', ' sql knowledge', ' credit assessment', 'rnn', ' trade settlements', 'quantitative analysis', ' digital analytics tools', ' manager', 'azure databricks admin', ' rooshal dsouza', ' transact sql', ' ai factory', ' collibra', ' client engagement', ' rewards and recognition', ' azure ecosystem', ' markit', ' cloudwatch', ' international business development', ' vendor master', 'monitoring', ' it security analyst', ' salesforce . com', 'azure data lake', ' boto3', ' nosql db', 'backend engineer', ' analyst', ' oltp', ' quick sight', 'sqa', 'etrm', ' market intelligence', ' fund administration', ' bms', ' power bi .', ' lead product designer', 'pyramid', ' data center activities', ' gcp cloud', ' aws cloud', ' ca intern', 'sap business objects', ' research engineer', ' analytics data', ' bmc', 'vertica', ' itl', ' demand planning', ' restful web api development', ' cma data', ' cloud applications', ' bdcs', ' machine learning algorithm', ' qa testing', ' web development', ' aml compliance', ' apache kafka', ' consulting analyst', ' equity derivatives', ' informatica. data science/ data management.business analysis workflow power bi/tableau or any other data visualization tools.oracle 10/11g- sql pl/sql or similar rdbms.', ' hypothesis testing. -experience working on building an ai conversation voice chatbot', ' operations manager', ' campaigns', ' anaconda enterprise', 'arimax', ' smb', ' proc sql', ' netbackup', 'patent landscaping', 'designing b2b and b2c products', 'unix scripting', ' change analyst', ' db replicas', ' boosting bagging techniques', ' dsp', ' performance metrics', ' seo executive', 'coding analyst', ' implementation support', ' computing', ' statistical', ' linkedin sales', ' tfserve', 'enterprise reporting', ' network programming', ' excel modeling', ' augmented reality', ' itil framework', ' author', 'smtp', ' cdc', ' hrsd framework', ' healthcare support operations', ' revenue recognition', ' modelling', ' software development life', ' tableau analytics', ' silicon', 'serverless', ' taxation', ' sql data analysis', ' ifs erp', ' maintenance operations', ' snowflake sql', 'alteryx tableau', ' c2c', ' aurora mysql', ' industry 4.0', ' scala', 'analysis skills', ' test design', ' traceability matrix', 'oozie', ' md', ' networking protocols', ' full stack development', ' cloud analytics', ' vpn', ' effort estimation', ' credit underwriting', 'atlassian tools', ' automation testing', ' ip routing', ' iis', 'account reconciliation', ' xpath', ' classification', ' media strategy', 'ci/cd pipeline', ' mis', ' rest api', ' l1', ' advanced sql', ' solution development', 'primary market research', ' effective communication', ' proteomics', ' market access', ' religare', ' power bi', ' ml algorithm', ' react', ' ci', ' it staffing', 'pmp', ' business process analysis', ' pcm', 'rest api design', ' power-bi', ' accounts payables', ' sql server analysis', 'matlababout', ' amazon athena', ' spark framework', ' oops concepts', ' copd', ' elt engineering', ' content filtering', ' aws spark', ' react js', 'data visualization tools', ' hotspot', ' excel sheet', ' accounts receivables', ' software product development', ' digital forensics', ' salesforce.com administration', ' sql analytics', ' pharmaceutical', ' cost reduction', 'os vulnerability management', ' cicd', ' journalism', 'gsm', ' hr mis', 'c# sharp & dot net', ' power bi development', ' heart disease', ' assistant manager r&d', ' scrum ceremonies', ' amazon macie', ' domain expert', 'cluster management', ' application support analyst', ' roads', ' ansi', ' risk mitigation', 'cloud storage', 'python/nodejs/java', ' technology solutions', ' decision sciences', ' go getter', ' knowledge management', ' oracle database', ' anatomy', ' hadoop technologies', 'qualitrix', ' transfer learning', ' advance analytics', ' html5+', 'system design', ' media', ' pci', ' cocoa framework', ' bootloader', ' copyright', ' gherkin', 'life sciences', ' baw', ' servicenow hiring', ' project management skills', ' asp net core', ' schema', ' engineering project management', ' data reports', 'hr', ' cosmosdb', ' elmo', ' presentation skills', ' data models', ' theano', 'statistics modelling preferably graduated in stats field.', ' platform development', ' cook', ' confidentiality', ' spacy', ' rest api s', ' build', 'spend analysis', ' project financial cost tracker', ' rackspace', ' etl data integration', ' design validation', 'large', ' visualization consultant', ' hyperparameter tuning', ' spark mllib', 'predictive modeling', ' hair care', ' debugging', ' database testing', ' corporate services', ' turbine', ' management audit', ' trade reporting', 'datapower', ' test cases', ' service bus', ' ml', ' compelling explainer', ' data warehouses', ' jboss', ' elt', 'dynamo db', ' azure data sql dw', ' emblem', ' hse', ' semiconductor', ' physics simulations', ' asp.net mvc', ' investor relations', 'fixed income', ' business process improvement', ' process design', ' openwrt', ' genpact', ' us healthcare', ' android coding', ' azure data lake services', ' seoluxury', 'fundamentals', ' contract abstraction', ' tier 3-4 support', ' mobile technology', 'windows administration', 'engineer ii', 'rca', ' microsoft technologies', ' veeva vault', ' database modelling', ' general ledger accounting', ' investment analytics', ' apics', ' python trainer', ' quality assurance engineering', ' telecom', ' sap mm', 'shell scripting', 'azure data factory', ' s / 4', ' oracle epm', ' data verification', ' shell.', ' mis reporting', 'chatbots', ' heroku', ' document management systems', 'c#', ' biochemistry', ' data bricks landscape', ' azure data factory', ' spring boot', 'sap ewm', ' simulation', ' looker', ' search engine marketing', 'qa', ' r program', ' creative designing', ' product operations', 'prototype', ' wholesale banking', ' hotspot data sync', ' recruiter', ' microsoft azure stack', 'unix shell scripting', ' scrum framework', ' cloud dw', 'azure data engineer', ' sales planning', ' emi', ' object relational mapper', ' tsql queries', ' lead', ' logic', ' procurement analyst', ' strategy deployment', ' ms sql dba', ' keyword research', ' salesforce com', ' development', ' corporate security', ' sumif', ' medicinal chemistry', ' rave', 'staff software engineer - full stack ( angular / node)', ' competitor analysis', 'model behaviors', 'mis updation', ' translation', ' adobe suite', ' mobile', ' linux administration', ' snowflake', ' software testing', 'fx', ' property management', ' lcl pricing', ' dwbi', ' it automation tools', ' payments', ' development lifecycle', ' information security management', 'r language', ' nosql technologies', 'written communication', ' payments compliance', ' line management', ' featured snippets', 'ssisssrs', ' big data tech stacks', ' jax - rs', 'dwbi', ' fme', 'sso', 'diagnostics', ' ci/cd', ' code refactoring', ' essbase', ' bq', ' medallia', ' trademarks', ' routing & switching', 'data analyst', 'business process modeling', ' sigma', ' .net core', ' sqlalchemy', ' keystone framework', 'visio', 'data', ' cloud technologies', 'analytical skills', ' drill', ' coding analyst', ' it hardware', ' iaas', ' ucs', 'azure synapse', ' end user support', ' elicitation', ' medical insurance', ' aws bigdata', ' invision app', ' decipher', 'software development engineer 2', ' google cloud platform', ' informatic', ' sdlc methodologies', 'listing', ' bi analyst', 'salesforce crm', ' pl - sql', ' activemq broker', 'sas sql', ' techno-commercial', ' business optimization', ' sap erp', ' market survey', ' solution analyst', ' medical devices', ' ms visio', ' espresso', ' informtica', ' prep', ' computer languages', ' japanese', ' business solutions', ' monitoring', ' amazon ai', ' aws/ azure', ' hiring', 'cloud warehouse', 'functional lead', ' support services', ' noc', ' database knowledge', ' scala programming', ' anomaly detection', ' scrum master', 'data quality process', ' supply chain analytics', ' test case', ' income tax audit', 'docker', ' strategic hr', ' front end', ' general administrator', ' commvault', ' spotfire', ' candidae shall be prepared for timel', ' tally', ' data modeling tool', ' ldap', 'microsoft excel', ' business suite', ' material ledger', ' litigation support', ' large data sets', ' business objects', ' emerging technologies', ' power point presentation', ' developing', ' ips', ' cloud aws', ' business development', ' azure logic app', ' legal advice', ' part time', 'jest', ' cassadra', ' automated tests', ' non voice', ' agrochemicals', ' ocr', ' training analysis', ' jupyter notebook', ' ecosystem', ' user story', ' database automation - ci/cd & devops', ' big data design patterns', ' bigdata engineer', ' linux script', ' apache spark', ' marketing management', ' sas model', 'master data', 'variance analysis', 'digital marketing', 'workday', ' quickbooks', ' odi', 'bigdata developer', ' ibm datapower', ' dataops', ' high availability', ' programing', ' pivot tables', ' vulnerability', ' ssjs', 'condition monitoring', ' data imputations', ' netsuite', ' treasury operations', ' mixed signal', ' ms data management', ' campaign execution', ' cybersecurity data science', ' banking operations', ' lead management', ' employee records', ' event grid', ' dynamo', ' proprietary trading', 'applied intelligence', ' data collection', ' manufacturing process', ' cluster analysis', 'distribution analysis', 'machine learning operations', ' bioanalytical', 'microservices', 'conversions', 'printing', ' design studio', ' data annotation', ' process analysis', ' rust', ' relational database management systems', ' infrastructure services', ' statistical analyst', ' software sales', ' azure sql pools', ' copywriter', ' benefit analysis', ' nist', ' gis software', ' oracle service bus', ' shell', ' bw', ' investment strategies', ' big data spark sql', ' azure active directory', 'pmo', ' air flow', 'architecture shell', 'dom', ' making', 'matillion', ' query authoring', ' ci cd', ' rfp', ' base shell', ' databases', ' helpdesk', ' easy writer', ' digital strategy', ' director', ' embedded c', ' portfolio management', 'market research', ' programmer analyst', ' scala developer', 'ui development', ' sc', 'sdlc', ' qt', ' microsoft windows programming', ' tsne', ' product innovation', ' timescale', ' mis generation', 'process management', 'excel', 'css', ' basic networking', ' value added services', ' impact analysis', ' patterns', ' sparql', ' software packages', ' mysql', 'process audit', ' pay per click', ' palantir', ' bdd', ' work', 'legal contracts', ' etl/elt', ' business analysis', ' bios', 'sap master data governance', 'adobe experience manager', ' azure cloud engineer', ' accountancy', ' mergers', 'data visulization', ' hana data warehouse', ' data integration engineer', ' open query', ' pgdca', ' investment risk', ' invoice processing', ' hcm', 'data enrichment', ' defect analysis', ' virtualization', ' data compression', ' programming knowledge', ' mis report', ' matlab', ' informatica master data management', ' unit testing framework', ' data warehousing concepts', ' online banking', ' direct sales', ' infringement', ' security testing', ' design specifications', ' vehicle dynamics', ' e-governance', ' rf', 'automation', ' dodaf', ' data testing', ' quantexa', ' hadoop dfs', ' database warehousing', ' aws snowflake', ' api gateway', ' data audit', ' application architecture', ' general accounting', ' french', ' s3', 'agile methodologies', ' software configuration management', ' test strategy', ' research associate', ' risk governance', ' layout design engineering', ' mesos', ' network administration', ' training', ' data engineer python sql', ' node', 'test reporting', ' synapse / dw', ' aem', 'crawler data engineer', ' mortgage underwriting', ' ms - sql', 'computer vision', ' tuning', 'data42 platforms', ' data - sql', 'd3 js', 'bfsi', ' data centre', ' public relations', ' atlassian tools', 'linux internals', ' content analytics', ' lightgbm.', ' reporting analyst', ' market mix modelling', ' access control', ' notion', ' oop skills', ' agile software design life cycle', ' apex', ' hr policies', 'datascience', 'debugging', ' vlan', ' client servicing', ' py', ' product mapping', ' erwin tool', ' cmbs', 'java', 'microsoft sql server 2012', 'medical devices', ' consulting - retail', ' database administration', ' interface testing', ' system architecture', ' columns', ' sql database', ' bds', ' senior data scientist', ' associate data analyst', ' sql server 2008', 'cca', ' sales engineering', 'cognos', 'swift', 'deep troubleshooting', ' computer operator', ' eia', ' pre sales', ' automation frameworks', ' bitbucket', ' client meeting', ' struts', ' maximo data migration', ' asset management analyst', 'strategy consulting', ' hadoop family', ' microfinance', ' interpret data', 'retail domain', 'azure synapse analytics', ' operational skills', 'enterprise cloud', ' skill development', 'scripting language skills', ' pig', ' azure sql db', ' ms sql server', 'wind modelling', ' category management', 'operations analyst', 'sentry', 'agile framework', ' azure cl', ' oops', ' reconciliation', ' asset management', ' service delivery', ' rta', ' resource requirements', ' it lead', ' google cloud sdk', 'hibernate', ' coding and development', ' ale', ' process development', 'ngs data analysis', ' data base administration', ' project leading', 'snowflake db', ' principal', ' oracle analytics', ' aws crawlers', ' performance analyst', ' data developer', ' vuejs', 'r&d', 'statistical modelling', ' predictive model', ' web scrapping', ' draw io', 'object oriented analysis', 'oracle', 'python frameworks', ' ssis developer', ' solution implementation', ' solution delivery', ' senior data analyst', ' solar', ' aci', 'project management', ' innovation management', ' english language', ' hadoop developer', 'sql scripting', ' everbridge', ' fi derivatives product', ' swaps', ' iterative', ' distributed training', ' pharma', 'informatica idq', ' mode analytics', ' ssp', ' data anayst', ' oracle e', ' ux', ' opentext', 'strong analytical skills', ' mis manager', 'public relations', ' market analyst', ' hybrid cloud infrastructure', ' functional design', ' dfm', 'sales', ' regulatory issues', ' apache nifi', ' ms project', ' qa data management', 'sitecore', ' system maintenance', 'information security', ' django framework', ' technical skills', 'ms windows', ' user experience design', 'manager technology', ' anypoint', ' tdm', ' sockets', ' sql query', ' sdlc process', 'quantum', 'google cloud', 'aws lambda', ' ehr database mapping', ' computer vision', 'informatica master data management', ' credit derivatives swaps', ' msft word', 'jmeter', ' data processing', ' spring batch', ' sales engineer', ' environment', ' pilot plant', ' operating systems', ' documents', ' mixpanel', ' maintain workload files', 'environmental analyst', ' managed services', 'microsoft sql server', ' apache 9', ' graph', 'ai modelling', ' object - oriented development', ' software distribution', 'digital transformations', ' investment', ' natural language generation', ' editing', ' web / application servers', 'ehs', ' business awareness', ' email marketing', ' onetrust', ' it sourcing business analyst', ' solution architecting', ' analytics models', ' kibana', ' data analysis and project management.', ' configuration management', ' order processing', ' datawarehousing', ' transaction processing', ' middleware', ' sme', ' cloud concepts', 'vmware', 'client communication', 'sr. data analyst', ' iqn', ' data flow mapper', ' linear regression', ' crc', ' financial', ' pcb design', ' elastic search sold', 'data model', ' voip', 'bloomberg', ' apache airflow', 's3 data lake', ' big data analysis tool', ' cosmos db master', ' freshers', ' web technologies', 'eloqua', 'react native', ' cognitive search', ' full stack developer', ' java spring framework', ' microsoft ssis', ' strings', 'ml development', ' drupal', ' query resolution', 'global operations', ' sql dwh', ' cloud portal', 'hr analytics', ' java/python', ' data engineering manager', ' whodd', ' agile framework', ' process re-engineering', ' ds modelling', ' cloud essentials', ' data engineer/etl developer', ' zyputer', ' electronics engineering', ' lead assistant manager', ' identifying', ' sap fiori', ' cicd deployment', ' azure data architect', 'sap webi', ' excel dashboards', ' ms-excel skills', 'marketing programs', ' medicare', ' drafting', ' testing', ' hadoop cloudera distribution', ' assortment planning', 'test data management', ' terraform', ' monitoring tools', 'database architecture', ' sap mdg', ' advertising', ' soc analyst', ' ed', ' kubeflow', 'faster payments', 'engineering project management', ' product specification', ' big data data', 'teradata sql', ' staffing', ' v5 collibra', ' cloud platform', ' sap erp implementation', ' system admin support', 'application programming', ' jmeter', ' servlets', ' oozieairflow', ' data processing analyst', ' mlops', ' azure data lake store', 'test scripts', ' customer analytics', ' automl', 'azure iot engineer (streaming data)', ' aws/azure data services', 'aws cloudformation', ' microsoft modern data platform', ' real time analysis', ' data analysts with business analysis', ' it operations', ' search engines', ' pharmacy', ' manager presales', ' - end', ' no sql', 'oracle database', ' account planning', 'sigma', ' advisory', ' corrective action', ' query handling', ' software project', ' data architect', 'hedge funds', ' active directory', 'statistical testing', 'daily accounting', ' transportation planning', 'advanced excel', ' cloud architectures', ' endur', ' matillion snowflake', ' dashboard development', ' internal control', ' review data', 'data intelligence', ' production support', ' data systems specialist', ' rest assured', ' spark code', ' supplier management', ' training and development', ' linux kernel', ' data dictionaries', ' arcgis server', ' skillsql', 'hospitality', ' financial data analyst', 'ecc', ' digital engineering', ' azure datafactory', 'material management', ' environment health safety', ' handling', ' big data language', ' direct tax', ' soap ui', ' speech analytics', 'kubernetes', ' inbound calls', ' training delivery', ' scoop', ' hadoop hive', ' thoughtspot', ' oracle financials', 'dimension', ' ecosys', ' hydraulic actuators', ' bpc', ' analysis services', ' simulation modeling', ' automation framework', ' sfmc', ' test automation', ' risk modeling', ' executive management', ' oracle soa', 'prtg', 'fccs', 'matplotlib', ' medical writing', ' grammar', ' distribution system', ' programming', ' python 3', ' data querying', ' system interface diagrams', ' kudu', ' project implementation', ' consultant', ' microsoft power bi architecture', 'process orientation', 'wireframe', ' stakeholders', ' problem solving skills', ' full stack', ' adb+adf+python', ' sales forecasting', ' voice', ' high performance computing', ' next js', ' consumer marketing', ' sap apo', 'image recognition', 'paid social media marketing', ' data platform', ' data noc', ' data modeling tools', ' pca', 'snowflake / redshift', ' broadcasting', ' head hunting', ' chemical', ' ebx5', ' technology', 'advanced statistics', ' team manager', 'quality orientation', ' quality tools', ' azure python', ' technical leadership', ' supply chain operations', 'apache', ' edm', ' adobe analytics', 'core data', ' program manager', 'defect analysis', ' data monitoring', 'industry reports', 'vba automation', 'business system', ' informatica powercenter', ' engineeringdatabase', ' process compliance', ' cruise control', ' operational risk reporting', ' infosphere', ' sql scripts', ' rls', ' kpi', 'ml', 'sql server', 'sap co', ' webhooks', ' pubsub', ' spacity', ' sap fi', 'stress testing', 'cae', 'remediation', ' otbi', ' usability testing', ' saml', ' test scripts', 'qliksense', ' liquidity management', ' fortigate', ' data architects', ' oracle support', ' hotjar', ' load testing', ' competencies', ' hardware specification analysis', ' gurobi', ' sparkql', ' install base', 'sysops', 'talend open studio', \" restful api's\", 'plm', ' mobile phones', ' idms', 'metadata', ' quality consultant', ' computational biology', 'principal director', 'mis analyst', ' plc programming', ' cfa level 2', ' application management', ' sld', ' a3', 'technology consulting', ' sap', ' power point', 'configuration', ' dw program management', 'sqlite', ' general ledger', ' business insights', ' machine -', 'amazon web services', ' data lineage', 'windows server configuration', ' salesforce.com development', ' solutions.ai', ' ui design', 'sql server database', ' commercial real estate', 'architectural design', ' rabbit mq', ' illustrator', 'iisc', 'it recruitment', 'knowledge of big data stackdata modelling', ' warehouse management', 'people management', ' machine learning lifecycle', 'active directory', 'mis generation', 'lda', ' sap data reports', 'data ingestion elt', 'trading system', ' network security', ' senior business process analyst', ' google spreadsheet', ' cmdb', ' sql pools', ' data base', 's3', ' corporate it operations', ' brand management', ' switching', ' mba marketing', ' c developer', ' ratio analysis', ' feature engineering', ' azure stack module', ' cash management', ' e-discovery', ' real time operating systems', 'sas', ' bugzilla', ' etl projects', 'sap hcm', ' programming languages', ' linux', ' data sciences', ' windows 2008', ' sip', ' hazard analysis', ' plc', ' cross architecture', 'section engineer - afc', ' maintainance', ' power - bi', 'development testing', 'service delivery', ' azure ml', ' dataflow', ' roadmap', 'figma', 'accountancy', ' demand analytics', ' java enterprise', ' international clients', ' database building', ' titan', ' pycharm', ' mbs data', ' back office', ' ibm mq', ' lab analyst', ' cio', ' frameworks', ' epc', ' design analysis', ' dl math', ' data research analyst', ' organic polymers', ' websense', ' communication', ' keyboard', ' implement', 'data transformation', ' cognos 11 version', ' peoplesoft', 'big data analytics', 'unix linux', 'campaign planning', ' beautifulsoup', 'application designing', ' social science', 'r/python', 'managed services', ' cloud data engineer', ' selenium', ' sftp protocols', ' azure sql', ' cloudera data', ' jms', ' learning', 'online research', ' medical monitor', 'financial research', ' product owner', ' analysis of data', ' building ds solutions', ' azure sql database', 'process improvement', ' technology regulation', ' fertilizer', ' process data engineer', 'angular 4+', ' proc', ' data quality analyst', ' object - oriented concepts', ' ssl', 'customer relationship management', 'ip addressing', ' life cycle', ' pmo', 'enterprise content management', ' cloud services', 't-sql', ' css', ' performance tuning', 'wireless', ' scientists', ' control management', ' execution', 'product catalog', ' flutter mobile uis', ' relational sql', ' water structures', ' customer acceptance testing', ' business presentation', ' jmp', ' etl with aws', ' cause analysis', ' data quality assessment', ' ml libraries &application', ' survey questionnaire', ' firmware', ' kubernetes service *ml', 'tdd', ' devops', ' technical', ' visualization engineer', ' data platforms', 'data migration', ' unix operating system', ' post gress', ' geopandas', ' healthcare operations', ' ingestion tier', ' image segmentation', ' aix scripting', ' ccna', 'security analysis', ' reference data management', ' project analyst', 'sme bank data', ' provident fund', ' cloud aidevopsmachine', ' reference data', ' sdk', ' financial accounting', ' azure sql data warehouse', ' data services', ' statistical modeling', ' regulatory guidelines', ' analysis coding', 'forms', ' web tools', ' data management', ' conceptualization', ' kafka and kafka', ' jcl', ' adl', ' cdqa', ' vision', ' process improvement projects', ' analysing', 'problem solving and decision-making skills', ' data warehouse', ' prolease', ' rss', ' typing speed', ' field marketing', ' as2', ' ms office package', 'data governance', ' corporate finance', ' information system design', ' b2b sales', ' ecc', ' ado net', ' web services', 'corporate strategy', ' analysis', 'java web services', ' perforce', ' hysys', ' scheduling', ' t', ' nprinting', ' ups', ' management reports', ' soql', ' power queries', ' knowledge of computers', ' supply chain solutions', 'excellent communication', 'asp net', 'finance manager', 'redux saga', ' aws data tools', ' dlp policies', ' d3j', ' visualization tools', 'tomcat', 'life cycle', ' sda', ' neural networks', ' moss', ' murex', ' sql server database', ' aws oracle rds', ' data maintenance', ' networks', 'sap', ' excel macros', ' data modeling', ' mangodb', ' processing', 'adobe analytics', ' visualization', ' clinical monitoring', ' non it recruitment', 'sap mm materials management', ' perl', ' gpt', 'impala', 'power query', ' it infrastructure', ' scala with spark', ' good communication skills', 'microsoft sql', ' good communication skill', ' headless chrome', ' end user training', ' micro services architecture', 'gunicorn', ' lotus notes', ' auditing', ' machine language', 'tasks', ' data proc', ' aws', ' manager program management', ' maths', 'stash', 'web development', 'ssas', ' e - mail', ' legal', ' visualizing', 'ibm', ' google data studio', ' h-sql', ' data apis', ' tcp', ' sap bpc', ' engineer analyst', ' appium', ' wind', ' artificial neural networks', ' athena', ' pu - sub', ' hris analyst', ' user documentation', ' statistical learning', ' elasticache', ' java/golang/kotlin', ' charles', ' rds', ' group head', ' hortonworks hadoop', ' machine learning ml', ' industry analysis', ' jsonnet', ' blackbox', ' cadence', 'usfda', ' hr processes', 'jdbc', ' taxonomy', ' rapid miner', ' risk analyst', ' windographer', ' use cases', ' oauth', ' forecasting skills', ' incharge', ' demand management', 'sap finance', 'operations management', ' static data', ' soap', ' ensemble', ' audit command language', ' notebooks development', ' power operations', 'power and utilities', ' training & development', ' full stack application development', ' pmp', ' financial services', ' roc', 'vnet', 'disaster recovery planning', ' selection process', 'cloudera data', ' building', 'data mapping', ' vnet', ' fintech', ' citrix', ' competitive intelligence', ' circleci', 'package configuration', ' open-source code', ' memcached aws', ' language skills', ' core banking', ' apis', ' site management', ' alarm management', 'inventory management', 'mongo', ' installation', 'sosl', ' cissp', 'python scripting', ' software engineering', ' bills receivables', ' lead generation', ' cataloguing', ' tableau apis', 'restful apis', ' hld', ' project management office', ' seaborn', ' object oriented programming', ' computer skills', ' insurance', ' email support', ' rpc', ' hadoop hortonworks', 'dataflow', ' elastic search', ' business analysts', 'code review', ' vba coding', ' data structurescapacity planning', ' risk consulting', ' account development', ' cloudera', ' regulatory reporting', ' kafka rabbit mq', ' hadoop architecture', ' data and analytics', 'aiml', ' cloud strategy', ' h1b', ' mentor', ' cosmo db', ' information retrieval', ' memory management', ' sql developer', ' isomorphic react', ' python skills', ' fab process', ' db querying', ' model deployment', ' trend forecasting', ' next.js', ' business system analyst', ' bigdata technologies', ' social', ' powerapps', 'sre', ' nifi', ' intranet', ' mining', ' power bi reports', 'esri certified geodata', ' statistical modelling', ' eai', ' azure adls gen2', '.net', ' bioinformatics', 'minimum 4 years experience as data business analyst', ' power pivot tables', ' data lifecycle', ' pwd', ' cpi', ' qtest', 'nlp/python/r', 'it business analyst', 'content management', 'restful api', ' aws ses', ' academic research', 'web scraping', ' regression modeling', ' executive search', 'bitbucket', ' hcp', 'mean stack', ' pl / sql', ' dimensional data modeling', ' computer vision stack', ' nutrition', 'aas', ' requirements management', ' credit card', ' netcool omnibus', ' oracle sql', ' t - sql', ' analytics studio', ' data solution', 'troubleshooting', ' routing', ' data vault', ' sap development', ' qgis pix4d', ' containerization', ' trams', ' flink', 'analytical project management', ' team development', ' research', 'cisco routers', 'sap master data management consultant', ' android development', ' data integrations patterns', ' json', ' ecmascript', 'administration', ' postgresql schema', ' qlik coder', ' azure information protection', ' esxi', ' hadoop administration', ' epigenomics', ' mdm ui', 'gcp', ' scikit learn', ' predictive modelling', 'marketing analytics', ' sparksql', ' feature selection', ' data enrichment', 'polyglot', ' opt', 'ms sql', ' unix scripting', 'cargo', ' data base management', 'linux', 'ml libraries', ' ml algorithms', 'margins', ' delivery excellence', ' time series', 'nexus switches', 'relationship management', 'tapeout engineering', ' cpm', ' inside sales', ' metadata management', ' system testing', ' it compliance', ' communications skills', 'sap c4c', ' pmi acp', 'strategy', ' pyython', ' microservice architecture', ' aws athena', ' content management communication', 'glue', ' netconf', ' mis analyst', 'performance tuning', ' new product development', ' aws data pipeline', ' low level design', 'sql python', ' query optimization teradata', ' software engineering lead', ' driven', 'tealium', ' desktop support', ' code', ' test data', ' clinical data management', ' c / c++', ' d3', ' career development', ' proof reading', ' business planning', 'business solutions', ' freight', ' content marketing', ' dwh testing', 'firebase', ' scorecard', ' filenet', ' restapi', ' benefits evaluation', ' product placement', 'cati', ' hedge funds', ' physical verification', ' banking', ' text analytics', ' no sql db', ' orchestrators airflow', ' integration', ' white box testing', ' dream weaver', ' db modelling', 'manufacturing data scientist', ' data storage', ' technical services', ' internal communication', ' tibco', ' compliance', ' sprint boot', ' azure logic apps', ' log analysis', 'brd', ' remote sensing', ' analytics reporting', ' pyspark sql', ' demand forecasting', ' data storytelling', ' careerbuilder', ' linux server', ' computervision', ' crimsons hexagon', ' application engineering', ' hadoop v2', ' junior research analyst', ' brand marketing', 'cyber security', ' slas', ' be', ' configuration', ' client relationship', 'mis reporting', ' oracle procedural', 'time series forecasting', ' client sanctions screening', ' sql pl sql', 'data engineer', ' ihs', ' ifrs', ' dimensionality reduction', ' snaplogic', ' process efficiency', 'agile development methodologies', ' snowflake data warehouse', ' big data architecture', ' varonis', ' ses', 'angularjs', ' graph analytics', ' tensorflow', ' cloud infrastructure', ' business intelligence', ' fas', ' asic', ' machine queues', ' statistical programmer', ' designing', ' python programmer', ' content development', ' google f1', ' sabre', ' wholesale', ' artifi', ' system troubleshooting', ' consumer behaviour', 'phython', ' market data', ' redux', 'spark core', ' oracle pl / sql', ' database development', 'interpersonal skills', 'apis', ' amazon aws', 'data loader', ' dev - ops', ' prototyping', ' data science modeling', ' datawarehouse', ' qa associate', 'google tag management', ' data flow diagrams', ' mobile development', ' refrigeration', ' ssas', ' budget management', 'business services', ' web2py', ' scikit learn]', ' business intelligence tools', ' oracle designer', ' lldb', ' strategy consulting', 'ediscovery processing', ' etl tool', ' calling', 'cloud data fusion', ' reactnative', 'finance', ' hdinsight', ' sql server', ' project closure', ' test scripting', ' business enhancement', ' non functional testing', 'consulting', ' project task management', ' amazon elastic search', ' ann', ' java fs', ' manual testing', 'pmo analyst', 'composer', ' maintenance management', ' machine learning eng', ' verbal communication', ' postgresql database administration', 'kaizen', ' claims', ' multi - threading', ' middle office', 'ms - excel', 'relationship', ' dot net', ' application designing', ' decision tree learning', ' scipy', ' verbal communications', ' analytical skills', ' workflow diagrams', 'cms', ' search engine', ' query optimization', 'api', 'campaign analytics', ' record keeping', ' mongodb sql development', 'us it recruiter', ' web', ' dom', ' gcp infra', ' developer trainee', ' python coding', ' pl / sql scripting', ' elasticsearch engine', ' data scraping', ' accounting configuration', ' redshift datawarehouse', ' nlp communication', ' galue', 'azure sql dw', ' stepfunction', 'azure sql', 'c / c++', 'technology research', ' ms office tools', ' bex', ' mvc patterns', ' enterprise application integration', ' design etl pipelines', ' pega', ' vc', ' tabulation program', ' k tp', 'tam', 'rest apis', ' software development life cycle', 'tensorflow', ' flat files', ' dns', 'applied science', ' sap ewm', ' orchestration', ' aws ci / cd', ' data lakes', ' inventory', ' information', ' molecular biology', ' jsp', ' resource optimization', ' senior business analyst', 'selenium', ' indian analytics', ' proposal writing', ' mercurial', 'it services & consulting', ' kafkainput', 'sports prediction', ' power trading', ' windows workflow foundation', ' ms outlook', ' google stack reporting', ' analytical reports.', ' pl sql', 'mainframe programming', ' azure app', ' hive scripting', 'react', ' internet banking', ' sql server development', 'team lead', ' scylla', ' bi', 'project analysis', ' bulk emailing', ' web framework', ' query languages such as sql', 'toxicology', ' big data lake', ' system software development', 'mysql object oriented program', ' whitebox', ' sckit-learn', ' oracle database patching', ' pfd', ' azure events hub', 'technical training', ' synthesis', ' full-stack developer', ' ai/ml', ' web testing', ' ppts', ' techno functional', 'blended process', ' lead solution architect', ' cost accounting', 'python', ' blueprints', 'process', 'gis', ' validation', ' sas power bi', ' entity framework', ' aws ecr', ' alteryx', ' retail analytics', ' back office operations', ' bigdata sql', ' rest frameworks', ' incident response', ' s3 aws', ' microsoft data', 'process engineering', ' adms/oem', ' statistical programming', 'french', 'linkedin', 'transaction processing', ' sociology', ' investment advisory', ' microservices architecture', ' tensorflow vision', 'crm', ' axon api', ' bmc remedy', ' gcp', 'staff software engineer (full stack development - typejs/node/angular)', ' dq suite', ' koras', ' oracle data integrator', ' bi tools', ' machine learning algorithms', ' core innovation services', 'marketing strategy', 'vsam', ' reporting', ' api integration', ' supervised learning', ' tdd', ' fraud risk assessment', ' - sql', ' azure architecture', ' ms team', ' kafka rabbitmq', 'network design', ' comms', ' pricing analyst', 'mvc frameworks', ' salesforce effectiveness', ' report generation', 'storage cloud', ' dynamo db', ' cbs', 'executive leadership', ' column chromatography', 'patent drafting', ' babel', ' services', ' etl pipelines', 'my', ' django', ' core net', 'configuration management', ' gitbun ci', ' electrical engineering', 'business objects', ' test case execution', ' etl aws cloud', ' grid', 'prepayment modeling', ' global sales', 'claims', ' resource management', 'aws sagemaker', ' exploratory testing', 'google bigquery', ' talkwalker', ' report writing', 'networking', 'operational excellence', 'whitebox', ' sprint planning', ' fcm', ' vb scripting', ' vcenter', ' zabbix administration', ' side', ' biztalk', ' competitive analysis', ' sap bods', ' sketch design', 'aws glue', ' warehouse design', ' housing finance', ' capacity and availability management', ' jython', ' metagenomics', 'backup and restore', ' j2me', ' data analysis tools', ' financial products', ' biqquery', ' ahv', ' windows os', 'communication protocols', ' hubspot', ' it services', 'production support', ' mis analysis', ' data pipelines', ' server administration', ' software services', ' ruby on rails', ' web application firewall', ' c / c + +', 'spark', 'training management', 'devops', 'saas', ' sales enablement', ' accessories', ' sap hr', 'bootstrap', ' test execution', 'phoenix', ' adobe creative suite', ' language teaching', ' risk assessment', ' oracle application server', 'soft skills', ' keyword discovery', ' analog', ' agile project management', ' legal counsel', ' journal entries', 'etl', 'azure dw', ' google kubernetes', ' ms office word', ' us mortgage', ' spark rdd', ' datacenter cabling', ' sas analytics', 'metadata management', ' lan', ' six sigma green belt', ' unixlinux systems', ' scikit', ' mapping', ' effective communication skills', ' vertica', ' data flow mapping', ' financial institutions', ' microsoft power bi', ' powershell', ' resourcing', ' power', 'data analysis', ' trend analysis', ' algorithms', ' intex', ' aws analytics', ' xcode', ' hr operations', 'risk', ' component design', ' marketing communication', ' excellent communication skills', ' backend architecture', ' operations support analyst', ' supervision', ' activevos', 'j2ee', ' integration testing', ' sql scripting', ' product manager', ' project execution', 'powe bi', ' unit testing', 'power bi dashboards', ' itil', ' project documentation', ' cost controlling and analysis', ' cdn', ' azure cloud', ' ab initio etl', ' redshift aws', 'connector', ' questionnaire design', ' incident prediction model', ' benchmarking', ' circle ci', 'tsql', ' data processing executive', ' manager ii', ' google scripting', ' waste management', ' expenses', ' unix', ' iso', ' gosu scripting', ' btech', ' action plan', 'typescript', ' 9', ' power shell', ' document management', ' capital goods', ' ci / cd', 'quest', ' metabase', ' html canvas', ' legal process outsourcing', ' cloudera hadoop ecosystem', ' basel', ' resource allocation', 'api testing using soap ui', ' information gathering', ' online media', ' oracle etl', 'etl methodology', ' verint', ' channel management', ' data visualisation', 'sql - designing tables', ' native', ' wan', ' functional programming', ' aws python', 'hadoop development', ' job analysis', ' ml flows', ' vba excel', ' sql and nosql databases', 'test plan preparation', 'six sigma green belt', ' amazon kinesis', ' sales associate', ' bi analytics', 'data modeling', ' emea', ' kyc verification', ' container registry', ' deep learning model', ' spss', 'salesforce bsa', ' clm', ' bi reporting tools', 'spark sql', ' tool design', ' employee wellness', ' agile teams', ' xlsx', ' iot', ' streaming', ' maximo implementation', ' ui technologies', ' treasury', ' software quality', ' 24x7', ' informatica idq', ' financial risk', ' tech lead', ' test driven development', ' informatica 10x', ' autosys', ' brand and messages coding', 'api integration', ' core java', 'product analysis', 'operation transition', ' user administration', ' imps', 'warehouse', 'pysql', ' e-r schema modeling', 'data scientist', ' git big', 'compensation analyst', ' eda', ' data loader demand', ' flow diagrams', ' front - end', ' cloud bigtable', 'data ingestion design', 'aws redshift', ' splunk admin', ' asap', ' cplex', ' data quality services', ' quality control', ' sap businessobjects data services', ' life insurance', ' application software', ' ui / ux', ' unix shell scripts', ' .net technologies', ' sds', 'kibana', ' ca workload management', 'seo analyst', ' siemens tia portal', ' c plus plus', ' test automation framework', ' sap mm module', ' data lake gen', ' hypothesis testing', 'solution design', ' logistic regression', 'azure kubernetes', 'audacity', ' fastload', ' wireless', ' stl', ' confluent kafka', ' spoken english', ' software solution', ' sso', ' communication skills', ' lso', ' aws computing', ' fed', ' platform', ' ab initio', ' formulas', ' aws|azure| sql', ' technical documentation', ' transaction management', ' visual analytics', ' qliksense', 'consultant business analyst', ' speech synthesis', ' device driver', ' trade finance', ' e2e implementation', 'customer operations', ' autodesk', ' teradata operations', ' medical imaging', ' event engine', ' product designer', 'us healthcare', ' database architect', ' market analysis'}\n"
          ]
        }
      ],
      "source": [
        "skillset=[]\n",
        "s=[]\n",
        "for i in df[\"Skills/Description\"]:\n",
        "  x=i.lower()\n",
        "  for y in x.split(\",\"):\n",
        "    # print(x)\n",
        "    y=y.lower()\n",
        "    skillset.append(y)\n",
        "\n",
        "skillset=set(skillset)\n",
        "print(skillset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyiOg4VQCBle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec377bb-58c1-462b-8ece-9525ea65349f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "software engineer, google.com - mountain view \n",
            "this position can be based in san franci sco, ca; santa monica, ca; pittsburgh, pa; new \n",
            "york, ny or kirkland/seattle, wa. \n",
            "to apply vist: http://www.google.com/intl/en/jobs/usl ocations/mountain-view/swe/software-\n",
            "engineer-google-com-mountain-view/index.html   \n",
            " \n",
            "the area: google.com engineering \n",
            "with analytical and code-level troubleshooting abilities to spare, google.com's engineers are \n",
            "technology whizzes who love being in the center of the action. we tackle a range of complex \n",
            "software and systems issues, including m onitoring, responding to and safeguarding the \n",
            "availability of our most popular services. \n",
            "the role: software engineer, google.com \n",
            "as a software engineer working on google's crit ical production applications and infrastructure, \n",
            "your mission will be to ensure google is always fast, available, scalable and engineered to \n",
            "withstand unparalleled demand. you will be in the thick of solving the [often unexpected] \n",
            "problems of systems at scale in a way most engi neers never experience. your scope is from the \n",
            "kernel level to the continent level. this position re quires the flexibility and aptitude to zoom in to \n",
            "fine-grained detail, and the agility to zoom right back out and up the stack. delve into how \n",
            "software performs, packets flow, and hardware  and code interact, in support of managing \n",
            "services, steering global traffic a nd predicting and preventing failu res.... all in a day's work. you \n",
            "will design and develop systems to run google search, gmail, youtube, wave, maps, voice, \n",
            "appengine, and more. you'll manage, automate, a nd make data-based decisions and judgment \n",
            "calls which influence globally distributed applications. you'll own the production services which comprise *.google.com, and critical infrastructure like \n",
            "gfs, bigtable , mapreduce  and large-\n",
            "scale 'cloud computing' clusters. \n",
            "you will also be driving performance and reliabilit y from software and infrastructure at massive \n",
            "scale -- where dealing in petabytes  and gigabits and shifting by or ders of magnitude is routine. \n",
            "you will tackle challenging, novel situations every day and work with just about every other engineering and operations team at google. you will be looked upon as an expert and advocate \n",
            "to fellow engineers on making design and reliability  trade-offs in running large- scale services \n",
            "and engineering complex systems that fail gracef ully and transparently to users. the most \n",
            "successful candidates for this role will have stro ng analytical and trouble shooting skills, fluency \n",
            "in coding and systems design, solid communication skills and a desire to tackle the complex \n",
            "problems of scale which are uniqu ely google. we are particular ly interested in software \n",
            "engineers familiar with aspects of running web services at scale -- depth in either networking \n",
            "technologies and unix system calls are strong pluses.  \n",
            "responsibilities: \n",
            "• manage availability, latency, s calability and efficiency of go ogle services by engineering \n",
            "reliability into software and systems \n",
            "• respond to and resolve emergent service probl ems; write software and build automation \n",
            "to prevent problem recurrence \n",
            "• participate in service capacity planning and demand forecasting, software performance \n",
            "analysis and system tuning \n",
            "• review and influence ongoing design, architecture, standards and methods for operating \n",
            "services and systems \n",
            "requirements: \n",
            "• bs/ms in computer science or related field/degree, and/or equivalent work experience \n",
            "• fluency in one or more of: c, c++, java; and familiarity with one or more of: python, \n",
            "perl, shell, php \n",
            "• expertise in data structures, al gorithms and complexity analysis \n",
            "• expertise in analyzing an d troubleshooting large-s cale distributed systems \n",
            "• knowledge of ip networking, network analysis, performance a nd application issues using \n",
            "standard tools like tcpdump \n",
            "• ability to handle periodic oncall dut y as well as out-of-band requests \n",
            "• experience in a high-volume or critical production service envir onment is preferred \n",
            " \n"
          ]
        }
      ],
      "source": [
        "#jd all pages print\n",
        "from PyPDF2 import PdfReader\n",
        "jd=\"\"\n",
        "for page_num in range(len(reader.pages)):\n",
        "        page = reader.pages[page_num]\n",
        "        jdd = page.extract_text()\n",
        "        jd+=jdd\n",
        "        # print(f\"Page {page_num + 1}:\\n{jd}\\n\")\n",
        "jd=jd.lower()\n",
        "print(jd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lajTgCa3Nep0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8dabcd4-9ed5-4aad-83d8-3851642529d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[': \\n• BS/MS in Computer Science or related field/degree, and/or equivalent work experience \\n• Fluency in one or more of: C, C++, Java; and familiarity with one or more of: Python, \\nPerl, Shell, PHP \\n• Expertise in data structures, al gorithms and complexity analysis \\n• Expertise in analyzing an d troubleshooting large-s cale distributed systems \\n• Knowledge of IP networking, network analysis, performance a nd application issues using \\nstandard tools like tcpdump \\n• Ability to handle periodic oncall dut y as well as out-of-band requests \\n• Experience in a high-volume or critical production service envir onment is preferred'][]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "\n",
        "def create_directory(directory):\n",
        "    # Check if the directory exists, and if not, create it\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        print(f\"Directory '{directory}' created.\")\n",
        "    else:\n",
        "        print()\n",
        "\n",
        "def extract_contents_under_heading(pdf_path, heading):\n",
        "    contents = []\n",
        "\n",
        "    with open(pdf_path, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text = page.extract_text()\n",
        "\n",
        "            # Find the position of the heading\n",
        "            heading_index = text.find(heading)\n",
        "\n",
        "            # If heading is found, extract contents until the next heading\n",
        "            if heading_index != -1:\n",
        "                start_index = heading_index + len(heading)\n",
        "                end_index = text.find(\"Requirements\", start_index)  # Assuming the next heading is \"Requirements\"\n",
        "\n",
        "                # If no next heading is found, extract until the end of the document\n",
        "                if end_index == -1:\n",
        "                    end_index = len(text)\n",
        "\n",
        "                contents.append(text[start_index:end_index].strip())\n",
        "\n",
        "    return contents\n",
        "\n",
        "# Example usage\n",
        "pdf_path = \"JD.pdf\"\n",
        "heading_to_find = \"Requirements\"\n",
        "heading_to_find1 = \"Preferred qualifications\"\n",
        "output_directory = 'static/'\n",
        "\n",
        "# Create the 'static/' directory if it doesn't exist\n",
        "create_directory(output_directory)\n",
        "\n",
        "# Extract contents under the heading and save to a text file\n",
        "content = extract_contents_under_heading(pdf_path, heading_to_find)\n",
        "\n",
        "content1 = extract_contents_under_heading(pdf_path, heading_to_find1)\n",
        "jdreq1=\"\"\n",
        "jdreq2=\"\"\n",
        "# Include additional paragraph\n",
        "jdreq1=str(content)\n",
        "jdreq2=str(content1)\n",
        "jdreq=\"\"\n",
        "jdreq=jdreq1+jdreq2\n",
        "# print(type(jdreq))\n",
        "# jdreq=jdreq.lower()\n",
        "\n",
        "print(jdreq)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKz39nhIRrE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a88eb91-a1f5-4955-a20b-67c111dc9b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-grams: [('[',), (\"'\",), (':',), ('\\\\n•',), ('BS/MS',), ('in',), ('Computer',), ('Science',), ('or',), ('related',), ('field/degree',), (',',), ('and/or',), ('equivalent',), ('work',), ('experience',), ('\\\\n•',), ('Fluency',), ('in',), ('one',), ('or',), ('more',), ('of',), (':',), ('C',), (',',), ('C++',), (',',), ('Java',), (';',), ('and',), ('familiarity',), ('with',), ('one',), ('or',), ('more',), ('of',), (':',), ('Python',), (',',), ('\\\\nPerl',), (',',), ('Shell',), (',',), ('PHP',), ('\\\\n•',), ('Expertise',), ('in',), ('data',), ('structures',), (',',), ('al',), ('gorithms',), ('and',), ('complexity',), ('analysis',), ('\\\\n•',), ('Expertise',), ('in',), ('analyzing',), ('an',), ('d',), ('troubleshooting',), ('large-s',), ('cale',), ('distributed',), ('systems',), ('\\\\n•',), ('Knowledge',), ('of',), ('IP',), ('networking',), (',',), ('network',), ('analysis',), (',',), ('performance',), ('a',), ('nd',), ('application',), ('issues',), ('using',), ('\\\\nstandard',), ('tools',), ('like',), ('tcpdump',), ('\\\\n•',), ('Ability',), ('to',), ('handle',), ('periodic',), ('oncall',), ('dut',), ('y',), ('as',), ('well',), ('as',), ('out-of-band',), ('requests',), ('\\\\n•',), ('Experience',), ('in',), ('a',), ('high-volume',), ('or',), ('critical',), ('production',), ('service',), ('envir',), ('onment',), ('is',), ('preferred',), (\"'\",), (']',), ('[',), (']',)]\n",
            "2-grams (bigrams): [('[', \"'\"), (\"'\", ':'), (':', '\\\\n•'), ('\\\\n•', 'BS/MS'), ('BS/MS', 'in'), ('in', 'Computer'), ('Computer', 'Science'), ('Science', 'or'), ('or', 'related'), ('related', 'field/degree'), ('field/degree', ','), (',', 'and/or'), ('and/or', 'equivalent'), ('equivalent', 'work'), ('work', 'experience'), ('experience', '\\\\n•'), ('\\\\n•', 'Fluency'), ('Fluency', 'in'), ('in', 'one'), ('one', 'or'), ('or', 'more'), ('more', 'of'), ('of', ':'), (':', 'C'), ('C', ','), (',', 'C++'), ('C++', ','), (',', 'Java'), ('Java', ';'), (';', 'and'), ('and', 'familiarity'), ('familiarity', 'with'), ('with', 'one'), ('one', 'or'), ('or', 'more'), ('more', 'of'), ('of', ':'), (':', 'Python'), ('Python', ','), (',', '\\\\nPerl'), ('\\\\nPerl', ','), (',', 'Shell'), ('Shell', ','), (',', 'PHP'), ('PHP', '\\\\n•'), ('\\\\n•', 'Expertise'), ('Expertise', 'in'), ('in', 'data'), ('data', 'structures'), ('structures', ','), (',', 'al'), ('al', 'gorithms'), ('gorithms', 'and'), ('and', 'complexity'), ('complexity', 'analysis'), ('analysis', '\\\\n•'), ('\\\\n•', 'Expertise'), ('Expertise', 'in'), ('in', 'analyzing'), ('analyzing', 'an'), ('an', 'd'), ('d', 'troubleshooting'), ('troubleshooting', 'large-s'), ('large-s', 'cale'), ('cale', 'distributed'), ('distributed', 'systems'), ('systems', '\\\\n•'), ('\\\\n•', 'Knowledge'), ('Knowledge', 'of'), ('of', 'IP'), ('IP', 'networking'), ('networking', ','), (',', 'network'), ('network', 'analysis'), ('analysis', ','), (',', 'performance'), ('performance', 'a'), ('a', 'nd'), ('nd', 'application'), ('application', 'issues'), ('issues', 'using'), ('using', '\\\\nstandard'), ('\\\\nstandard', 'tools'), ('tools', 'like'), ('like', 'tcpdump'), ('tcpdump', '\\\\n•'), ('\\\\n•', 'Ability'), ('Ability', 'to'), ('to', 'handle'), ('handle', 'periodic'), ('periodic', 'oncall'), ('oncall', 'dut'), ('dut', 'y'), ('y', 'as'), ('as', 'well'), ('well', 'as'), ('as', 'out-of-band'), ('out-of-band', 'requests'), ('requests', '\\\\n•'), ('\\\\n•', 'Experience'), ('Experience', 'in'), ('in', 'a'), ('a', 'high-volume'), ('high-volume', 'or'), ('or', 'critical'), ('critical', 'production'), ('production', 'service'), ('service', 'envir'), ('envir', 'onment'), ('onment', 'is'), ('is', 'preferred'), ('preferred', \"'\"), (\"'\", ']'), (']', '['), ('[', ']')]\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "#n grams\n",
        "from nltk import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def generate_ngrams(text, n):\n",
        "    tokens = word_tokenize(text)\n",
        "    n_grams = list(ngrams(tokens, n))\n",
        "    return n_grams\n",
        "\n",
        "# Example usage\n",
        "\n",
        "\n",
        "# Generate 1-grams\n",
        "unigrams = generate_ngrams(jdreq, 1)\n",
        "print(\"1-grams:\", unigrams)\n",
        "\n",
        "# Generate 2-grams (bigrams)\n",
        "bigrams = generate_ngrams(jdreq, 2)\n",
        "print(\"2-grams (bigrams):\", bigrams)\n",
        "\n",
        "# Generate 3-grams (trigrams)\n",
        "\n",
        "r=[]\n",
        "for i in unigrams:\n",
        "  if i in skillset:\n",
        "    r.append(i)\n",
        "\n",
        "for i in bigrams:\n",
        "  if i in skillset:\n",
        "    r.append(i)\n",
        "\n",
        "\n",
        "print(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03GT2ltfSwzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a008f8-34a0-46c1-e5b4-fd18aac5d9d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[', \"'\", ':', '\\\\n•', 'bs/ms', 'in', 'computer', 'science', 'or', 'related', 'field/degree', ',', 'and/or', 'equivalent', 'work', 'experience', '\\\\n•', 'fluency', 'in', 'one', 'or', 'more', 'of', ':', 'c', ',', 'c++', ',', 'java', ';', 'and', 'familiarity', 'with', 'one', 'or', 'more', 'of', ':', 'python', ',', '\\\\nperl', ',', 'shell', ',', 'php', '\\\\n•', 'expertise', 'in', 'data', 'structures', ',', 'al', 'gorithms', 'and', 'complexity', 'analysis', '\\\\n•', 'expertise', 'in', 'analyzing', 'an', 'd', 'troubleshooting', 'large-s', 'cale', 'distributed', 'systems', '\\\\n•', 'knowledge', 'of', 'ip', 'networking', ',', 'network', 'analysis', ',', 'performance', 'a', 'nd', 'application', 'issues', 'using', '\\\\nstandard', 'tools', 'like', 'tcpdump', '\\\\n•', 'ability', 'to', 'handle', 'periodic', 'oncall', 'dut', 'y', 'as', 'well', 'as', 'out-of-band', 'requests', '\\\\n•', 'experience', 'in', 'a', 'high-volume', 'or', 'critical', 'production', 'service', 'envir', 'onment', 'is', 'preferred', \"'\", ']', '[', ']', \"[ '\", \"' :\", ': \\\\n•', '\\\\n• bs/ms', 'bs/ms in', 'in computer', 'computer science', 'science or', 'or related', 'related field/degree', 'field/degree ,', ', and/or', 'and/or equivalent', 'equivalent work', 'work experience', 'experience \\\\n•', '\\\\n• fluency', 'fluency in', 'in one', 'one or', 'or more', 'more of', 'of :', ': c', 'c ,', ', c++', 'c++ ,', ', java', 'java ;', '; and', 'and familiarity', 'familiarity with', 'with one', 'one or', 'or more', 'more of', 'of :', ': python', 'python ,', ', \\\\nperl', '\\\\nperl ,', ', shell', 'shell ,', ', php', 'php \\\\n•', '\\\\n• expertise', 'expertise in', 'in data', 'data structures', 'structures ,', ', al', 'al gorithms', 'gorithms and', 'and complexity', 'complexity analysis', 'analysis \\\\n•', '\\\\n• expertise', 'expertise in', 'in analyzing', 'analyzing an', 'an d', 'd troubleshooting', 'troubleshooting large-s', 'large-s cale', 'cale distributed', 'distributed systems', 'systems \\\\n•', '\\\\n• knowledge', 'knowledge of', 'of ip', 'ip networking', 'networking ,', ', network', 'network analysis', 'analysis ,', ', performance', 'performance a', 'a nd', 'nd application', 'application issues', 'issues using', 'using \\\\nstandard', '\\\\nstandard tools', 'tools like', 'like tcpdump', 'tcpdump \\\\n•', '\\\\n• ability', 'ability to', 'to handle', 'handle periodic', 'periodic oncall', 'oncall dut', 'dut y', 'y as', 'as well', 'well as', 'as out-of-band', 'out-of-band requests', 'requests \\\\n•', '\\\\n• experience', 'experience in', 'in a', 'a high-volume', 'high-volume or', 'or critical', 'critical production', 'production service', 'service envir', 'envir onment', 'onment is', 'is preferred', \"preferred '\", \"' ]\", '] [', '[ ]']\n"
          ]
        }
      ],
      "source": [
        "from nltk import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def generate_ngrams(text, n):\n",
        "    tokens = word_tokenize(text)\n",
        "    n_grams = list(ngrams(tokens, n))\n",
        "    return n_grams\n",
        "\n",
        "def generate_all_strings(ngrams_list):\n",
        "    all_strings = []\n",
        "    for ngrams in ngrams_list:\n",
        "        current_strings = [' '.join(gram) for gram in ngrams]\n",
        "        all_strings.extend(current_strings)\n",
        "    return all_strings\n",
        "\n",
        "# Example usage\n",
        "# input_text = \"This is an example sentence for n-gram generation.\"\n",
        "\n",
        "# Generate 1-grams, 2-grams (bigrams), and 3-grams (trigrams)\n",
        "unigrams = generate_ngrams(jdreq, 1)\n",
        "bigrams = generate_ngrams(jdreq, 2)\n",
        "# trigrams = generate_ngrams(jdreq, 3)\n",
        "\n",
        "# Generate all possible strings\n",
        "all_strings = generate_all_strings([unigrams, bigrams])\n",
        "l1=str(all_strings)\n",
        "\n",
        "l1=l1.lower()\n",
        "# print(l1)\n",
        "for string in l1.split(\"\\n\"):\n",
        "  print(string)\n",
        "\n",
        "  if string in skillset:\n",
        "      print(string)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ewzaSm4TPD-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33044597-3e69-4395-bece-4f455d344040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'c++', 'data structures', 'analysis', 'python', 'computer science', 'java', 'troubleshooting', 'c', 'performance', 'data', 'networking', 'distributed systems'}\n"
          ]
        }
      ],
      "source": [
        "from nltk import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def generate_ngrams(text, n):\n",
        "    tokens = word_tokenize(text)\n",
        "    n_grams = list(ngrams(tokens, n))\n",
        "    return n_grams\n",
        "\n",
        "def generate_all_strings(ngrams_list):\n",
        "    all_strings = []\n",
        "    for ngrams in ngrams_list:\n",
        "        current_strings = [' '.join(gram) for gram in ngrams]\n",
        "        all_strings.extend(current_strings)\n",
        "    return all_strings\n",
        "\n",
        "# # Example usage\n",
        "# jdreq = \"This is a sample job description requirement.\"\n",
        "# skillset = {\"sample\", \"experience\", \"requirement\"}\n",
        "\n",
        "# Convert jdreq to lowercase\n",
        "jdreq = jdreq.lower()\n",
        "\n",
        "# Generate 1-grams and 2-grams (bigrams)\n",
        "unigrams = generate_ngrams(jdreq, 1)\n",
        "bigrams = generate_ngrams(jdreq, 2)\n",
        "\n",
        "# Generate all possible strings\n",
        "all_strings = generate_all_strings([unigrams, bigrams])\n",
        "# print(all_strings)\n",
        "jdskill=[]\n",
        "# Print the generated strings\n",
        "for string in all_strings:\n",
        "    # print(string)\n",
        "\n",
        "    if string in skillset:\n",
        "        # print(string)\n",
        "        jdskill.append(string)\n",
        "print(set(jdskill))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S5YrPFNZ-6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193b9a3d-f921-4961-a655-c5b3bed48982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'finance', 'programming', 'fundamentals', 'development', 'css', 'github', 'end-to-end', 'cloud', 'ui', 'api', 'backend', 'microservices', 'python', 'risk', 'nlp', 'learning', 'deployment', 'react', 'aws', 'flask', 'the', 'ci/cd', 'analysis', 'ml', 'data', 'engineering'}\n"
          ]
        }
      ],
      "source": [
        "x11=x11.lower()\n",
        "# print(x11)\n",
        "resumeskill=[]\n",
        "for i in x11.split(\" \"):\n",
        "  # print(i)\n",
        "  if i in skillset:\n",
        "    resumeskill.append(i)\n",
        "\n",
        "print(set(resumeskill))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkqpW5WNaS-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "092dc2af-ee4b-448f-dc1b-91efec67f326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['c', 'c++', 'java', 'python', 'data', 'analysis', 'troubleshooting', 'networking', 'analysis', 'performance', 'computer science', 'data structures', 'distributed systems']\n",
            "{'c++', 'data structures', 'computer science', 'java', 'troubleshooting', 'c', 'performance', 'networking', 'distributed systems'}\n"
          ]
        }
      ],
      "source": [
        "notavail=[]\n",
        "print(jdskill)\n",
        "for i in jdskill:\n",
        "  if i not in resumeskill:\n",
        "    notavail.append(i)\n",
        "notavail=set(notavail)\n",
        "# print(notavail)\n",
        "if 'r' in notavail:\n",
        "  notavail.remove('r')\n",
        "print(notavail)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gr98yB8uKfWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986b4b92-4190-4d69-f78d-063ee56bee40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data', 'analysis', 'python'}\n"
          ]
        }
      ],
      "source": [
        "avail=[]\n",
        "# print(jdskill)\n",
        "for i in jdskill:\n",
        "  if i  in resumeskill:\n",
        "    avail.append(i)\n",
        "avail=set(avail)\n",
        "# print(notavail)\n",
        "if 'r' in avail:\n",
        "  avail.remove('r')\n",
        "print(avail)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UmhQMprkd0r"
      },
      "outputs": [],
      "source": [
        "edf=pd.read_csv(r\"/content/EdX.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP40gjjBm6qt"
      },
      "source": [
        "**Course Recommendation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9q9gyz0nj0NT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b55dde2-b12a-4ab6-f545-757bc3f81136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data structures   python data structures\n",
            "Corresponding Link: https://www.edx.org/course/python-data-structures\n",
            "computer science   cs50's introduction to computer science\n",
            "Corresponding Link: https://www.edx.org/course/cs50s-introduction-to-computer-science\n",
            "java   cs50's web programming with python and javascript\n",
            "Corresponding Link: https://www.edx.org/course/cs50s-web-programming-with-python-and-javascript\n",
            "c   cs50's introduction to computer science\n",
            "Corresponding Link: https://www.edx.org/course/cs50s-introduction-to-computer-science\n",
            "networking   using email for networking in english\n",
            "Corresponding Link: https://www.edx.org/course/using-email-for-networking-in-english\n"
          ]
        }
      ],
      "source": [
        "if matchpercentage<40:\n",
        "  for i in notavail:\n",
        "    # print(i)\n",
        "    for idx, x in enumerate(edf[\"Course\"]):\n",
        "      x=str(x).lower()\n",
        "      if str(i) in str(x):\n",
        "        print(i,\" \",x)\n",
        "        matching_link = edf[\"Link\"].iloc[idx]\n",
        "        # print(f\"Matched Course: {x}\")\n",
        "        print(f\"Corresponding Link: {matching_link}\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "622gRbaWJQx7"
      },
      "outputs": [],
      "source": [
        "if matchpercentage>=40:\n",
        "  for i in avail:\n",
        "    for idx, x in enumerate(edf[\"Course\"]):\n",
        "        x = str(x).lower()\n",
        "        difficulty_level = edf[\"Difficulty Level\"].iloc[idx].lower()  # Assuming 'Difficulty' is the column name\n",
        "        if str(i) in x and difficulty_level in ['intermediate', 'advanced']:\n",
        "            print(i, \" \", x)\n",
        "            matching_link = edf[\"Link\"].iloc[idx]\n",
        "            difficulty = edf[\"Difficulty Level\"].iloc[idx]\n",
        "            print(f\"Corresponding Link: {matching_link}\")\n",
        "            print(f\"Difficulty Level: {difficulty}\")\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItaA85ezoieV"
      },
      "source": [
        "Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    sentiment_analyzer = pipeline('sentiment-analysis', model='nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "    result = sentiment_analyzer(text)\n",
        "    return result[0]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    i = '''EXPERIENCE\n",
        "\n",
        "\n",
        "•Worked on Smart Labs India Assistant Project, a generative AI , based chat-bot that helps employees to get quick response on\n",
        "documents related to SAP\n",
        "•Built a website that follows the Model-View-Controller (MVC) model, utilizing HanaDB ,Flask server in the back-end, and UI5\n",
        "for front-end for department admins to add documents to retrieve data from them.\n",
        "•Integrated the chat-bot with OpenAI’s Large Language Model to understand the documents and generate answers from the\n",
        "documents.\n",
        "•Successfully was able to answer Percentage: 90% ; of the queries within 10 seconds and also successfully scrapped 4 lakh of blogs\n",
        "in 2 hours .\n",
        "PROJECTS\n",
        "\n",
        "•Techie Corner,is a full stack application is a student management portal for students to view their performance and also enables them to\n",
        "pay all college related fees.\n",
        "•Developed a responsive website applying the Model-View-Controller (MVC) architecture, leveraging MongoDB for database\n",
        "management, Node.js server for back-end operations, and React for seamless user experiences\n",
        "•Implemented a reliable authentication andauthorization system that utilizes JWT implementations, along with cookies and sessions\n",
        "•Led a team of 5 and practised Agile methodology with proper sprint planning, daily scrums, scrum reviews.\n",
        "\n",
        "•Apython project, for students to check their document for plagiarism with other students and paraphrase it if plagiarism score is greater\n",
        "than 0.5 to reduce the score. Teachers can further read the summary of the document with this application.\n",
        "•Employed Flask for processing the data, and performing plagiarism, paraphrasing and summarizing text and integrated with front end.\n",
        "•Performed plagiarism check accurately for Percentage: 60% ; of the documents\n",
        "\n",
        "•Amachine learning and a data science project that is can be utilized to find the possibility of a server hack with various parameters like\n",
        "password length, special character count, time etc.\n",
        "•Integrated various machine learning algorithms like KNN, SVM, random forest etc.\n",
        "•Pre processed, normalized and cleaned the data and also analysed the data with various graphs using matplotlib library.\n",
        "•Classified about Percentage: 80%  of data and predicted accurately.\n",
        "\n",
        "\n",
        "•Created a responsive and accessible website for club.\n",
        "•Conducted various workshops on topics like DSA, Web Development.'''\n",
        "\n",
        "\n",
        "    i1=\"This product is okay, but there are some issues that need improvement.\"\n",
        "\n",
        "    sentiment_result = analyze_sentiment(i)\n",
        "\n",
        "    print(f\"Sentiment: {sentiment_result['label']} \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKNek2qq7Qq-",
        "outputId": "f8a21cff-dba0-4058-f424-96f177052454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: 5 stars \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the sentiment analysis pipeline\n",
        "sentiment_analyzer = pipeline('sentiment-analysis')\n",
        "\n",
        "# Example text\n",
        "abx = '''Techie Corner |MERN stack GitHub\n",
        "•Engineered an integrated university portal enabling 10k+ students to access academics, payments and learning through a MERN and\n",
        "Flask application.\n",
        "•Reduced login failures by 30 % implementing JWT authorization, enhancing student experience and security.\n",
        "•Integrated Stripe API to enable seamless fee payments including tuition, bus and housing.\n",
        "•Created a React quiz portal with Flask backend enabling real-time sync of test scores to student dashboards\n",
        "•Built a simple text editor to download notes as .txt files and customized UI components using React libraries\n",
        "Consumer Review Analyser |Machine Learning GitHub\n",
        "•Developed an XGBoost model predicting consumer dispute risk using 400,000+ real complaint records.\n",
        "•Improved dispute prediction accuracy by 5% over baseline through rigorous EDA, algorithm selection and hyperparameter tuning.\n",
        "•Constructed an end-to-end ML pipeline enabling seamless batch and real-time predictions on new complaints.\n",
        "•Operationalized model inferences to provide actionable dispute risk forecasts for consumer finance complaints.\n",
        "Text Analyser |NLP , Python , Flask GitHub\n",
        "•Created a modular web application enabling plagiarism detection, text summarization, paraphrasing and grammar correction.\n",
        "•Combined rule-based techniques and ML models like TextRank and BERT to ensure over 90% accuracy across NLP tasks.\n",
        "•Designed an intuitive UI for users to seamlessly access multiple text analysis features through one platform.\n",
        "•Operationalized NLP microservices for plagiarism checking, summarization and paraphrasing using Python, NLTK and TensorFlow.\n",
        "Wizarts - Art Display Webpage |HTML, CSS, Github Pages GitHub Link\n",
        "•Designed an art gallery web app showcasing artwork from 50+ amateur artists using HTML, CSS and JavaScript.\n",
        "•Led development of responsive UI and core pages ensuring smooth user experience.\n",
        "•Managed CI/CD pipelines and GitHub Pages deployment for rapid iterations and collaboration.\n",
        "CO-CURRICULAR\n",
        "Computer Society of India Feb. 2023 – Present\n",
        "President Bengaluru\n",
        "Kala - The art club June 2022 – August 2022\n",
        "Executive Bengaluru'''\n",
        "\n",
        "# Perform sentiment analysis\n",
        "result = sentiment_analyzer(abx)\n",
        "\n",
        "# Print the result\n",
        "print(result[0][\"label\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWPGNOiDWxbC",
        "outputId": "c46093f2-ce83-4f22-9810-0fbbb1756e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POSITIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def vec(text1,text2):\n",
        "  tokens1 = text1.split()\n",
        "  tokens2 = text2.split()\n",
        "\n",
        "  # Train Word2Vec model\n",
        "  model = Word2Vec([tokens1, tokens2], vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "  # Vectorize the texts\n",
        "  vector1 = sum(model.wv[word] for word in tokens1) / len(tokens1)\n",
        "  vector2 = sum(model.wv[word] for word in tokens2) / len(tokens2)\n",
        "\n",
        "  # Print the similarity\n",
        "  similarity = cosine_similarity([vector1], [vector2])[0][0]\n",
        "  return similarity\n",
        "# Tokenize and remove stop words\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word.lower() for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
        "    return filtered_tokens\n",
        "\n",
        "\n",
        "# Set the path to the folder containing PDF files\n",
        "folder_path = '/content/rank'\n",
        "\n",
        "# Constant text (job in your example)\n",
        "constant_text = job\n",
        "\n",
        "# Tokenize and vectorize constant text\n",
        "constant_tokens = preprocess_text(constant_text)\n",
        "vectorized_constant = vectorize_text(constant_tokens, model)\n",
        "\n",
        "# List to store combined similarity scores\n",
        "combined_similarity_scores = []\n",
        "t2=preprocess_text(job)\n",
        "t2 = ', '.join(t2)\n",
        "# Iterate through PDF files in the folder\n",
        "for filename in tqdm(os.listdir(folder_path)):\n",
        "    if filename.endswith('.pdf'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        resume_text = extract_text_from_pdf(file_path)\n",
        "        t1=preprocess_text(resume_text)\n",
        "        t1 = ', '.join(t1)\n",
        "        similarity_word2vec = vec(t1,t2)\n",
        "        similarity_word2vec=(similarity_word2vec + 1) / 2 * 100\n",
        "\n",
        "        # Calculate CountVectorizer similarity\n",
        "\n",
        "        similarity_countvectorizer =  score_resume(resume_text, skill_scores)\n",
        "\n",
        "        avg_similarity = (similarity_word2vec + similarity_countvectorizer) / 2\n",
        "        combined_similarity_scores.append((filename, avg_similarity))\n",
        "\n",
        "# Sort the combined similarity scores in descending order\n",
        "combined_similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Display the combined similarity scores\n",
        "for filename, normalized_score in combined_similarity_scores:\n",
        "    print(f\"{filename}: {normalized_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9bmSaGEjDGP",
        "outputId": "aeeae017-6141-496f-ea48-3be852715eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/122 [00:00<?, ?it/s]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            "  1%|          | 1/122 [00:01<02:25,  1.21s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            "  2%|▏         | 2/122 [00:03<04:01,  2.01s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            "  2%|▏         | 3/122 [00:05<03:37,  1.83s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            "  3%|▎         | 4/122 [00:06<03:08,  1.59s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            "  4%|▍         | 5/122 [00:08<03:34,  1.83s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            "  5%|▍         | 6/122 [00:10<03:37,  1.87s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            "  6%|▌         | 7/122 [00:13<04:23,  2.29s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            "  7%|▋         | 8/122 [00:15<03:46,  1.99s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            "  7%|▋         | 9/122 [00:18<04:41,  2.50s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            "  8%|▊         | 10/122 [00:20<04:04,  2.18s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            "  9%|▉         | 11/122 [00:21<03:27,  1.87s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 10%|▉         | 12/122 [00:23<03:35,  1.96s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 11%|█         | 13/122 [00:25<03:15,  1.79s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 11%|█▏        | 14/122 [00:26<02:54,  1.61s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 12%|█▏        | 15/122 [00:27<02:39,  1.49s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 13%|█▎        | 16/122 [00:30<03:35,  2.03s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 14%|█▍        | 17/122 [00:32<03:29,  1.99s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 15%|█▍        | 18/122 [00:33<03:01,  1.75s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 16%|█▌        | 19/122 [00:35<02:40,  1.56s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 16%|█▋        | 20/122 [00:36<02:26,  1.43s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 17%|█▋        | 21/122 [00:37<02:17,  1.36s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 18%|█▊        | 22/122 [00:38<02:10,  1.30s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 19%|█▉        | 23/122 [00:39<02:05,  1.27s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 20%|█▉        | 24/122 [00:41<02:17,  1.41s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 20%|██        | 25/122 [00:45<03:25,  2.12s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 21%|██▏       | 26/122 [00:46<03:02,  1.90s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 22%|██▏       | 27/122 [00:47<02:41,  1.70s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 23%|██▎       | 28/122 [00:49<02:40,  1.71s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 24%|██▍       | 29/122 [00:52<03:05,  2.00s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 25%|██▍       | 30/122 [00:53<02:40,  1.75s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 25%|██▌       | 31/122 [00:54<02:22,  1.57s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 26%|██▌       | 32/122 [00:58<03:33,  2.37s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 27%|██▋       | 33/122 [01:00<03:05,  2.08s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 28%|██▊       | 34/122 [01:01<02:40,  1.83s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 29%|██▊       | 35/122 [01:02<02:23,  1.65s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 30%|██▉       | 36/122 [01:03<02:11,  1.53s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 30%|███       | 37/122 [01:05<02:16,  1.60s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 31%|███       | 38/122 [01:07<02:06,  1.51s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 32%|███▏      | 39/122 [01:08<01:59,  1.44s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 33%|███▎      | 40/122 [01:09<01:57,  1.44s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 34%|███▎      | 41/122 [01:14<03:08,  2.33s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 34%|███▍      | 42/122 [01:16<03:08,  2.36s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 35%|███▌      | 43/122 [01:17<02:39,  2.02s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 36%|███▌      | 44/122 [01:18<02:18,  1.77s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 37%|███▋      | 45/122 [01:21<02:37,  2.05s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 38%|███▊      | 46/122 [01:23<02:34,  2.04s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 39%|███▊      | 47/122 [01:27<03:02,  2.43s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 39%|███▉      | 48/122 [01:28<02:34,  2.09s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 40%|████      | 49/122 [01:30<02:44,  2.25s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 41%|████      | 50/122 [01:32<02:21,  1.97s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 42%|████▏     | 51/122 [01:35<02:37,  2.21s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 43%|████▎     | 52/122 [01:39<03:31,  3.02s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 43%|████▎     | 53/122 [01:42<03:16,  2.84s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 44%|████▍     | 54/122 [01:43<02:39,  2.34s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 45%|████▌     | 55/122 [01:44<02:14,  2.01s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 46%|████▌     | 56/122 [01:45<01:55,  1.75s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 47%|████▋     | 57/122 [01:48<02:03,  1.90s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 48%|████▊     | 58/122 [01:49<01:48,  1.70s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 48%|████▊     | 59/122 [01:51<01:49,  1.73s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 49%|████▉     | 60/122 [01:53<01:52,  1.81s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 50%|█████     | 61/122 [01:54<01:37,  1.60s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 51%|█████     | 62/122 [01:55<01:28,  1.48s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 52%|█████▏    | 63/122 [01:56<01:24,  1.43s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 52%|█████▏    | 64/122 [01:58<01:28,  1.53s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 53%|█████▎    | 65/122 [01:59<01:22,  1.44s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 54%|█████▍    | 66/122 [02:00<01:15,  1.35s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 55%|█████▍    | 67/122 [02:02<01:12,  1.32s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 56%|█████▌    | 68/122 [02:03<01:12,  1.34s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 57%|█████▋    | 69/122 [02:05<01:24,  1.60s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 57%|█████▋    | 70/122 [02:07<01:22,  1.59s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 58%|█████▊    | 71/122 [02:08<01:15,  1.49s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 59%|█████▉    | 72/122 [02:12<01:53,  2.26s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 60%|█████▉    | 73/122 [02:15<02:02,  2.50s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 61%|██████    | 74/122 [02:17<01:42,  2.14s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 61%|██████▏   | 75/122 [02:21<02:07,  2.72s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 62%|██████▏   | 76/122 [02:24<02:11,  2.85s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 63%|██████▎   | 77/122 [02:25<01:46,  2.37s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 64%|██████▍   | 78/122 [02:26<01:29,  2.04s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 65%|██████▍   | 79/122 [02:29<01:41,  2.35s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 66%|██████▌   | 80/122 [02:31<01:30,  2.16s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 66%|██████▋   | 81/122 [02:35<01:50,  2.70s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 67%|██████▋   | 82/122 [02:38<01:45,  2.63s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 68%|██████▊   | 83/122 [02:40<01:40,  2.58s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 69%|██████▉   | 84/122 [02:41<01:23,  2.21s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 70%|██████▉   | 85/122 [02:43<01:11,  1.92s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 70%|███████   | 86/122 [02:45<01:12,  2.01s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 71%|███████▏  | 87/122 [02:47<01:12,  2.07s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 72%|███████▏  | 88/122 [02:48<01:00,  1.79s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 73%|███████▎  | 89/122 [02:49<00:53,  1.61s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 74%|███████▍  | 90/122 [02:51<00:47,  1.48s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 75%|███████▍  | 91/122 [02:52<00:43,  1.42s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 75%|███████▌  | 92/122 [02:53<00:44,  1.50s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 76%|███████▌  | 93/122 [02:55<00:41,  1.42s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 77%|███████▋  | 94/122 [02:56<00:37,  1.35s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 78%|███████▊  | 95/122 [02:59<00:53,  1.99s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 80%|███████▉  | 97/122 [03:01<00:36,  1.46s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 80%|████████  | 98/122 [03:04<00:44,  1.85s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 81%|████████  | 99/122 [03:05<00:39,  1.72s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 82%|████████▏ | 100/122 [03:07<00:35,  1.62s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 83%|████████▎ | 101/122 [03:08<00:31,  1.49s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 84%|████████▎ | 102/122 [03:09<00:28,  1.42s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 84%|████████▍ | 103/122 [03:14<00:43,  2.30s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 86%|████████▌ | 105/122 [03:16<00:30,  1.80s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 87%|████████▋ | 106/122 [03:17<00:27,  1.71s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 88%|████████▊ | 107/122 [03:19<00:23,  1.57s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 89%|████████▊ | 108/122 [03:20<00:20,  1.49s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 89%|████████▉ | 109/122 [03:21<00:18,  1.41s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 90%|█████████ | 110/122 [03:22<00:16,  1.37s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 91%|█████████ | 111/122 [03:27<00:24,  2.26s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 92%|█████████▏| 112/122 [03:30<00:25,  2.58s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 93%|█████████▎| 113/122 [03:32<00:20,  2.29s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 93%|█████████▎| 114/122 [03:33<00:16,  2.02s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 94%|█████████▍| 115/122 [03:35<00:14,  2.11s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 95%|█████████▌| 116/122 [03:37<00:10,  1.83s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 96%|█████████▌| 117/122 [03:41<00:12,  2.51s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 97%|█████████▋| 118/122 [03:43<00:10,  2.55s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 98%|█████████▊| 119/122 [03:45<00:06,  2.20s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 98%|█████████▊| 120/122 [03:47<00:04,  2.25s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            " 99%|█████████▉| 121/122 [03:48<00:01,  1.94s/it]<ipython-input-109-6d2f9a300925>:85: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = doc.similarity(phrase_doc)\n",
            "100%|██████████| 122/122 [03:50<00:00,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vishnu Vijai_BL.EN.U4CSE19146.pdf: 42.11\n",
            "Lekkala Naveen Kumar Reddy_BL.EN.U4CSE19077.pdf: 42.01\n",
            "Yennam Sasidhar Reddy_BL.EN.U4CSE19153.pdf: 40.48\n",
            "Renjith Ravi_BL.EN.U4MEE19038.pdf: 37.96\n",
            "Ganugapati Sri Sai Vignesh_BL.EN.U4CSE19044.pdf: 37.41\n",
            "Kopella Gopi Venkata Manoj Kumar_BL.EN.U4CSE19071.pdf: 35.65\n",
            "Toram Venkata Lalith Vinay_BL.EN.U4MEE19054.pdf: 35.54\n",
            "Sairi Rithvik_BL.EN.U4CSE19118.pdf: 34.96\n",
            "Hari Srinivas Kothuri_BL.EN.U4CSE19054.pdf: 34.94\n",
            "Ganti Surya Sai Ashwin_BL.EN.U4CSE19043.pdf: 34.91\n",
            "Keerthana S_BL.EN.U4AIE19029.pdf: 34.82\n",
            "Ravi Naga Yaswanth_BL.EN.U4CSE19112.pdf: 34.63\n",
            "Kommalapati Nikhilesh Datha_BL.EN.U4CSE19069.pdf: 34.58\n",
            "Tadi Praveen Reddy_BL.EN.U4MEE19050.pdf: 34.51\n",
            "Vuppada Abhishek_BL.EN.U4MEE19061.pdf: 34.46\n",
            "Kovvuri Vinay Kamalnath Reddy_BL.EN.U4CSE19074.pdf: 34.46\n",
            "Sunkavilli Prathyusha_BL.EN.U4CSE19128.pdf: 34.30\n",
            "Puvvadi Rama Sai Yaswanth Kumar_BL.EN.U4CSE19111.pdf: 34.26\n",
            "Prateek Prabodh Upadhya_BL.EN.U4CSE19109.pdf: 34.23\n",
            "Pasumarthy Venkata Akhil_BL.EN.U4AIE19049.pdf: 34.12\n",
            "Sathian M_BL.EN.U4CSE19120.pdf: 34.08\n",
            "Yalamanchili Harischandra_BL.EN.U4MEE19062.pdf: 34.05\n",
            "Polasam Navya Sree_BL.EN.U4MEE19035.pdf: 34.04\n",
            "Pajjuru Hemanth_BL.EN.U4CSE19100.pdf: 34.02\n",
            "Maroju Jaya Venkata Sai Neel Charan_BL.EN.U4MEE19025.pdf: 33.68\n",
            "Vishnu V M_BL.EN.U4MEE19060.pdf: 33.66\n",
            "Machireddy Abhinag Reddy_BL.EN.U4MEE19016.pdf: 33.65\n",
            "Kanamarlapudi P V Pavan Kumar_BL.EN.U4MEE19014.pdf: 33.62\n",
            "Kolanupaka Anirudh_BL.EN.U4CSE19068.pdf: 33.61\n",
            "Suriya K S_BL.EN.U4CSE19129.pdf: 33.59\n",
            "Nagulapati Kavya Reddy_BL.EN.U4CSE19091.pdf: 33.59\n",
            "Revilla Yaswitha_BL.EN.U4CSE19114.pdf: 33.51\n",
            "Marthala Mallika Reddy_BL.EN.U4CSE19085.pdf: 33.49\n",
            "Sree Ram Kommula_BL.EN.U4CSE19126.pdf: 33.44\n",
            "Gogineni Bala Nagendra Babu_BL.EN.U4CSE19046.pdf: 33.38\n",
            "Marthala Venkata Sreekanth Reddy_BL.EN.U4CSE19086.pdf: 33.38\n",
            "Mourya Viswanadh Kalidindi_BL.EN.U4CSE19087.pdf: 33.37\n",
            "Mukkamala Shanmukha Srinivasa Sai_BL.EN.U4CSE19089.pdf: 33.31\n",
            "Malapati Girish Reddy_BL.EN.U4CSE19080.pdf: 33.21\n",
            "Sai Sri Mohan Datta Bayya_BL.EN.U4CSE19117.pdf: 33.21\n",
            "Lavanya Ratna Sirisha Munduri_BL.EN.U4CSE19076.pdf: 33.07\n",
            "Mandalapu Revanth Sai_BL.EN.U4CSE19082.pdf: 32.97\n",
            "Karan Singh Bagga_BL.EN.U4CSE19062.pdf: 32.95\n",
            "Maddirevula Dheeraj Kumar Reddy_BL.EN.U4CSE19079.pdf: 32.92\n",
            "Rohith T_BL.EN.U4AIE19064.pdf: 32.87\n",
            "Vunnam Rishitha_BL.EN.U4CSE19148.pdf: 32.84\n",
            "K Chaitanya Vadiraj_BL.EN.U4CSE19058.pdf: 32.82\n",
            "Madhur Ramachandruni_BL.EN.U4MEE19018.pdf: 32.70\n",
            "Mohammed Bilal K_BL.EN.U4MEE19028.pdf: 32.68\n",
            "Vinamratha Pattar_BL.EN.U4CSE19145.pdf: 32.50\n",
            "Sahil Singh_BL.EN.U4MEE19041.pdf: 32.48\n",
            "Kallem Anudeep Reddy_BL.EN.U4MEE19013.pdf: 32.44\n",
            "Narapureddy Sanjaya Pavan Kumar Reddy_BL.EN.U4CSE19094.pdf: 32.40\n",
            "Nallani Naveen Kumar_BL.EN.U4CSE19093.pdf: 32.36\n",
            "Tanmay Gupta_BL.EN.U4MEE19052.pdf: 32.33\n",
            "Jupelly Vishnuvardhan Rao_BL.EN.U4MEE19010.pdf: 32.31\n",
            "Sidharth Nair_BL.EN.U4MEE19044.pdf: 32.30\n",
            "Yeddula Bharath Kumar_BL.EN.U4CSE19150.pdf: 32.28\n",
            "Sikhakolanu Sambasiva Sai Venkatesh_BL.EN.U4CSE19123.pdf: 32.24\n",
            "Kodadala Charan Kumar Reddy_BL.EN.U4CSE19066.pdf: 32.23\n",
            "Vedant Pramod Naik_BL.EN.U4CSE19141.pdf: 32.21\n",
            "Marisetti Surya Teja_BL.EN.U4CSE19083.pdf: 32.17\n",
            "Doddapaneni Tanmayi_BL.EN.U4CSE19035.pdf: 32.12\n",
            "Gogineni Meghana Chowdary_BL.EN.U4CSE19047.pdf: 31.91\n",
            "B S Shatya Pramod_BL.EN.U4MEE19003.pdf: 31.91\n",
            "Vellanki Mukesh_BL.EN.U4CSE19143.pdf: 31.91\n",
            "Sathi Ravi Shankar Reddy_BL.EN.U4CSE19119.pdf: 31.82\n",
            "Preethi Reddy Mudireddy_BL.EN.U4CSE19110.pdf: 31.76\n",
            "Pottimuthi Praneeth_BL.EN.U4CSE19106.pdf: 31.75\n",
            "Gudibandi Hema Naga Sai_BL.EN.U4CSE19049.pdf: 31.74\n",
            "Duggireddy Dharanidhara Reddy_BL.EN.U4MEE19006.pdf: 31.69\n",
            "Naveen Balaji K P_BL.EN.U4CSE19095.pdf: 31.48\n",
            "Vasanth S_BL.EN.U4CSE19139.pdf: 31.44\n",
            "Oruganti Naga Lakshmi Lalasa_BL.EN.U4CSE19097.pdf: 31.38\n",
            "Kodati Kasi Viswas_BL.EN.U4CSE19067.pdf: 31.36\n",
            "V Ganith_BL.EN.U4CSE19134.pdf: 31.30\n",
            "Devarapalli Vamsi Krishna Reddy_BL.EN.U4MEE19004.pdf: 31.29\n",
            "Katta Aditya Rohith_BL.EN.U4CSE19064.pdf: 31.28\n",
            "Guntuka Sravani Reddy_BL.EN.U4CSE19052.pdf: 31.28\n",
            "Mukku Sathya Sai Krishna_BL.EN.U4MEE19030.pdf: 31.26\n",
            "Revant Reddy Dondeti_BL.EN.U4CSE19113.pdf: 31.22\n",
            "Josyula VMS Suryanarayana Kapardhi_BL.EN.U4CSE19056.pdf: 31.20\n",
            "Kishan Maniyar_BL.EN.U4CSE19065.pdf: 31.16\n",
            "Kedarisetty Vishnu Sainadh_BL.EN.U4AIE19028.pdf: 31.08\n",
            "Polireddi Venkata Sampat_BL.EN.U4CSE19105.pdf: 31.06\n",
            "Manjunath Sakthivel_BL.EN.U4MEE19023.pdf: 31.01\n",
            "M Sri Charan_BL.EN.U4CSE19078.pdf: 30.95\n",
            "Kadiyala Raj Kumar_BL.EN.U4CSE19060.pdf: 30.85\n",
            "G Sai Pavan_BL.EN.U4CSE19041.pdf: 30.84\n",
            "Madireddy Balasubrahmanyam_BL.EN.U4MEE19019.pdf: 30.83\n",
            "Subrahmanya B A_BL.EN.U4CSE19127.pdf: 30.54\n",
            "V R S Vishal Matcha_BL.EN.U4CSE19135.pdf: 30.52\n",
            "Yeguvapalli Hruthik Sai_BL.EN.U4CSE19152.pdf: 30.52\n",
            "Jutur Manogna_BL.EN.U4CSE19057.pdf: 30.51\n",
            "S Loheth_BL.EN.U4MEE19039.pdf: 30.51\n",
            "K Sukha_BL.EN.U4CSE19059.pdf: 30.50\n",
            "K Ashwin_BL.EN.U4MEE19011.pdf: 30.49\n",
            "Himnish Pritmani_BL.EN.U4CSE19055.pdf: 30.42\n",
            "Yenumula Sravya Reddy_BL.EN.U4CSE19154.pdf: 30.40\n",
            "Vanukuri Sai Prakash Reddy_BL.EN.U4CSE19138.pdf: 30.34\n",
            "Yerradoddi Hrudeep Reddy_BL.EN.U4CSE19155.pdf: 30.20\n",
            "Sivannarayana Pannasi_BL.EN.U4MEE19045.pdf: 30.08\n",
            "Pendyala Venkat Sai_BL.EN.U4CSE19104.pdf: 30.08\n",
            "Vattikuti Shravya_BL.EN.U4CSE19140.pdf: 30.07\n",
            "Maddirala Venkata Tarun Pradeep_BL.EN.U4MEE19017.pdf: 29.89\n",
            "Kakaraparthi Rakesh_BL.EN.U4CSE19061.pdf: 29.84\n",
            "Karthik Puppala_BL.EN.U4CSE19063.pdf: 29.82\n",
            "Paluvayi Veera Adithya_BL.EN.U4CSE19102.pdf: 29.71\n",
            "Gayatri Sanjana Sannala_BL.EN.U4CSE19045.pdf: 29.69\n",
            "Sree Neha M_BL.EN.U4CSE19125.pdf: 29.68\n",
            "P Shanmukha Praneeth_BL.EN.U4CSE19098.pdf: 29.67\n",
            "Pasala Jaswanth Sai Reddy_BL.EN.U4CSE19103.pdf: 29.65\n",
            "Tadi Akhil_BL.EN.U4CSE19131.pdf: 29.49\n",
            "Konakalla Syam Sai_BL.EN.U4CSE19070.pdf: 29.22\n",
            "Gogineni Sravan Chowdary_BL.EN.U4CSE19048.pdf: 28.53\n",
            "Gudivada Harshitha_BL.EN.U4CSE19050.pdf: 28.21\n",
            "Sreekara Reddy N_BL.EN.U4MEE19046.pdf: 28.06\n",
            "V Satyakshaj Raju Pakalapati_BL.EN.U4CSE19136.pdf: 28.04\n",
            "Gudla Deshik Kumar_BL.EN.U4CSE19051.pdf: 27.07\n",
            "Sidharth Menon_BL.EN.U4MEE19043.pdf: 26.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}